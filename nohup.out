wandb: Currently logged in as: vinakhiem120 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py:305: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="./configs", config_name="main")
/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.
wandb: WARNING To avoid this, please fix the sweep config schema violations below:
wandb: WARNING   Violation 1. learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
Create sweep with ID: 2ti66t54
Sweep URL: https://wandb.ai/vinakhiem120/naim_tbi/sweeps/2ti66t54
[2025-05-30 15:03:57,645][wandb.agents.pyagent][INFO] - Starting sweep agent: entity=None, project=None, count=100
wandb: Agent Starting Run: yuychk78 with config:
wandb: 	Fdropout_rate: 0.4267264940197225
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 7
wandb: 	Mdropout_rate: 0.3958642162219067
wandb: 	Mnum_layers: 1
wandb: 	batch_size: 4
wandb: 	learning_rate: 0.0383532260879397
wandb: 	pretrained_model_name: nvidia/biomegatron-345m-uncased
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-03-13/wandb/run-20250530_150358-yuychk78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/2ti66t54
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/yuychk78
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
wandb:                                                                                
wandb: üöÄ View run sparkling-sweep-1 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/yuychk78
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_150358-yuychk78/logs
wandb: ERROR Run yuychk78 errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 406, in hf_raise_for_status
wandb: ERROR     response.raise_for_status()
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
wandb: ERROR     raise HTTPError(http_error_msg, response=self)
wandb: ERROR requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 342, in cached_file
wandb: ERROR     resolved_file = hf_hub_download(
wandb: ERROR                     ^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
wandb: ERROR     return _hf_hub_download_to_cache_dir(
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
wandb: ERROR     _raise_on_head_call_error(head_call_error, force_download, local_files_only)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1482, in _raise_on_head_call_error
wandb: ERROR     raise head_call_error
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
wandb: ERROR     metadata = get_hf_file_metadata(
wandb: ERROR                ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
wandb: ERROR     r = _request_wrapper(
wandb: ERROR         ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
wandb: ERROR     response = _request_wrapper(
wandb: ERROR                ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 302, in _request_wrapper
wandb: ERROR     hf_raise_for_status(response)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 454, in hf_raise_for_status
wandb: ERROR     raise _format(RepositoryNotFoundError, message, response) from e
wandb: ERROR huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-68394a51-1cc7633c786b8ab5220d5092;2aca3903-10c3-4195-8fe1-a0f33ff649db)
wandb: ERROR 
wandb: ERROR Repository Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json.
wandb: ERROR Please make sure you specified the correct `repo_id` and `repo_type`.
wandb: ERROR If you are trying to access a private or gated repo, make sure you are authenticated.
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
wandb: ERROR     return _target_(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/src/data/dataset.py", line 155, in __init__
wandb: ERROR     self.tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 881, in from_pretrained
wandb: ERROR     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
wandb: ERROR                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 713, in get_tokenizer_config
wandb: ERROR     resolved_config_file = cached_file(
wandb: ERROR                            ^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 365, in cached_file
wandb: ERROR     raise EnvironmentError(
wandb: ERROR OSError: nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
wandb: ERROR If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 299, in sweep_train
wandb: ERROR     train(config)
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 54, in train
wandb: ERROR     train_dataset = hydra.utils.instantiate(config.data.caller, data = train_data)
wandb: ERROR                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
wandb: ERROR     return instantiate_node(
wandb: ERROR            ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
wandb: ERROR     return _call_target(_target_, partial, args, kwargs, full_key)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
wandb: ERROR     raise InstantiationException(msg) from e
wandb: ERROR hydra.errors.InstantiationException: Error in call to target 'src.data.dataset.TBIDataset2stream':
wandb: ERROR OSError("nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`")
wandb: ERROR full_key: default_sweep.data.caller
wandb: ERROR 
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dvrumueg with config:
wandb: 	Fdropout_rate: 0.3551730916109501
wandb: 	Fnum_heads: 4
wandb: 	Fnum_layers: 4
wandb: 	Mdropout_rate: 0.30951478988493647
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 16
wandb: 	learning_rate: 0.0796555872105671
wandb: 	pretrained_model_name: emilyalsentzer/Bio_ClinicalBERT
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-03-13/wandb/run-20250530_150414-dvrumueg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/2ti66t54
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/dvrumueg
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
Training started...
Training started...
Epoch 0 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:19,853][__main__][INFO] - Train Epoch: 0 [0/26 (0%)]	Loss: 1.674473
Epoch 0 [Train]:   4%|‚ñç         | 1/26 [00:00<00:11,  2.08it/s]Epoch 0 [Train]:   8%|‚ñä         | 2/26 [00:00<00:07,  3.33it/s]Epoch 0 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:05,  4.12it/s]Epoch 0 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:01<00:04,  4.62it/s]Epoch 0 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:01<00:04,  4.95it/s]Epoch 0 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.17it/s]Epoch 0 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.32it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.40it/s]Epoch 0 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.46it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:02<00:02,  5.50it/s]Epoch 0 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:02<00:02,  5.54it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.56it/s]Epoch 0 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.58it/s]Epoch 0 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.57it/s]Epoch 0 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.58it/s]Epoch 0 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:03<00:01,  5.58it/s]Epoch 0 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.61it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.63it/s]Epoch 0 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.63it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.64it/s]Epoch 0 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:04<00:00,  5.65it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:04<00:00,  5.65it/s]Epoch 0 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.66it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.64it/s]Epoch 0 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.64it/s]                                                                Epoch 0 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 0 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.71it/s]Epoch 0 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.85it/s]Epoch 0 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.91it/s]Epoch 0 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.92it/s]Epoch 0 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.94it/s]Epoch 0 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.95it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:04:25,254][__main__][INFO] - Epoch 0: Val Loss: 3.8875, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7fdaf7fe8a80>
<numpy.flatiter object at 0x7fdaf7fe8a80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7fdaec67fc90>
<numpy.flatiter object at 0x7fdaec67fc90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7fdaec67fc90>
<numpy.flatiter object at 0x7fdaec67fc90>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7fdaec680290>
<numpy.flatiter object at 0x7fdaec680290>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7fdaec680290>
<numpy.flatiter object at 0x7fdaec680290>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:04:25,322][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:04:25,440][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:04:25,958][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:26,149][__main__][INFO] - Train Epoch: 1 [0/26 (0%)]	Loss: 3.554786
Epoch 1 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.32it/s]Epoch 1 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.48it/s]Epoch 1 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.54it/s]Epoch 1 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:03,  5.57it/s]Epoch 1 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.59it/s]Epoch 1 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.59it/s]Epoch 1 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.60it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.62it/s]Epoch 1 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.60it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.61it/s]Epoch 1 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:01<00:02,  5.62it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.68it/s]Epoch 1 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.67it/s]Epoch 1 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.66it/s]Epoch 1 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.65it/s]Epoch 1 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.63it/s]Epoch 1 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.64it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.63it/s]Epoch 1 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.63it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.62it/s]Epoch 1 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.63it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:03<00:00,  5.63it/s]Epoch 1 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.63it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.63it/s]Epoch 1 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.63it/s]                                                                Epoch 1 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 1 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.90it/s]Epoch 1 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.79it/s]Epoch 1 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.83it/s]Epoch 1 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.86it/s]Epoch 1 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.90it/s]Epoch 1 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.89it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:04:31,562][__main__][INFO] - Epoch 1: Val Loss: 1.3716, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2272012578616352, 'f1_weighted': 0.45167818668659315, 'precision_macro': 0.39749999999999996, 'recall_macro': 0.2727272727272727}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7fdaec8f06a0>
<numpy.flatiter object at 0x7fdaec8f06a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7fdaec939650>
<numpy.flatiter object at 0x7fdaec939650>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7fdaec939650>
<numpy.flatiter object at 0x7fdaec939650>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7fdaec90fa00>
<numpy.flatiter object at 0x7fdaec90fa00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7fdaec90fa00>
<numpy.flatiter object at 0x7fdaec90fa00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:04:31,628][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:04:31,730][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:31,941][__main__][INFO] - Train Epoch: 2 [0/26 (0%)]	Loss: 1.475522
Epoch 2 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.61it/s]Epoch 2 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.58it/s]Epoch 2 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.55it/s]Epoch 2 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:03,  5.57it/s]Epoch 2 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.57it/s]Epoch 2 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.58it/s]Epoch 2 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.59it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.60it/s]Epoch 2 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.60it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.63it/s]Epoch 2 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:01<00:02,  5.61it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.60it/s]Epoch 2 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.60it/s]Epoch 2 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.61it/s]Epoch 2 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.60it/s]Epoch 2 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.58it/s]Epoch 2 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.57it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.56it/s]Epoch 2 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.56it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.57it/s]Epoch 2 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.57it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:03<00:00,  5.59it/s]Epoch 2 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.58it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.59it/s]Epoch 2 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.58it/s]                                                                Epoch 2 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 2 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.88it/s]Epoch 2 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.87it/s]Epoch 2 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.94it/s]Epoch 2 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.91it/s]Epoch 2 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.93it/s]Epoch 2 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.92it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:04:37,380][__main__][INFO] - Epoch 2: Val Loss: 1.1543, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:37,572][__main__][INFO] - Train Epoch: 3 [0/26 (0%)]	Loss: 1.290411
Epoch 3 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.38it/s]Epoch 3 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.45it/s]Epoch 3 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.50it/s]Epoch 3 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:03,  5.52it/s]Epoch 3 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.53it/s]Epoch 3 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.53it/s]Epoch 3 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.55it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.56it/s]Epoch 3 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.57it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.56it/s]Epoch 3 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:01<00:02,  5.57it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.55it/s]Epoch 3 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.56it/s]Epoch 3 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.58it/s]Epoch 3 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.59it/s]Epoch 3 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.59it/s]Epoch 3 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.58it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.59it/s]Epoch 3 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.59it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.59it/s]Epoch 3 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.59it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:03<00:00,  5.51it/s]Epoch 3 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.52it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.53it/s]Epoch 3 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.54it/s]                                                                Epoch 3 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 3 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.88it/s]Epoch 3 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.86it/s]Epoch 3 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.90it/s]Epoch 3 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.87it/s]Epoch 3 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.86it/s]Epoch 3 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.86it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:04:43,042][__main__][INFO] - Epoch 3: Val Loss: 1.1803, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:43,226][__main__][INFO] - Train Epoch: 4 [0/26 (0%)]	Loss: 1.062194
Epoch 4 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.50it/s]Epoch 4 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.53it/s]Epoch 4 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.53it/s]Epoch 4 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:03,  5.52it/s]Epoch 4 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.54it/s]Epoch 4 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.55it/s]Epoch 4 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.55it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.54it/s]Epoch 4 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.55it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.54it/s]Epoch 4 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:01<00:02,  5.53it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.53it/s]Epoch 4 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.53it/s]Epoch 4 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.51it/s]Epoch 4 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.50it/s]Epoch 4 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.50it/s]Epoch 4 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.53it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.50it/s]Epoch 4 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.49it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.49it/s]Epoch 4 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.49it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:03<00:00,  5.48it/s]Epoch 4 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.49it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.50it/s]Epoch 4 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.51it/s]                                                                Epoch 4 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 4 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.80it/s]Epoch 4 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.80it/s]Epoch 4 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.83it/s]Epoch 4 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.81it/s]Epoch 4 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.82it/s]Epoch 4 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.82it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:04:48,735][__main__][INFO] - Epoch 4: Val Loss: 1.1986, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:48,925][__main__][INFO] - Train Epoch: 5 [0/26 (0%)]	Loss: 1.094357
Epoch 5 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.44it/s]Epoch 5 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.48it/s]Epoch 5 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.49it/s]Epoch 5 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:04,  5.50it/s]Epoch 5 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.50it/s]Epoch 5 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.49it/s]Epoch 5 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.49it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.50it/s]Epoch 5 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.50it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.52it/s]Epoch 5 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:01<00:02,  5.52it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.52it/s]Epoch 5 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.52it/s]Epoch 5 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.52it/s]Epoch 5 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.52it/s]Epoch 5 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.51it/s]Epoch 5 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.51it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.51it/s]Epoch 5 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.54it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.52it/s]Epoch 5 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.51it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:03<00:00,  5.48it/s]Epoch 5 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.47it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.47it/s]Epoch 5 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.46it/s]                                                                Epoch 5 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 5 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.73it/s]Epoch 5 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.76it/s]Epoch 5 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.78it/s]Epoch 5 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.80it/s]Epoch 5 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.79it/s]Epoch 5 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.80it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:04:54,456][__main__][INFO] - Epoch 5: Val Loss: 1.1757, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:04:54,646][__main__][INFO] - Train Epoch: 6 [0/26 (0%)]	Loss: 1.061434
Epoch 6 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.39it/s]Epoch 6 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.44it/s]Epoch 6 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.47it/s]Epoch 6 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:04,  5.47it/s]Epoch 6 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.47it/s]Epoch 6 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.45it/s]Epoch 6 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.47it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.44it/s]Epoch 6 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.45it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.45it/s]Epoch 6 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:02<00:02,  5.44it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.49it/s]Epoch 6 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.50it/s]Epoch 6 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.50it/s]Epoch 6 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.51it/s]Epoch 6 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.50it/s]Epoch 6 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.50it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.49it/s]Epoch 6 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.47it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  4.78it/s]Epoch 6 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:04<00:01,  3.95it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:04<00:01,  3.52it/s]Epoch 6 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  3.27it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:05<00:00,  3.11it/s]Epoch 6 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:05<00:00,  3.01it/s]                                                                Epoch 6 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 6 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:02,  2.91it/s]Epoch 6 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:01,  2.92it/s]Epoch 6 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01<00:01,  2.92it/s]Epoch 6 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01<00:01,  2.92it/s]Epoch 6 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01<00:00,  2.91it/s]Epoch 6 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  3.34it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:05:02,085][__main__][INFO] - Epoch 6: Val Loss: 1.1344, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:05:02,278][__main__][INFO] - Train Epoch: 7 [0/26 (0%)]	Loss: 1.169298
Epoch 7 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.27it/s]Epoch 7 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.38it/s]Epoch 7 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.41it/s]Epoch 7 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:04,  5.42it/s]Epoch 7 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.42it/s]Epoch 7 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.41it/s]Epoch 7 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.41it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.42it/s]Epoch 7 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.44it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.50it/s]Epoch 7 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:02<00:02,  5.48it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.47it/s]Epoch 7 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.47it/s]Epoch 7 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.45it/s]Epoch 7 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:02,  5.46it/s]Epoch 7 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.46it/s]Epoch 7 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.46it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.45it/s]Epoch 7 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.45it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.45it/s]Epoch 7 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.45it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:04<00:00,  5.46it/s]Epoch 7 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.44it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.44it/s]Epoch 7 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.42it/s]                                                                Epoch 7 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 7 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.80it/s]Epoch 7 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.74it/s]Epoch 7 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.75it/s]Epoch 7 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.75it/s]Epoch 7 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.74it/s]Epoch 7 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.76it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:05:07,854][__main__][INFO] - Epoch 7: Val Loss: 1.0339, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.2360641891891892, 'f1_weighted': 0.47919454107572923, 'precision_macro': 0.21980337078651685, 'recall_macro': 0.27478813559322035}
Epoch 8 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:05:08,041][__main__][INFO] - Train Epoch: 8 [0/26 (0%)]	Loss: 0.899581
Epoch 8 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.43it/s]Epoch 8 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.43it/s]Epoch 8 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.43it/s]Epoch 8 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:04,  5.43it/s]Epoch 8 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.43it/s]Epoch 8 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.44it/s]Epoch 8 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.43it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.42it/s]Epoch 8 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.42it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.42it/s]Epoch 8 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:02<00:02,  5.42it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.43it/s]Epoch 8 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.43it/s]Epoch 8 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.43it/s]Epoch 8 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:01,  5.50it/s]Epoch 8 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.48it/s]Epoch 8 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.45it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.44it/s]Epoch 8 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.44it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.43it/s]Epoch 8 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.42it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:04<00:00,  5.41it/s]Epoch 8 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.41it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.41it/s]Epoch 8 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.40it/s]                                                                Epoch 8 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 8 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.74it/s]Epoch 8 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.71it/s]Epoch 8 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.72it/s]Epoch 8 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.71it/s]Epoch 8 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.71it/s]Epoch 8 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.72it/s]                                                            [2025-05-30 15:05:13,639][__main__][INFO] - Epoch 8: Val Loss: 1.1550, Accuracy: 0.4257, Metrics: {'accuracy': 0.42574257425742573, 'f1_macro': 0.43756416972236767, 'f1_weighted': 0.4354964757869187, 'precision_macro': 0.46634615384615385, 'recall_macro': 0.5421802773497688}
Epoch 9 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:05:13,825][__main__][INFO] - Train Epoch: 9 [0/26 (0%)]	Loss: 0.791862
Epoch 9 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.42it/s]Epoch 9 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.43it/s]Epoch 9 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.43it/s]Epoch 9 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:04,  5.42it/s]Epoch 9 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.42it/s]Epoch 9 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.42it/s]Epoch 9 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.43it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.43it/s]Epoch 9 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.42it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.40it/s]Epoch 9 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:02<00:02,  5.40it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.40it/s]Epoch 9 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.40it/s]Epoch 9 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.40it/s]Epoch 9 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:02,  5.41it/s]Epoch 9 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.41it/s]Epoch 9 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.41it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.39it/s]Epoch 9 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.38it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.38it/s]Epoch 9 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.39it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:04<00:00,  5.40it/s]Epoch 9 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.39it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.38it/s]Epoch 9 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.40it/s]                                                                Epoch 9 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 9 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.69it/s]Epoch 9 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.71it/s]Epoch 9 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.72it/s]Epoch 9 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.71it/s]Epoch 9 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.71it/s]Epoch 9 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.72it/s]                                                            [2025-05-30 15:05:19,445][__main__][INFO] - Epoch 9: Val Loss: 1.1889, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.37427536231884057, 'f1_weighted': 0.5517721337351127, 'precision_macro': 0.5875, 'recall_macro': 0.3984206471494607}
Epoch 10 [Train]:   0%|          | 0/26 [00:00<?, ?it/s][2025-05-30 15:05:19,639][__main__][INFO] - Train Epoch: 10 [0/26 (0%)]	Loss: 1.256972
Epoch 10 [Train]:   4%|‚ñç         | 1/26 [00:00<00:04,  5.22it/s]Epoch 10 [Train]:   8%|‚ñä         | 2/26 [00:00<00:04,  5.31it/s]Epoch 10 [Train]:  12%|‚ñà‚ñè        | 3/26 [00:00<00:04,  5.33it/s]Epoch 10 [Train]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:04,  5.35it/s]Epoch 10 [Train]:  19%|‚ñà‚ñâ        | 5/26 [00:00<00:03,  5.36it/s]Epoch 10 [Train]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:01<00:03,  5.36it/s]Epoch 10 [Train]:  27%|‚ñà‚ñà‚ñã       | 7/26 [00:01<00:03,  5.26it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:01<00:03,  5.30it/s]Epoch 10 [Train]:  35%|‚ñà‚ñà‚ñà‚ñç      | 9/26 [00:01<00:03,  5.32it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:01<00:02,  5.34it/s]Epoch 10 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 11/26 [00:02<00:02,  5.35it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:02<00:02,  5.37it/s]Epoch 10 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 13/26 [00:02<00:02,  5.39it/s]Epoch 10 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:02<00:02,  5.39it/s]Epoch 10 [Train]:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 15/26 [00:02<00:02,  5.39it/s]Epoch 10 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:02<00:01,  5.40it/s]Epoch 10 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 17/26 [00:03<00:01,  5.40it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:03<00:01,  5.40it/s]Epoch 10 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 19/26 [00:03<00:01,  5.41it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:03<00:01,  5.41it/s]Epoch 10 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 21/26 [00:03<00:00,  5.41it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:04<00:00,  5.41it/s]Epoch 10 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23/26 [00:04<00:00,  5.41it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:04<00:00,  5.42it/s]Epoch 10 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 25/26 [00:04<00:00,  5.42it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/7 [00:00<?, ?it/s]wandb: Ctrl + C detected. Stopping sweep.
Epoch 10 [Val]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:01,  5.70it/s]Epoch 10 [Val]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00<00:00,  5.65it/s]Epoch 10 [Val]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00<00:00,  5.66it/s]Epoch 10 [Val]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00<00:00,  5.67it/s]Epoch 10 [Val]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00<00:00,  5.68it/s]Epoch 10 [Val]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01<00:00,  5.70it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:05:25,282][__main__][INFO] - Epoch 10: Val Loss: 1.1316, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.4354166666666667, 'f1_weighted': 0.586963696369637, 'precision_macro': 0.5221273291925466, 'recall_macro': 0.4317989214175655}
Exception in thread Thread-7 (_run_job):
Traceback (most recent call last):
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 299, in sweep_train
    train(config)
  File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 152, in train
    wandb.log({"Validation Loss": val_loss, "Validation Accuracy": val_accuracy})  # Log to wandb
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 441, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 393, in wrapper_fn
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 383, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1871, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1585, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1415, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 692, in publish_partial_history
    self._publish_partial_history(partial_history)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 89, in _publish_partial_history
    self._publish(rec)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 47, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 222, in send_record_publish
    self.send_server_request(server_req)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in send_server_request
    self._send_message(msg)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 151, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
    self.run()
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 311, in _run_job
    wandb.finish(exit_code=1)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 4137, in finish
    wandb.run.finish(exit_code=exit_code, quiet=quiet)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 441, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 383, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 2104, in finish
    return self._finish(exit_code)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 2111, in _finish
    with telemetry.context(run=self) as tel:
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/telemetry.py", line 42, in __exit__
    self._run._telemetry_callback(self._obj)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 741, in _telemetry_callback
    self._telemetry_flush()
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 754, in _telemetry_flush
    self._backend.interface._publish_telemetry(self._telemetry_obj)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 101, in _publish_telemetry
    self._publish(rec)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 47, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 222, in send_record_publish
    self.send_server_request(server_req)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 154, in send_server_request
    self._send_message(msg)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 151, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mapricot-sweep-2[0m at: [34mhttps://wandb.ai/vinakhiem120/naim_tbi/runs/dvrumueg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250530_150414-dvrumueg/logs[0m
wandb: Currently logged in as: vinakhiem120 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py:305: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="./configs", config_name="main")
/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.
wandb: WARNING To avoid this, please fix the sweep config schema violations below:
wandb: WARNING   Violation 1. learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.
Create sweep with ID: dpgwzdsz
Sweep URL: https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
[2025-05-30 15:05:59,166][wandb.agents.pyagent][INFO] - Starting sweep agent: entity=None, project=None, count=100
wandb: Agent Starting Run: sg2e92ty with config:
wandb: 	Fdropout_rate: 0.22807270521203535
wandb: 	Fnum_heads: 4
wandb: 	Fnum_layers: 4
wandb: 	Mdropout_rate: 0.2132278262473509
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 8
wandb: 	learning_rate: 0.025342914297172028
wandb: 	pretrained_model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_150600-sg2e92ty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/sg2e92ty
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
Training started...
Epoch 0 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:06,423][__main__][INFO] - Train Epoch: 0 [0/51 (0%)]	Loss: 1.837089
Epoch 0 [Train]:   2%|‚ñè         | 1/51 [00:00<00:20,  2.49it/s]Epoch 0 [Train]:   4%|‚ñç         | 2/51 [00:00<00:11,  4.29it/s]Epoch 0 [Train]:   6%|‚ñå         | 3/51 [00:00<00:08,  5.73it/s]Epoch 0 [Train]:   8%|‚ñä         | 4/51 [00:00<00:06,  6.89it/s]Epoch 0 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:05,  7.75it/s]Epoch 0 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:05,  8.37it/s]Epoch 0 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:01<00:04,  9.09it/s]Epoch 0 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:01<00:04,  9.29it/s]Epoch 0 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.43it/s]Epoch 0 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.55it/s]Epoch 0 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.62it/s]Epoch 0 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.70it/s]Epoch 0 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.74it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.77it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.75it/s]Epoch 0 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:02<00:03,  9.78it/s]Epoch 0 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:02<00:03,  9.80it/s]Epoch 0 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.82it/s]Epoch 0 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.81it/s]Epoch 0 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.83it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.84it/s]Epoch 0 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.81it/s]Epoch 0 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.82it/s]Epoch 0 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.84it/s]Epoch 0 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.83it/s]Epoch 0 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:03<00:02,  9.82it/s]Epoch 0 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:03<00:02,  9.82it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.85it/s]Epoch 0 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.85it/s]Epoch 0 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.84it/s]Epoch 0 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.82it/s]Epoch 0 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.83it/s]Epoch 0 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.85it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.85it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.87it/s]Epoch 0 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:04<00:01,  9.88it/s]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.88it/s]Epoch 0 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.81it/s]Epoch 0 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.80it/s]Epoch 0 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.83it/s]Epoch 0 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.84it/s]Epoch 0 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.86it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.86it/s]Epoch 0 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.87it/s]Epoch 0 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.89it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.87it/s]Epoch 0 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.88it/s]Epoch 0 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.88it/s]Epoch 0 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.88it/s]                                                                Epoch 0 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 0 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.87it/s]Epoch 0 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.28it/s]Epoch 0 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.50it/s]Epoch 0 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.59it/s]Epoch 0 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.63it/s]Epoch 0 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.68it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 11.23it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:12,672][__main__][INFO] - Epoch 0: Val Loss: 1.2343, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3753c57c80>
<numpy.flatiter object at 0x7f3753c57c80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3753c6c980>
<numpy.flatiter object at 0x7f3753c6c980>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3753c6c980>
<numpy.flatiter object at 0x7f3753c6c980>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3753c6cf80>
<numpy.flatiter object at 0x7f3753c6cf80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3753c6cf80>
<numpy.flatiter object at 0x7f3753c6cf80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:06:12,750][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:06:12,854][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:06:13,402][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:13,518][__main__][INFO] - Train Epoch: 1 [0/51 (0%)]	Loss: 1.508669
Epoch 1 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  8.97it/s]Epoch 1 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.43it/s]Epoch 1 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.65it/s]Epoch 1 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.74it/s]Epoch 1 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.79it/s]Epoch 1 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.81it/s]Epoch 1 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.83it/s]Epoch 1 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.83it/s]Epoch 1 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.83it/s]Epoch 1 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.83it/s]Epoch 1 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.85it/s]Epoch 1 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.85it/s]Epoch 1 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.84it/s]Epoch 1 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.84it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.85it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.86it/s]Epoch 1 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.84it/s]Epoch 1 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.82it/s]Epoch 1 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.89it/s]Epoch 1 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.89it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.88it/s]Epoch 1 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.86it/s]Epoch 1 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.86it/s]Epoch 1 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.83it/s]Epoch 1 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.84it/s]Epoch 1 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.85it/s]Epoch 1 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.84it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.85it/s]Epoch 1 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.85it/s]Epoch 1 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.84it/s]Epoch 1 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.80it/s]Epoch 1 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.80it/s]Epoch 1 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.82it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.82it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.82it/s]Epoch 1 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.82it/s]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.85it/s]Epoch 1 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:03<00:01,  9.84it/s]Epoch 1 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.83it/s]Epoch 1 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.83it/s]Epoch 1 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.86it/s]Epoch 1 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.86it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.85it/s]Epoch 1 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.85it/s]Epoch 1 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.85it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.84it/s]Epoch 1 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.83it/s]Epoch 1 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:04<00:00,  9.83it/s]Epoch 1 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.82it/s]                                                                Epoch 1 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 1 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.60it/s]Epoch 1 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.53it/s]Epoch 1 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.55it/s]Epoch 1 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.61it/s]Epoch 1 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.65it/s]Epoch 1 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.67it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:19,753][__main__][INFO] - Epoch 1: Val Loss: 1.1242, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3503978779840849, 'f1_weighted': 0.5262914620374505, 'precision_macro': 0.29903100775193797, 'recall_macro': 0.42334360554699535}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374868d9e0>
<numpy.flatiter object at 0x7f374868d9e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f374862f2d0>
<numpy.flatiter object at 0x7f374862f2d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374862f2d0>
<numpy.flatiter object at 0x7f374862f2d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374862f8d0>
<numpy.flatiter object at 0x7f374862f8d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374862f8d0>
<numpy.flatiter object at 0x7f374862f8d0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:06:19,822][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.6436
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:06:19,955][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:20,104][__main__][INFO] - Train Epoch: 2 [0/51 (0%)]	Loss: 0.971789
Epoch 2 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.78it/s]Epoch 2 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.79it/s]Epoch 2 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.84it/s]Epoch 2 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.83it/s]Epoch 2 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.85it/s]Epoch 2 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.87it/s]Epoch 2 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.87it/s]Epoch 2 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.88it/s]Epoch 2 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.88it/s]Epoch 2 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.87it/s]Epoch 2 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.89it/s]Epoch 2 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.92it/s]Epoch 2 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.92it/s]Epoch 2 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.91it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.91it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.91it/s]Epoch 2 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.91it/s]Epoch 2 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.89it/s]Epoch 2 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.89it/s]Epoch 2 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.87it/s]Epoch 2 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.88it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.86it/s]Epoch 2 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.86it/s]Epoch 2 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.86it/s]Epoch 2 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.87it/s]Epoch 2 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.88it/s]Epoch 2 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.87it/s]Epoch 2 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.86it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.86it/s]Epoch 2 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.84it/s]Epoch 2 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.83it/s]Epoch 2 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.79it/s]Epoch 2 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.81it/s]Epoch 2 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.86it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.87it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.80it/s]Epoch 2 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.80it/s]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.80it/s]Epoch 2 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:03<00:01,  9.83it/s]Epoch 2 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.83it/s]Epoch 2 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.82it/s]Epoch 2 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.83it/s]Epoch 2 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.81it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.80it/s]Epoch 2 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.77it/s]Epoch 2 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.76it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.80it/s]Epoch 2 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.79it/s]Epoch 2 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:04<00:00,  9.78it/s]Epoch 2 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.78it/s]                                                                Epoch 2 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 2 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.22it/s]Epoch 2 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.33it/s]Epoch 2 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.46it/s]Epoch 2 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.52it/s]Epoch 2 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.56it/s]Epoch 2 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.54it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:26,354][__main__][INFO] - Epoch 2: Val Loss: 0.8700, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.36858076563958914, 'f1_weighted': 0.5717521331965129, 'precision_macro': 0.37719633307868605, 'recall_macro': 0.4111517719568567}
Epoch 3 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:26,457][__main__][INFO] - Train Epoch: 3 [0/51 (0%)]	Loss: 0.840295
Epoch 3 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.91it/s]Epoch 3 [Train]:   4%|‚ñç         | 2/51 [00:00<00:04,  9.84it/s]Epoch 3 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.89it/s]Epoch 3 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.89it/s]Epoch 3 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.88it/s]Epoch 3 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.91it/s]Epoch 3 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.90it/s]Epoch 3 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.88it/s]Epoch 3 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.89it/s]Epoch 3 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.90it/s]Epoch 3 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.89it/s]Epoch 3 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.90it/s]Epoch 3 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.91it/s]Epoch 3 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.88it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.89it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.87it/s]Epoch 3 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.88it/s]Epoch 3 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.87it/s]Epoch 3 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.86it/s]Epoch 3 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.83it/s]Epoch 3 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.83it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.84it/s]Epoch 3 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.81it/s]Epoch 3 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.77it/s]Epoch 3 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.77it/s]Epoch 3 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.79it/s]Epoch 3 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.80it/s]Epoch 3 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.79it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.77it/s]Epoch 3 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.76it/s]Epoch 3 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.73it/s]Epoch 3 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.71it/s]Epoch 3 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.71it/s]Epoch 3 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.71it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.73it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.73it/s]Epoch 3 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.75it/s]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.74it/s]Epoch 3 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:03<00:01,  9.75it/s]Epoch 3 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.76it/s]Epoch 3 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.78it/s]Epoch 3 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.79it/s]Epoch 3 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.79it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.78it/s]Epoch 3 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.78it/s]Epoch 3 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.77it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.77it/s]Epoch 3 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.77it/s]Epoch 3 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:04<00:00,  9.76it/s]Epoch 3 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.76it/s]                                                                Epoch 3 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 3 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.46it/s]Epoch 3 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.46it/s]Epoch 3 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.51it/s]Epoch 3 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.54it/s]Epoch 3 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.56it/s]Epoch 3 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.56it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:32,723][__main__][INFO] - Epoch 3: Val Loss: 0.8846, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.50352081970787, 'f1_weighted': 0.6507111142768953, 'precision_macro': 0.5349431818181818, 'recall_macro': 0.5108436055469954}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486f8a60>
<numpy.flatiter object at 0x7f37486f8a60>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748729b00>
<numpy.flatiter object at 0x7f3748729b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748729b00>
<numpy.flatiter object at 0x7f3748729b00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374870e6c0>
<numpy.flatiter object at 0x7f374870e6c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374870e6c0>
<numpy.flatiter object at 0x7f374870e6c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:06:32,788][__main__][INFO] - Saved best model at epoch 3 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:06:32,885][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 4 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:33,021][__main__][INFO] - Train Epoch: 4 [0/51 (0%)]	Loss: 0.233434
Epoch 4 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.79it/s]Epoch 4 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.80it/s]Epoch 4 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.78it/s]Epoch 4 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.76it/s]Epoch 4 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.75it/s]Epoch 4 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.76it/s]Epoch 4 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.76it/s]Epoch 4 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.74it/s]Epoch 4 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.77it/s]Epoch 4 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.75it/s]Epoch 4 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.74it/s]Epoch 4 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.72it/s]Epoch 4 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.70it/s]Epoch 4 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.70it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.69it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.71it/s]Epoch 4 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.71it/s]Epoch 4 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 4 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.70it/s]Epoch 4 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.72it/s]Epoch 4 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.61it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.64it/s]Epoch 4 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.63it/s]Epoch 4 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.64it/s]Epoch 4 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.64it/s]Epoch 4 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.65it/s]Epoch 4 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.66it/s]Epoch 4 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.68it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.64it/s]Epoch 4 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.65it/s]Epoch 4 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.62it/s]Epoch 4 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.64it/s]Epoch 4 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.61it/s]Epoch 4 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.54it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.58it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.57it/s]Epoch 4 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.59it/s]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.63it/s]Epoch 4 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.66it/s]Epoch 4 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.65it/s]Epoch 4 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.64it/s]Epoch 4 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.64it/s]Epoch 4 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.64it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.66it/s]Epoch 4 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.66it/s]Epoch 4 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.67it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.66it/s]Epoch 4 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.66it/s]Epoch 4 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.66it/s]Epoch 4 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.63it/s]                                                                Epoch 4 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 4 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.30it/s]Epoch 4 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.33it/s]Epoch 4 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.41it/s]Epoch 4 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.45it/s]Epoch 4 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.50it/s]Epoch 4 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.52it/s]                                                              [2025-05-30 15:06:39,366][__main__][INFO] - Epoch 4: Val Loss: 0.7668, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5897782675482535, 'f1_weighted': 0.7012695459087083, 'precision_macro': 0.6349252013808976, 'recall_macro': 0.5812981510015408}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374879aa00>
<numpy.flatiter object at 0x7f374879aa00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748786540>
<numpy.flatiter object at 0x7f3748786540>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748786540>
<numpy.flatiter object at 0x7f3748786540>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748786b40>
<numpy.flatiter object at 0x7f3748786b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748786b40>
<numpy.flatiter object at 0x7f3748786b40>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:06:39,427][__main__][INFO] - Saved best model at epoch 4 with accuracy: 0.7525
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:06:39,528][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 5 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:39,663][__main__][INFO] - Train Epoch: 5 [0/51 (0%)]	Loss: 0.596873
Epoch 5 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.89it/s]Epoch 5 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.79it/s]Epoch 5 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.76it/s]Epoch 5 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.74it/s]Epoch 5 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.69it/s]Epoch 5 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.68it/s]Epoch 5 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.67it/s]Epoch 5 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.70it/s]Epoch 5 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.71it/s]Epoch 5 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.65it/s]Epoch 5 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.70it/s]Epoch 5 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.72it/s]Epoch 5 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.73it/s]Epoch 5 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.73it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.70it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.68it/s]Epoch 5 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.67it/s]Epoch 5 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.65it/s]Epoch 5 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.64it/s]Epoch 5 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.59it/s]Epoch 5 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.64it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.63it/s]Epoch 5 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.63it/s]Epoch 5 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.65it/s]Epoch 5 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.63it/s]Epoch 5 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.63it/s]Epoch 5 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.64it/s]Epoch 5 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.57it/s]Epoch 5 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.56it/s]Epoch 5 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.61it/s]Epoch 5 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.61it/s]Epoch 5 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.62it/s]Epoch 5 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.62it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.63it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.66it/s]Epoch 5 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.66it/s]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.68it/s]Epoch 5 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.65it/s]Epoch 5 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.67it/s]Epoch 5 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.65it/s]Epoch 5 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.66it/s]Epoch 5 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.62it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.61it/s]Epoch 5 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.62it/s]Epoch 5 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.64it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.64it/s]Epoch 5 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.64it/s]Epoch 5 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.66it/s]Epoch 5 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.63it/s]                                                                Epoch 5 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 5 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.37it/s]Epoch 5 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.37it/s]Epoch 5 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.44it/s]Epoch 5 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.46it/s]Epoch 5 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.49it/s]Epoch 5 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.50it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:46,017][__main__][INFO] - Epoch 5: Val Loss: 1.1417, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4069634703196347, 'f1_weighted': 0.5548849405488493, 'precision_macro': 0.358974358974359, 'recall_macro': 0.4730354391371341}
Epoch 6 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:46,124][__main__][INFO] - Train Epoch: 6 [0/51 (0%)]	Loss: 0.992597
Epoch 6 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.56it/s]Epoch 6 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.63it/s]Epoch 6 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.63it/s]Epoch 6 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.66it/s]Epoch 6 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.68it/s]Epoch 6 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.73it/s]Epoch 6 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.55it/s]Epoch 6 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.50it/s]Epoch 6 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.52it/s]Epoch 6 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.52it/s]Epoch 6 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.54it/s]Epoch 6 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.55it/s]Epoch 6 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.59it/s]Epoch 6 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.59it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.61it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.59it/s]Epoch 6 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.59it/s]Epoch 6 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.61it/s]Epoch 6 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.63it/s]Epoch 6 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.62it/s]Epoch 6 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.62it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.61it/s]Epoch 6 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.61it/s]Epoch 6 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.60it/s]Epoch 6 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.61it/s]Epoch 6 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.63it/s]Epoch 6 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.64it/s]Epoch 6 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.64it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.66it/s]Epoch 6 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.67it/s]Epoch 6 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.67it/s]Epoch 6 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.63it/s]Epoch 6 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.62it/s]Epoch 6 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.60it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.61it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.63it/s]Epoch 6 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.64it/s]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.65it/s]Epoch 6 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.66it/s]Epoch 6 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.67it/s]Epoch 6 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.63it/s]Epoch 6 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.62it/s]Epoch 6 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.62it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.63it/s]Epoch 6 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.63it/s]Epoch 6 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.65it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.66it/s]Epoch 6 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.67it/s]Epoch 6 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.62it/s]Epoch 6 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.61it/s]                                                                Epoch 6 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 6 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.43it/s]Epoch 6 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.35it/s]Epoch 6 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.44it/s]Epoch 6 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.43it/s]Epoch 6 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.46it/s]Epoch 6 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.48it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:52,496][__main__][INFO] - Epoch 6: Val Loss: 0.7870, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5572458221711953, 'f1_weighted': 0.6948186207828589, 'precision_macro': 0.594561403508772, 'recall_macro': 0.5463790446841295}
Epoch 7 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:52,601][__main__][INFO] - Train Epoch: 7 [0/51 (0%)]	Loss: 0.941769
Epoch 7 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.68it/s]Epoch 7 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.67it/s]Epoch 7 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.71it/s]Epoch 7 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.73it/s]Epoch 7 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.74it/s]Epoch 7 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.77it/s]Epoch 7 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.76it/s]Epoch 7 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.74it/s]Epoch 7 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.73it/s]Epoch 7 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.72it/s]Epoch 7 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.71it/s]Epoch 7 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.71it/s]Epoch 7 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.69it/s]Epoch 7 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.66it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.65it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.65it/s]Epoch 7 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.65it/s]Epoch 7 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.67it/s]Epoch 7 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.68it/s]Epoch 7 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.68it/s]Epoch 7 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.68it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.66it/s]Epoch 7 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.62it/s]Epoch 7 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.63it/s]Epoch 7 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.65it/s]Epoch 7 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.65it/s]Epoch 7 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.65it/s]Epoch 7 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.62it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.62it/s]Epoch 7 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.62it/s]Epoch 7 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.61it/s]Epoch 7 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.60it/s]Epoch 7 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.60it/s]Epoch 7 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.61it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.63it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.65it/s]Epoch 7 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.64it/s]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.62it/s]Epoch 7 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.60it/s]Epoch 7 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.59it/s]Epoch 7 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.59it/s]Epoch 7 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.61it/s]Epoch 7 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.63it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.65it/s]Epoch 7 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.65it/s]Epoch 7 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.60it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.60it/s]Epoch 7 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.60it/s]Epoch 7 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.59it/s]Epoch 7 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.60it/s]                                                                Epoch 7 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 7 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.43it/s]Epoch 7 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.39it/s]Epoch 7 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.39it/s]Epoch 7 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.46it/s]Epoch 7 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.48it/s]Epoch 7 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.47it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:06:58,957][__main__][INFO] - Epoch 7: Val Loss: 0.7182, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6137171286425018, 'f1_weighted': 0.7239896697558881, 'precision_macro': 0.6241666666666666, 'recall_macro': 0.6145608628659476}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748dac640>
<numpy.flatiter object at 0x7f3748dac640>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748daa4c0>
<numpy.flatiter object at 0x7f3748daa4c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748daa4c0>
<numpy.flatiter object at 0x7f3748daa4c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37487e6d30>
<numpy.flatiter object at 0x7f37487e6d30>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37487e6d30>
<numpy.flatiter object at 0x7f37487e6d30>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:06:59,024][__main__][INFO] - Saved best model at epoch 7 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:06:59,122][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 8 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:06:59,256][__main__][INFO] - Train Epoch: 8 [0/51 (0%)]	Loss: 0.621675
Epoch 8 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.85it/s]Epoch 8 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.46it/s]Epoch 8 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.56it/s]Epoch 8 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.61it/s]Epoch 8 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.64it/s]Epoch 8 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.65it/s]Epoch 8 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.65it/s]Epoch 8 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.64it/s]Epoch 8 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.65it/s]Epoch 8 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.63it/s]Epoch 8 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.64it/s]Epoch 8 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.64it/s]Epoch 8 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.60it/s]Epoch 8 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.60it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.56it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.57it/s]Epoch 8 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.60it/s]Epoch 8 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.60it/s]Epoch 8 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.61it/s]Epoch 8 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.60it/s]Epoch 8 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.59it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.57it/s]Epoch 8 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.58it/s]Epoch 8 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.59it/s]Epoch 8 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.58it/s]Epoch 8 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.58it/s]Epoch 8 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.59it/s]Epoch 8 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.58it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.58it/s]Epoch 8 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.59it/s]Epoch 8 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.59it/s]Epoch 8 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.59it/s]Epoch 8 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.59it/s]Epoch 8 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.58it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.56it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.56it/s]Epoch 8 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.58it/s]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.59it/s]Epoch 8 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.59it/s]Epoch 8 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.59it/s]Epoch 8 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.60it/s]Epoch 8 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.58it/s]Epoch 8 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.56it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.56it/s]Epoch 8 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.56it/s]Epoch 8 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.57it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.59it/s]Epoch 8 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.58it/s]Epoch 8 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.53it/s]Epoch 8 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.52it/s]                                                                Epoch 8 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 8 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.18it/s]Epoch 8 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.26it/s]Epoch 8 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.35it/s]Epoch 8 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.39it/s]Epoch 8 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.41it/s]Epoch 8 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:05,657][__main__][INFO] - Epoch 8: Val Loss: 0.8675, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.39713279678068414, 'f1_weighted': 0.5545450923361953, 'precision_macro': 0.33345145287030475, 'recall_macro': 0.4915254237288136}
Epoch 9 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:05,769][__main__][INFO] - Train Epoch: 9 [0/51 (0%)]	Loss: 0.943310
Epoch 9 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.12it/s]Epoch 9 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.09it/s]Epoch 9 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.42it/s]Epoch 9 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.54it/s]Epoch 9 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.58it/s]Epoch 9 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.60it/s]Epoch 9 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.61it/s]Epoch 9 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.62it/s]Epoch 9 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.63it/s]Epoch 9 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.63it/s]Epoch 9 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.64it/s]Epoch 9 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.63it/s]Epoch 9 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.63it/s]Epoch 9 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.63it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.60it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.62it/s]Epoch 9 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.60it/s]Epoch 9 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.61it/s]Epoch 9 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.56it/s]Epoch 9 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.49it/s]Epoch 9 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.49it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.52it/s]Epoch 9 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 9 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.56it/s]Epoch 9 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.58it/s]Epoch 9 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.58it/s]Epoch 9 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.58it/s]Epoch 9 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.58it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.58it/s]Epoch 9 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.59it/s]Epoch 9 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.61it/s]Epoch 9 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.60it/s]Epoch 9 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.60it/s]Epoch 9 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.58it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.58it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.58it/s]Epoch 9 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.59it/s]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.57it/s]Epoch 9 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.55it/s]Epoch 9 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.54it/s]Epoch 9 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.55it/s]Epoch 9 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.57it/s]Epoch 9 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.57it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.59it/s]Epoch 9 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.60it/s]Epoch 9 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.54it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.52it/s]Epoch 9 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.54it/s]Epoch 9 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.55it/s]Epoch 9 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.59it/s]                                                                Epoch 9 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 9 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.23it/s]Epoch 9 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.23it/s]Epoch 9 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.34it/s]Epoch 9 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.37it/s]Epoch 9 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.40it/s]Epoch 9 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.43it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:12,170][__main__][INFO] - Epoch 9: Val Loss: 0.7042, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6137171286425018, 'f1_weighted': 0.7239896697558881, 'precision_macro': 0.6241666666666666, 'recall_macro': 0.6145608628659476}
Epoch 10 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:12,283][__main__][INFO] - Train Epoch: 10 [0/51 (0%)]	Loss: 0.595487
Epoch 10 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.31it/s]Epoch 10 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.44it/s]Epoch 10 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.55it/s]Epoch 10 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.56it/s]Epoch 10 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.61it/s]Epoch 10 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.62it/s]Epoch 10 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.64it/s]Epoch 10 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.65it/s]Epoch 10 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.69it/s]Epoch 10 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.70it/s]Epoch 10 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.73it/s]Epoch 10 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.70it/s]Epoch 10 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.72it/s]Epoch 10 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.75it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.74it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.75it/s]Epoch 10 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.74it/s]Epoch 10 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.69it/s]Epoch 10 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.66it/s]Epoch 10 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.63it/s]Epoch 10 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.61it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.62it/s]Epoch 10 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.60it/s]Epoch 10 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.59it/s]Epoch 10 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.56it/s]Epoch 10 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.56it/s]Epoch 10 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.57it/s]Epoch 10 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.57it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.58it/s]Epoch 10 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.58it/s]Epoch 10 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.58it/s]Epoch 10 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.58it/s]Epoch 10 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.58it/s]Epoch 10 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.61it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.59it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.59it/s]Epoch 10 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.61it/s]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.60it/s]Epoch 10 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.59it/s]Epoch 10 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.59it/s]Epoch 10 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.60it/s]Epoch 10 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.60it/s]Epoch 10 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.61it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.61it/s]Epoch 10 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.59it/s]Epoch 10 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.58it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.58it/s]Epoch 10 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.60it/s]Epoch 10 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.60it/s]Epoch 10 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.62it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 10 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.29it/s]Epoch 10 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.29it/s]Epoch 10 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.36it/s]Epoch 10 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.36it/s]Epoch 10 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.41it/s]Epoch 10 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.41it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:18,659][__main__][INFO] - Epoch 10: Val Loss: 0.7160, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5504679144385027, 'f1_weighted': 0.6867819134854662, 'precision_macro': 0.5626873126873128, 'recall_macro': 0.5585708782742681}
Epoch 11 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:18,765][__main__][INFO] - Train Epoch: 11 [0/51 (0%)]	Loss: 0.352830
Epoch 11 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.67it/s]Epoch 11 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.27it/s]Epoch 11 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.42it/s]Epoch 11 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.49it/s]Epoch 11 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.52it/s]Epoch 11 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.56it/s]Epoch 11 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.58it/s]Epoch 11 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.56it/s]Epoch 11 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.60it/s]Epoch 11 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.60it/s]Epoch 11 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.57it/s]Epoch 11 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.57it/s]Epoch 11 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.57it/s]Epoch 11 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.57it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.59it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.58it/s]Epoch 11 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.57it/s]Epoch 11 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.55it/s]Epoch 11 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.54it/s]Epoch 11 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.54it/s]Epoch 11 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.55it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.57it/s]Epoch 11 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.57it/s]Epoch 11 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.55it/s]Epoch 11 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.54it/s]Epoch 11 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.55it/s]Epoch 11 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.56it/s]Epoch 11 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.58it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.60it/s]Epoch 11 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.59it/s]Epoch 11 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.57it/s]Epoch 11 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.56it/s]Epoch 11 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.56it/s]Epoch 11 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.57it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.59it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.59it/s]Epoch 11 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.55it/s]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.55it/s]Epoch 11 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.55it/s]Epoch 11 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.55it/s]Epoch 11 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.57it/s]Epoch 11 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.58it/s]Epoch 11 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.57it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.57it/s]Epoch 11 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.51it/s]Epoch 11 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.54it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.56it/s]Epoch 11 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.57it/s]Epoch 11 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.58it/s]Epoch 11 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.54it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 11 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.34it/s]Epoch 11 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.28it/s]Epoch 11 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.31it/s]Epoch 11 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.36it/s]Epoch 11 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.38it/s]Epoch 11 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.39it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:25,182][__main__][INFO] - Epoch 11: Val Loss: 0.7762, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.507992327365729, 'f1_weighted': 0.6584538249221342, 'precision_macro': 0.571004746835443, 'recall_macro': 0.4903890600924499}
Epoch 12 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:25,295][__main__][INFO] - Train Epoch: 12 [0/51 (0%)]	Loss: 0.379042
Epoch 12 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.21it/s]Epoch 12 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.39it/s]Epoch 12 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.53it/s]Epoch 12 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.62it/s]Epoch 12 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.64it/s]Epoch 12 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.67it/s]Epoch 12 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.69it/s]Epoch 12 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.71it/s]Epoch 12 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.70it/s]Epoch 12 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.71it/s]Epoch 12 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.69it/s]Epoch 12 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.68it/s]Epoch 12 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.68it/s]Epoch 12 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.68it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.67it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.69it/s]Epoch 12 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.72it/s]Epoch 12 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.74it/s]Epoch 12 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.72it/s]Epoch 12 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.73it/s]Epoch 12 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.69it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.68it/s]Epoch 12 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.66it/s]Epoch 12 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.65it/s]Epoch 12 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.65it/s]Epoch 12 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.67it/s]Epoch 12 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.66it/s]Epoch 12 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.63it/s]Epoch 12 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.58it/s]Epoch 12 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.58it/s]Epoch 12 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.54it/s]Epoch 12 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.53it/s]Epoch 12 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.55it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.56it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.55it/s]Epoch 12 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.56it/s]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.55it/s]Epoch 12 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.54it/s]Epoch 12 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.55it/s]Epoch 12 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.56it/s]Epoch 12 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.54it/s]Epoch 12 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.54it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.55it/s]Epoch 12 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.57it/s]Epoch 12 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.58it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.59it/s]Epoch 12 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.59it/s]Epoch 12 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.57it/s]Epoch 12 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.56it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 12 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.37it/s]Epoch 12 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.30it/s]Epoch 12 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.30it/s]Epoch 12 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.35it/s]Epoch 12 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.36it/s]Epoch 12 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.36it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:31,687][__main__][INFO] - Epoch 12: Val Loss: 0.9647, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5742387383608758, 'f1_weighted': 0.6968067832703915, 'precision_macro': 0.5703947368421053, 'recall_macro': 0.5833590138674885}
Epoch 13 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:31,793][__main__][INFO] - Train Epoch: 13 [0/51 (0%)]	Loss: 0.518757
Epoch 13 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.66it/s]Epoch 13 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.62it/s]Epoch 13 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.61it/s]Epoch 13 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.58it/s]Epoch 13 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.56it/s]Epoch 13 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.55it/s]Epoch 13 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.54it/s]Epoch 13 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.58it/s]Epoch 13 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.59it/s]Epoch 13 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.57it/s]Epoch 13 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.56it/s]Epoch 13 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.54it/s]Epoch 13 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.55it/s]Epoch 13 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.55it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.55it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.58it/s]Epoch 13 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.56it/s]Epoch 13 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.54it/s]Epoch 13 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.54it/s]Epoch 13 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.55it/s]Epoch 13 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.50it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.53it/s]Epoch 13 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.49it/s]Epoch 13 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.50it/s]Epoch 13 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.51it/s]Epoch 13 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.54it/s]Epoch 13 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.53it/s]Epoch 13 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.55it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.54it/s]Epoch 13 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.53it/s]Epoch 13 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.53it/s]Epoch 13 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.56it/s]Epoch 13 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.57it/s]Epoch 13 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.56it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.54it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.53it/s]Epoch 13 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.55it/s]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.56it/s]Epoch 13 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.58it/s]Epoch 13 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.55it/s]Epoch 13 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.55it/s]Epoch 13 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.55it/s]Epoch 13 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.57it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.57it/s]Epoch 13 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.58it/s]Epoch 13 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.57it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.54it/s]Epoch 13 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.54it/s]Epoch 13 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.55it/s]Epoch 13 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.57it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 13 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.25it/s]Epoch 13 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.22it/s]Epoch 13 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.33it/s]Epoch 13 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.36it/s]Epoch 13 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.37it/s]Epoch 13 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.39it/s]                                                               [2025-05-30 15:07:38,212][__main__][INFO] - Epoch 13: Val Loss: 0.7445, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6057084349069082, 'f1_weighted': 0.7173912341322212, 'precision_macro': 0.6923926767676768, 'recall_macro': 0.5978235747303544}
Epoch 14 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:38,321][__main__][INFO] - Train Epoch: 14 [0/51 (0%)]	Loss: 0.146901
Epoch 14 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.44it/s]Epoch 14 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.12it/s]Epoch 14 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.31it/s]Epoch 14 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.43it/s]Epoch 14 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.50it/s]Epoch 14 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.56it/s]Epoch 14 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.55it/s]Epoch 14 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.59it/s]Epoch 14 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.59it/s]Epoch 14 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.59it/s]Epoch 14 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.57it/s]Epoch 14 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.58it/s]Epoch 14 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.59it/s]Epoch 14 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.59it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.59it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.58it/s]Epoch 14 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.57it/s]Epoch 14 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.56it/s]Epoch 14 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.56it/s]Epoch 14 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.57it/s]Epoch 14 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.58it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.60it/s]Epoch 14 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.57it/s]Epoch 14 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.56it/s]Epoch 14 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.56it/s]Epoch 14 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.56it/s]Epoch 14 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.55it/s]Epoch 14 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.57it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.56it/s]Epoch 14 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.53it/s]Epoch 14 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.54it/s]Epoch 14 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 14 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.54it/s]Epoch 14 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.56it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.52it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.51it/s]Epoch 14 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.54it/s]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.55it/s]Epoch 14 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.54it/s]Epoch 14 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.57it/s]Epoch 14 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.57it/s]Epoch 14 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.57it/s]Epoch 14 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.57it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.57it/s]Epoch 14 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.58it/s]Epoch 14 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.59it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.61it/s]Epoch 14 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.59it/s]Epoch 14 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.57it/s]Epoch 14 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.57it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 14 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.18it/s]Epoch 14 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.23it/s]Epoch 14 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.33it/s]Epoch 14 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.37it/s]Epoch 14 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.39it/s]Epoch 14 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.41it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:44,737][__main__][INFO] - Epoch 14: Val Loss: 0.9491, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.39230769230769236, 'f1_weighted': 0.5511043412033512, 'precision_macro': 0.33527131782945735, 'recall_macro': 0.4730354391371341}
Epoch 15 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:44,847][__main__][INFO] - Train Epoch: 15 [0/51 (0%)]	Loss: 0.908639
Epoch 15 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.36it/s]Epoch 15 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.02it/s]Epoch 15 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.24it/s]Epoch 15 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.37it/s]Epoch 15 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.43it/s]Epoch 15 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.50it/s]Epoch 15 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.53it/s]Epoch 15 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.57it/s]Epoch 15 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.56it/s]Epoch 15 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.55it/s]Epoch 15 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.52it/s]Epoch 15 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.51it/s]Epoch 15 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.53it/s]Epoch 15 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.53it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.55it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.55it/s]Epoch 15 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.49it/s]Epoch 15 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.52it/s]Epoch 15 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.51it/s]Epoch 15 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.54it/s]Epoch 15 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.54it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.52it/s]Epoch 15 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 15 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.54it/s]Epoch 15 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.55it/s]Epoch 15 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.55it/s]Epoch 15 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.55it/s]Epoch 15 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.53it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.53it/s]Epoch 15 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.53it/s]Epoch 15 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.55it/s]Epoch 15 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 15 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.53it/s]Epoch 15 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.50it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.53it/s]Epoch 15 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.51it/s]Epoch 15 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.53it/s]Epoch 15 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.55it/s]Epoch 15 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.53it/s]Epoch 15 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.52it/s]Epoch 15 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.53it/s]Epoch 15 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.55it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.53it/s]Epoch 15 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.53it/s]Epoch 15 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.52it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.52it/s]Epoch 15 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.54it/s]Epoch 15 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.54it/s]Epoch 15 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.55it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 15 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.28it/s]Epoch 15 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.22it/s]Epoch 15 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.29it/s]Epoch 15 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.32it/s]Epoch 15 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.35it/s]Epoch 15 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.36it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:07:51,286][__main__][INFO] - Epoch 15: Val Loss: 1.1759, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.41863013698630136, 'f1_weighted': 0.5599674487996744, 'precision_macro': 0.3630952380952381, 'recall_macro': 0.4957627118644068}
Epoch 16 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:51,398][__main__][INFO] - Train Epoch: 16 [0/51 (0%)]	Loss: 1.239861
Epoch 16 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.25it/s]Epoch 16 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.08it/s]Epoch 16 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.33it/s]Epoch 16 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.45it/s]Epoch 16 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.44it/s]Epoch 16 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.49it/s]Epoch 16 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.52it/s]Epoch 16 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.55it/s]Epoch 16 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.54it/s]Epoch 16 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.52it/s]Epoch 16 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.51it/s]Epoch 16 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.51it/s]Epoch 16 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.51it/s]Epoch 16 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.53it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.56it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.55it/s]Epoch 16 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.55it/s]Epoch 16 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.54it/s]Epoch 16 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.55it/s]Epoch 16 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.56it/s]Epoch 16 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.56it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.57it/s]Epoch 16 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.56it/s]Epoch 16 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.56it/s]Epoch 16 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.54it/s]Epoch 16 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.56it/s]Epoch 16 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.56it/s]Epoch 16 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.55it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.56it/s]Epoch 16 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.52it/s]Epoch 16 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.53it/s]Epoch 16 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 16 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.53it/s]Epoch 16 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.54it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.55it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.54it/s]Epoch 16 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.52it/s]Epoch 16 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.55it/s]Epoch 16 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.55it/s]Epoch 16 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.55it/s]Epoch 16 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.53it/s]Epoch 16 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.52it/s]Epoch 16 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.53it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.55it/s]Epoch 16 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.54it/s]Epoch 16 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.55it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.54it/s]Epoch 16 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.51it/s]Epoch 16 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.54it/s]Epoch 16 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.53it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 16 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.23it/s]Epoch 16 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.23it/s]Epoch 16 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.29it/s]Epoch 16 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.33it/s]Epoch 16 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.36it/s]Epoch 16 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.37it/s]                                                               [2025-05-30 15:07:57,830][__main__][INFO] - Epoch 16: Val Loss: 0.6809, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6747785160575859, 'f1_weighted': 0.7478558819337083, 'precision_macro': 0.7333333333333333, 'recall_macro': 0.6390408320493066}
Epoch 17 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:07:57,944][__main__][INFO] - Train Epoch: 17 [0/51 (0%)]	Loss: 0.401779
Epoch 17 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.23it/s]Epoch 17 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.42it/s]Epoch 17 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.47it/s]Epoch 17 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.52it/s]Epoch 17 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.55it/s]Epoch 17 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.58it/s]Epoch 17 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.61it/s]Epoch 17 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.63it/s]Epoch 17 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.62it/s]Epoch 17 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.61it/s]Epoch 17 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.57it/s]Epoch 17 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.58it/s]Epoch 17 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.55it/s]Epoch 17 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.56it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.56it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.55it/s]Epoch 17 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.53it/s]Epoch 17 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.50it/s]Epoch 17 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.46it/s]Epoch 17 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.42it/s]Epoch 17 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.46it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.47it/s]Epoch 17 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 17 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.56it/s]Epoch 17 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.59it/s]Epoch 17 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.60it/s]Epoch 17 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.59it/s]Epoch 17 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.57it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.56it/s]Epoch 17 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.57it/s]Epoch 17 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.56it/s]Epoch 17 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.56it/s]Epoch 17 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.55it/s]Epoch 17 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.54it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.56it/s]Epoch 17 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.57it/s]Epoch 17 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.56it/s]Epoch 17 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.57it/s]Epoch 17 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.52it/s]Epoch 17 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.53it/s]Epoch 17 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.55it/s]Epoch 17 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.54it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.57it/s]Epoch 17 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.52it/s]Epoch 17 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.50it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.52it/s]Epoch 17 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.52it/s]Epoch 17 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.54it/s]Epoch 17 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.54it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 17 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.34it/s]Epoch 17 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.27it/s]Epoch 17 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.31it/s]Epoch 17 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.33it/s]Epoch 17 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.35it/s]Epoch 17 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.35it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:04,367][__main__][INFO] - Epoch 17: Val Loss: 0.9901, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4426850763807285, 'f1_weighted': 0.5730928086933252, 'precision_macro': 0.49625468164794007, 'recall_macro': 0.46280816640986133}
Epoch 18 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:04,480][__main__][INFO] - Train Epoch: 18 [0/51 (0%)]	Loss: 0.139455
Epoch 18 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.31it/s]Epoch 18 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.47it/s]Epoch 18 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.54it/s]Epoch 18 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.58it/s]Epoch 18 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.60it/s]Epoch 18 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.61it/s]Epoch 18 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.60it/s]Epoch 18 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.56it/s]Epoch 18 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.57it/s]Epoch 18 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.59it/s]Epoch 18 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.58it/s]Epoch 18 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.57it/s]Epoch 18 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.58it/s]Epoch 18 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.56it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.54it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.54it/s]Epoch 18 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.56it/s]Epoch 18 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.55it/s]Epoch 18 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.54it/s]Epoch 18 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.55it/s]Epoch 18 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.51it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.52it/s]Epoch 18 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 18 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.53it/s]Epoch 18 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.51it/s]Epoch 18 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.51it/s]Epoch 18 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.50it/s]Epoch 18 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.51it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.52it/s]Epoch 18 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.54it/s]Epoch 18 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.54it/s]Epoch 18 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 18 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.52it/s]Epoch 18 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.52it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.54it/s]Epoch 18 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.54it/s]Epoch 18 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.51it/s]Epoch 18 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.52it/s]Epoch 18 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.52it/s]Epoch 18 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.51it/s]Epoch 18 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.51it/s]Epoch 18 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.51it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.50it/s]Epoch 18 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.49it/s]Epoch 18 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.51it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.51it/s]Epoch 18 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.53it/s]Epoch 18 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.52it/s]Epoch 18 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.53it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 18 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.28it/s]Epoch 18 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.27it/s]Epoch 18 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.32it/s]Epoch 18 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.34it/s]Epoch 18 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.36it/s]Epoch 18 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.37it/s]                                                               [2025-05-30 15:08:10,908][__main__][INFO] - Epoch 18: Val Loss: 0.6969, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.716621863799283, 'f1_weighted': 0.7701923418148265, 'precision_macro': 0.7418956043956044, 'recall_macro': 0.7112480739599384}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748fb5a60>
<numpy.flatiter object at 0x7f3748fb5a60>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748dc83c0>
<numpy.flatiter object at 0x7f3748dc83c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748dc83c0>
<numpy.flatiter object at 0x7f3748dc83c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748dc89c0>
<numpy.flatiter object at 0x7f3748dc89c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748dc89c0>
<numpy.flatiter object at 0x7f3748dc89c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:08:10,968][__main__][INFO] - Saved best model at epoch 18 with accuracy: 0.7822
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:08:11,071][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 19 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:11,207][__main__][INFO] - Train Epoch: 19 [0/51 (0%)]	Loss: 0.263312
Epoch 19 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.74it/s]Epoch 19 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.64it/s]Epoch 19 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.61it/s]Epoch 19 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.60it/s]Epoch 19 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.62it/s]Epoch 19 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.62it/s]Epoch 19 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.66it/s]Epoch 19 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.66it/s]Epoch 19 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.68it/s]Epoch 19 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.67it/s]Epoch 19 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.66it/s]Epoch 19 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.65it/s]Epoch 19 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.67it/s]Epoch 19 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.67it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.69it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.68it/s]Epoch 19 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.71it/s]Epoch 19 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 19 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.70it/s]Epoch 19 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.72it/s]Epoch 19 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.66it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.61it/s]Epoch 19 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.63it/s]Epoch 19 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.64it/s]Epoch 19 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.64it/s]Epoch 19 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.64it/s]Epoch 19 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.64it/s]Epoch 19 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.63it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.61it/s]Epoch 19 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.58it/s]Epoch 19 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.57it/s]Epoch 19 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.56it/s]Epoch 19 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.58it/s]Epoch 19 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.57it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.54it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.52it/s]Epoch 19 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.54it/s]Epoch 19 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.56it/s]Epoch 19 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.57it/s]Epoch 19 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.58it/s]Epoch 19 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.56it/s]Epoch 19 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.55it/s]Epoch 19 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.50it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.53it/s]Epoch 19 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.52it/s]Epoch 19 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.53it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.50it/s]Epoch 19 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.51it/s]Epoch 19 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.53it/s]Epoch 19 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.53it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 19 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.32it/s]Epoch 19 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.26it/s]Epoch 19 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.32it/s]Epoch 19 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.32it/s]Epoch 19 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.36it/s]Epoch 19 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.35it/s]                                                               [2025-05-30 15:08:17,603][__main__][INFO] - Epoch 19: Val Loss: 0.7290, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5477121408463291, 'f1_weighted': 0.6597300598731396, 'precision_macro': 0.5916666666666667, 'recall_macro': 0.5622881355932203}
Epoch 20 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:17,709][__main__][INFO] - Train Epoch: 20 [0/51 (0%)]	Loss: 0.385822
Epoch 20 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.71it/s]Epoch 20 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.70it/s]Epoch 20 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.66it/s]Epoch 20 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.64it/s]Epoch 20 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.57it/s]Epoch 20 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.56it/s]Epoch 20 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.57it/s]Epoch 20 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.59it/s]Epoch 20 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.59it/s]Epoch 20 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.57it/s]Epoch 20 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.56it/s]Epoch 20 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.55it/s]Epoch 20 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.54it/s]Epoch 20 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.54it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.55it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.57it/s]Epoch 20 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.55it/s]Epoch 20 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.53it/s]Epoch 20 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.54it/s]Epoch 20 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.53it/s]Epoch 20 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.54it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.55it/s]Epoch 20 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.54it/s]Epoch 20 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.51it/s]Epoch 20 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.52it/s]Epoch 20 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.51it/s]Epoch 20 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.53it/s]Epoch 20 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.54it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.52it/s]Epoch 20 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.53it/s]Epoch 20 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.52it/s]Epoch 20 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.54it/s]Epoch 20 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.54it/s]Epoch 20 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.52it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.51it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.51it/s]Epoch 20 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.49it/s]Epoch 20 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.53it/s]Epoch 20 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.54it/s]Epoch 20 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.53it/s]Epoch 20 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.53it/s]Epoch 20 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.53it/s]Epoch 20 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.53it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.52it/s]Epoch 20 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.50it/s]Epoch 20 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.51it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.52it/s]Epoch 20 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.51it/s]Epoch 20 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.55it/s]Epoch 20 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.57it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 20 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.24it/s]Epoch 20 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.17it/s]Epoch 20 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.26it/s]Epoch 20 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.25it/s]Epoch 20 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 20 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.29it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:24,145][__main__][INFO] - Epoch 20: Val Loss: 0.7454, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5817389582095465, 'f1_weighted': 0.7001272676287237, 'precision_macro': 0.5900546821599453, 'recall_macro': 0.5895608628659477}
Epoch 21 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:24,250][__main__][INFO] - Train Epoch: 21 [0/51 (0%)]	Loss: 0.413163
Epoch 21 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.67it/s]Epoch 21 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.48it/s]Epoch 21 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.54it/s]Epoch 21 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.52it/s]Epoch 21 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.54it/s]Epoch 21 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.57it/s]Epoch 21 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.58it/s]Epoch 21 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.56it/s]Epoch 21 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.47it/s]Epoch 21 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.50it/s]Epoch 21 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.52it/s]Epoch 21 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.54it/s]Epoch 21 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.52it/s]Epoch 21 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.48it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.50it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.54it/s]Epoch 21 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.54it/s]Epoch 21 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.54it/s]Epoch 21 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.52it/s]Epoch 21 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.52it/s]Epoch 21 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.52it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.56it/s]Epoch 21 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.56it/s]Epoch 21 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.54it/s]Epoch 21 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.49it/s]Epoch 21 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.49it/s]Epoch 21 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.53it/s]Epoch 21 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.53it/s]Epoch 21 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.52it/s]Epoch 21 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 21 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.55it/s]Epoch 21 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.55it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.53it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.53it/s]Epoch 21 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.51it/s]Epoch 21 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.52it/s]Epoch 21 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.52it/s]Epoch 21 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.55it/s]Epoch 21 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.54it/s]Epoch 21 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.51it/s]Epoch 21 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.52it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.51it/s]Epoch 21 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.54it/s]Epoch 21 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.55it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.54it/s]Epoch 21 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.52it/s]Epoch 21 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.52it/s]Epoch 21 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.54it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 21 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.30it/s]Epoch 21 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.25it/s]Epoch 21 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.31it/s]Epoch 21 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.35it/s]Epoch 21 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.37it/s]Epoch 21 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.36it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:30,685][__main__][INFO] - Epoch 21: Val Loss: 0.8354, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5237423991155334, 'f1_weighted': 0.665818323125845, 'precision_macro': 0.5395833333333333, 'recall_macro': 0.5603235747303544}
Epoch 22 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:30,797][__main__][INFO] - Train Epoch: 22 [0/51 (0%)]	Loss: 0.505182
Epoch 22 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.37it/s]Epoch 22 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.18it/s]Epoch 22 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.32it/s]Epoch 22 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.45it/s]Epoch 22 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.42it/s]Epoch 22 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.51it/s]Epoch 22 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.55it/s]Epoch 22 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.51it/s]Epoch 22 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.50it/s]Epoch 22 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.54it/s]Epoch 22 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.56it/s]Epoch 22 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.59it/s]Epoch 22 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.58it/s]Epoch 22 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.56it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.54it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.54it/s]Epoch 22 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.56it/s]Epoch 22 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.55it/s]Epoch 22 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.55it/s]Epoch 22 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.54it/s]Epoch 22 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.49it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.52it/s]Epoch 22 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 22 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.53it/s]Epoch 22 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.49it/s]Epoch 22 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.49it/s]Epoch 22 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.50it/s]Epoch 22 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.52it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.54it/s]Epoch 22 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.53it/s]Epoch 22 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.53it/s]Epoch 22 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.51it/s]Epoch 22 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.50it/s]Epoch 22 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.52it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.53it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.52it/s]Epoch 22 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.52it/s]Epoch 22 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.51it/s]Epoch 22 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.55it/s]Epoch 22 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.54it/s]Epoch 22 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.56it/s]Epoch 22 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.56it/s]Epoch 22 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.55it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.53it/s]Epoch 22 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.54it/s]Epoch 22 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.54it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.53it/s]Epoch 22 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.53it/s]Epoch 22 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.52it/s]Epoch 22 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.52it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 22 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.23it/s]Epoch 22 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.24it/s]Epoch 22 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.28it/s]Epoch 22 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.32it/s]Epoch 22 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.35it/s]Epoch 22 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.35it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:37,235][__main__][INFO] - Epoch 22: Val Loss: 0.8993, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4426850763807285, 'f1_weighted': 0.5730928086933252, 'precision_macro': 0.49625468164794007, 'recall_macro': 0.46280816640986133}
Epoch 23 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:37,342][__main__][INFO] - Train Epoch: 23 [0/51 (0%)]	Loss: 0.921377
Epoch 23 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.54it/s]Epoch 23 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.49it/s]Epoch 23 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.56it/s]Epoch 23 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.56it/s]Epoch 23 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.56it/s]Epoch 23 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.57it/s]Epoch 23 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.56it/s]Epoch 23 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.58it/s]Epoch 23 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.55it/s]Epoch 23 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.55it/s]Epoch 23 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.53it/s]Epoch 23 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.51it/s]Epoch 23 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.52it/s]Epoch 23 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.53it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.50it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.51it/s]Epoch 23 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.50it/s]Epoch 23 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.51it/s]Epoch 23 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.53it/s]Epoch 23 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.53it/s]Epoch 23 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.54it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.54it/s]Epoch 23 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.51it/s]Epoch 23 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.52it/s]Epoch 23 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.54it/s]Epoch 23 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.54it/s]Epoch 23 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.53it/s]Epoch 23 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.53it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.52it/s]Epoch 23 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.50it/s]Epoch 23 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.52it/s]Epoch 23 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 23 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.54it/s]Epoch 23 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.55it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.56it/s]Epoch 23 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.54it/s]Epoch 23 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.56it/s]Epoch 23 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.51it/s]Epoch 23 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.49it/s]Epoch 23 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.49it/s]Epoch 23 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.32it/s]Epoch 23 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.37it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.39it/s]Epoch 23 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.44it/s]Epoch 23 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.48it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.50it/s]Epoch 23 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.51it/s]Epoch 23 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.50it/s]Epoch 23 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.50it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 23 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.21it/s]Epoch 23 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.23it/s]Epoch 23 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.31it/s]Epoch 23 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.33it/s]Epoch 23 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.35it/s]Epoch 23 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.35it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:43,786][__main__][INFO] - Epoch 23: Val Loss: 0.8798, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.427796803652968, 'f1_weighted': 0.5639608481396085, 'precision_macro': 0.3782051282051282, 'recall_macro': 0.4957627118644068}
Epoch 24 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:43,893][__main__][INFO] - Train Epoch: 24 [0/51 (0%)]	Loss: 0.671384
Epoch 24 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.60it/s]Epoch 24 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.60it/s]Epoch 24 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.60it/s]Epoch 24 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.62it/s]Epoch 24 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.61it/s]Epoch 24 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.59it/s]Epoch 24 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.57it/s]Epoch 24 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.59it/s]Epoch 24 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.59it/s]Epoch 24 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.61it/s]Epoch 24 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.59it/s]Epoch 24 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.58it/s]Epoch 24 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.52it/s]Epoch 24 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.53it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.55it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.55it/s]Epoch 24 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.57it/s]Epoch 24 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.57it/s]Epoch 24 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.52it/s]Epoch 24 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.50it/s]Epoch 24 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.52it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.54it/s]Epoch 24 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.56it/s]Epoch 24 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.54it/s]Epoch 24 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.53it/s]Epoch 24 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.53it/s]Epoch 24 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.51it/s]Epoch 24 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.32it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.37it/s]Epoch 24 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.44it/s]Epoch 24 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.48it/s]Epoch 24 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.51it/s]Epoch 24 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.51it/s]Epoch 24 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.50it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.51it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.53it/s]Epoch 24 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.57it/s]Epoch 24 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.58it/s]Epoch 24 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.53it/s]Epoch 24 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.51it/s]Epoch 24 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.51it/s]Epoch 24 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.54it/s]Epoch 24 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.54it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.54it/s]Epoch 24 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.54it/s]Epoch 24 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.53it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.51it/s]Epoch 24 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.53it/s]Epoch 24 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.53it/s]Epoch 24 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.50it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 24 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.28it/s]Epoch 24 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.23it/s]Epoch 24 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 24 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.28it/s]Epoch 24 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 24 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.31it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:50,332][__main__][INFO] - Epoch 24: Val Loss: 0.9374, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.44186972447842016, 'f1_weighted': 0.6307903604502829, 'precision_macro': 0.5619586942038641, 'recall_macro': 0.43470724191063176}
Epoch 25 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:50,443][__main__][INFO] - Train Epoch: 25 [0/51 (0%)]	Loss: 1.752562
Epoch 25 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.41it/s]Epoch 25 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.27it/s]Epoch 25 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.39it/s]Epoch 25 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.45it/s]Epoch 25 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.50it/s]Epoch 25 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.54it/s]Epoch 25 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.54it/s]Epoch 25 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.55it/s]Epoch 25 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.53it/s]Epoch 25 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.53it/s]Epoch 25 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.52it/s]Epoch 25 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.52it/s]Epoch 25 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.52it/s]Epoch 25 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.56it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.56it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.54it/s]Epoch 25 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.48it/s]Epoch 25 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.50it/s]Epoch 25 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.50it/s]Epoch 25 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.51it/s]Epoch 25 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.51it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.49it/s]Epoch 25 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.52it/s]Epoch 25 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.52it/s]Epoch 25 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.54it/s]Epoch 25 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.53it/s]Epoch 25 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.51it/s]Epoch 25 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.50it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.50it/s]Epoch 25 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.50it/s]Epoch 25 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.51it/s]Epoch 25 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.53it/s]Epoch 25 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.54it/s]Epoch 25 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.54it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.57it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.58it/s]Epoch 25 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.56it/s]Epoch 25 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.55it/s]Epoch 25 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.53it/s]Epoch 25 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.53it/s]Epoch 25 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.55it/s]Epoch 25 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.55it/s]Epoch 25 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.55it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.53it/s]Epoch 25 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.48it/s]Epoch 25 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.50it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.50it/s]Epoch 25 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.52it/s]Epoch 25 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.51it/s]Epoch 25 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.50it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 25 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.12it/s]Epoch 25 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.17it/s]Epoch 25 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.24it/s]Epoch 25 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.29it/s]Epoch 25 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 25 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.33it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:08:56,888][__main__][INFO] - Epoch 25: Val Loss: 0.7051, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.5923209221854813, 'f1_weighted': 0.70524289967515, 'precision_macro': 0.6164044289044289, 'recall_macro': 0.6040254237288136}
Epoch 26 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:08:57,001][__main__][INFO] - Train Epoch: 26 [0/51 (0%)]	Loss: 0.335287
Epoch 26 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.00it/s]Epoch 26 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.36it/s]Epoch 26 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.47it/s]Epoch 26 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.47it/s]Epoch 26 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.48it/s]Epoch 26 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.52it/s]Epoch 26 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.53it/s]Epoch 26 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.57it/s]Epoch 26 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.55it/s]Epoch 26 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.53it/s]Epoch 26 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.52it/s]Epoch 26 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.52it/s]Epoch 26 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.52it/s]Epoch 26 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.50it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.49it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.48it/s]Epoch 26 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.48it/s]Epoch 26 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.49it/s]Epoch 26 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.53it/s]Epoch 26 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.52it/s]Epoch 26 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.51it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.52it/s]Epoch 26 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 26 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.53it/s]Epoch 26 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.50it/s]Epoch 26 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.49it/s]Epoch 26 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.49it/s]Epoch 26 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.47it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.50it/s]Epoch 26 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.50it/s]Epoch 26 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.51it/s]Epoch 26 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.50it/s]Epoch 26 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.51it/s]Epoch 26 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.54it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.55it/s]Epoch 26 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.55it/s]Epoch 26 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.51it/s]Epoch 26 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.50it/s]Epoch 26 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.52it/s]Epoch 26 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.52it/s]Epoch 26 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.52it/s]Epoch 26 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.51it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.50it/s]Epoch 26 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.50it/s]Epoch 26 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.50it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.50it/s]Epoch 26 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.50it/s]Epoch 26 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.49it/s]Epoch 26 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.50it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 26 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.29it/s]Epoch 26 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.14it/s]Epoch 26 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.23it/s]Epoch 26 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 26 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 26 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.30it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:03,450][__main__][INFO] - Epoch 26: Val Loss: 0.7629, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6, 'f1_weighted': 0.7168316831683169, 'precision_macro': 0.609408795962509, 'recall_macro': 0.6000963020030817}
[2025-05-30 15:09:03,452][__main__][INFO] - Early stopping triggered after 26 epochs
[2025-05-30 15:09:03,452][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7822
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374922cdc0>
<numpy.flatiter object at 0x7f374922cdc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3749210ce0>
<numpy.flatiter object at 0x7f3749210ce0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3749210ce0>
<numpy.flatiter object at 0x7f3749210ce0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37492112e0>
<numpy.flatiter object at 0x7f37492112e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492112e0>
<numpy.flatiter object at 0x7f37492112e0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÇ
wandb:        Validation Accuracy ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñá‚ñà‚ñÑ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá
wandb:            Validation Loss ‚ñà‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñá‚ñÅ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ
wandb:        Validation accuracy ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñá‚ñà‚ñÑ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
wandb:     Validation f1_weighted ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá
wandb: Validation precision_macro ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ
wandb:    Validation recall_macro ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.78218
wandb:                 Train Loss 0.33529
wandb:        Validation Accuracy 0.76238
wandb:            Validation Loss 0.76288
wandb:        Validation accuracy 0.76238
wandb:        Validation f1_macro 0.6
wandb:     Validation f1_weighted 0.71683
wandb: Validation precision_macro 0.60941
wandb:    Validation recall_macro 0.6001
wandb: 
wandb: üöÄ View run hopeful-sweep-1 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/sg2e92ty
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_150600-sg2e92ty/logs
wandb: Agent Starting Run: q7owujig with config:
wandb: 	Fdropout_rate: 0.13507024605009088
wandb: 	Fnum_heads: 1
wandb: 	Fnum_layers: 5
wandb: 	Mdropout_rate: 0.14453836580667578
wandb: 	Mnum_layers: 1
wandb: 	batch_size: 32
wandb: 	learning_rate: 0.03557772637861391
wandb: 	pretrained_model_name: emilyalsentzer/Bio_ClinicalBERT
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_150908-q7owujig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/q7owujig
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:13,137][__main__][INFO] - Train Epoch: 0 [0/13 (0%)]	Loss: 1.871353
Epoch 0 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.75it/s]Epoch 0 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 0 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 0 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.87it/s]Epoch 0 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.87it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.87it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 0 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 0 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.02it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s]Epoch 0 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:18,265][__main__][INFO] - Epoch 0: Val Loss: 31.1736, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3812273f10>
<numpy.flatiter object at 0x7f3812273f10>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f6aec0>
<numpy.flatiter object at 0x7f3811f6aec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f6aec0>
<numpy.flatiter object at 0x7f3811f6aec0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38122b6450>
<numpy.flatiter object at 0x7f38122b6450>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38122b6450>
<numpy.flatiter object at 0x7f38122b6450>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:09:18,327][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:09:18,424][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:09:18,455][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:18,805][__main__][INFO] - Train Epoch: 1 [0/13 (0%)]	Loss: 28.978270
Epoch 1 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.86it/s]Epoch 1 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.88it/s]Epoch 1 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.88it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.88it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.89it/s]Epoch 1 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.89it/s]Epoch 1 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.88it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.88it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.88it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.87it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 1 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 1 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.01it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s]Epoch 1 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:23,917][__main__][INFO] - Epoch 1: Val Loss: 6.5691, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:24,277][__main__][INFO] - Train Epoch: 2 [0/13 (0%)]	Loss: 6.145930
Epoch 2 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 2 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 2 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 2 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 2 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.87it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 2 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 2 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.00it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 2 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:29,412][__main__][INFO] - Epoch 2: Val Loss: 1.8679, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:29,768][__main__][INFO] - Train Epoch: 3 [0/13 (0%)]	Loss: 0.817595
Epoch 3 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 3 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.85it/s]Epoch 3 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 3 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 3 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.87it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 3 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 3 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.00it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s]Epoch 3 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:34,898][__main__][INFO] - Epoch 3: Val Loss: 1.2333, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:35,249][__main__][INFO] - Train Epoch: 4 [0/13 (0%)]	Loss: 0.989286
Epoch 4 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.86it/s]Epoch 4 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 4 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.87it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.87it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.87it/s]Epoch 4 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 4 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 4 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 4 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 4 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:40,387][__main__][INFO] - Epoch 4: Val Loss: 1.2659, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:40,738][__main__][INFO] - Train Epoch: 5 [0/13 (0%)]	Loss: 1.377867
Epoch 5 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.87it/s]Epoch 5 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 5 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 5 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 5 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 5 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 5 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:45,892][__main__][INFO] - Epoch 5: Val Loss: 1.1355, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2113289760348584, 'f1_weighted': 0.4651955391617593, 'precision_macro': 0.19262917933130697, 'recall_macro': 0.2625}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811f45b20>
<numpy.flatiter object at 0x7f3811f45b20>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f6e4c0>
<numpy.flatiter object at 0x7f3811f6e4c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f6e4c0>
<numpy.flatiter object at 0x7f3811f6e4c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f6eac0>
<numpy.flatiter object at 0x7f3811f6eac0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f6eac0>
<numpy.flatiter object at 0x7f3811f6eac0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:09:45,971][__main__][INFO] - Saved best model at epoch 5 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:09:46,072][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 6 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:46,455][__main__][INFO] - Train Epoch: 6 [0/13 (0%)]	Loss: 0.686712
Epoch 6 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 6 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 6 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 6 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 6 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 6 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 6 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 6 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:51,620][__main__][INFO] - Epoch 6: Val Loss: 1.1562, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:51,974][__main__][INFO] - Train Epoch: 7 [0/13 (0%)]	Loss: 0.994359
Epoch 7 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 7 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.86it/s]Epoch 7 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 7 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 7 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 7 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 7 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 7 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:09:57,125][__main__][INFO] - Epoch 7: Val Loss: 1.1187, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:09:57,483][__main__][INFO] - Train Epoch: 8 [0/13 (0%)]	Loss: 1.004929
Epoch 8 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 8 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 8 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 8 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 8 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 8 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 8 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 8 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:02,644][__main__][INFO] - Epoch 8: Val Loss: 1.0902, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.26482116609505146, 'f1_weighted': 0.472560043853479, 'precision_macro': 0.4005102040816326, 'recall_macro': 0.29545454545454547}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702648a80>
<numpy.flatiter object at 0x7f3702648a80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702670940>
<numpy.flatiter object at 0x7f3702670940>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702670940>
<numpy.flatiter object at 0x7f3702670940>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702670f40>
<numpy.flatiter object at 0x7f3702670f40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702670f40>
<numpy.flatiter object at 0x7f3702670f40>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:10:02,710][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.6040
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:10:02,841][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:03,233][__main__][INFO] - Train Epoch: 9 [0/13 (0%)]	Loss: 1.150795
Epoch 9 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 9 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 9 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 9 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 9 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 9 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 9 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 9 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:08,396][__main__][INFO] - Epoch 9: Val Loss: 1.0407, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.41287078934137755, 'f1_weighted': 0.5663585363061192, 'precision_macro': 0.4550438596491228, 'recall_macro': 0.4047380585516179}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f46916c0>
<numpy.flatiter object at 0x7f36f46916c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381178c210>
<numpy.flatiter object at 0x7f381178c210>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381178c210>
<numpy.flatiter object at 0x7f381178c210>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f381178c810>
<numpy.flatiter object at 0x7f381178c810>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381178c810>
<numpy.flatiter object at 0x7f381178c810>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:10:08,458][__main__][INFO] - Saved best model at epoch 9 with accuracy: 0.6139
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:10:08,554][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 10 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:08,938][__main__][INFO] - Train Epoch: 10 [0/13 (0%)]	Loss: 0.868186
Epoch 10 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 10 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 10 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 10 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 10 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 10 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:10:14,104][__main__][INFO] - Epoch 10: Val Loss: 1.0316, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3758701154880557, 'f1_weighted': 0.5941729673679281, 'precision_macro': 0.547783251231527, 'recall_macro': 0.40556625577812017}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f4668e90>
<numpy.flatiter object at 0x7f36f4668e90>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63a6c40>
<numpy.flatiter object at 0x7f36f63a6c40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63a6c40>
<numpy.flatiter object at 0x7f36f63a6c40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63a7240>
<numpy.flatiter object at 0x7f36f63a7240>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63a7240>
<numpy.flatiter object at 0x7f36f63a7240>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:10:14,164][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:10:14,263][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:10:14,294][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:14,645][__main__][INFO] - Train Epoch: 11 [0/13 (0%)]	Loss: 0.831675
Epoch 11 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.86it/s]Epoch 11 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.86it/s]Epoch 11 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 11 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 11 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 11 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 11 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:19,819][__main__][INFO] - Epoch 11: Val Loss: 1.0284, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.38196347031963473, 'f1_weighted': 0.5618156336181563, 'precision_macro': 0.49166666666666664, 'recall_macro': 0.3741718027734977}
Epoch 12 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:20,175][__main__][INFO] - Train Epoch: 12 [0/13 (0%)]	Loss: 0.589201
Epoch 12 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 12 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 12 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 12 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 12 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 12 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 12 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:25,347][__main__][INFO] - Epoch 12: Val Loss: 1.1535, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.32298657718120805, 'f1_weighted': 0.5170775466808426, 'precision_macro': 0.36388888888888893, 'recall_macro': 0.34090909090909094}
Epoch 13 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:25,710][__main__][INFO] - Train Epoch: 13 [0/13 (0%)]	Loss: 0.836972
Epoch 13 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 13 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 13 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 13 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 13 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 13 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 13 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:30,895][__main__][INFO] - Epoch 13: Val Loss: 1.0925, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.3004901960784314, 'f1_weighted': 0.5320714424383615, 'precision_macro': 0.4900332225913621, 'recall_macro': 0.3184899845916795}
Epoch 14 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:31,251][__main__][INFO] - Train Epoch: 14 [0/13 (0%)]	Loss: 0.674464
Epoch 14 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 14 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 14 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 14 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 14 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 14 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 14 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:10:36,438][__main__][INFO] - Epoch 14: Val Loss: 0.9763, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.4614766940853897, 'f1_weighted': 0.636985414170089, 'precision_macro': 0.5627326880119137, 'recall_macro': 0.44493451463790445}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f4667b40>
<numpy.flatiter object at 0x7f36f4667b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37026845c0>
<numpy.flatiter object at 0x7f37026845c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37026845c0>
<numpy.flatiter object at 0x7f37026845c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702684bc0>
<numpy.flatiter object at 0x7f3702684bc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702684bc0>
<numpy.flatiter object at 0x7f3702684bc0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:10:36,735][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.6931
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:10:36,829][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:37,212][__main__][INFO] - Train Epoch: 15 [0/13 (0%)]	Loss: 0.559953
Epoch 15 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 15 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 15 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 15 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 15 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 15 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 15 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:42,394][__main__][INFO] - Epoch 15: Val Loss: 0.8983, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5213414634146342, 'f1_weighted': 0.6753199710214923, 'precision_macro': 0.5454990215264188, 'recall_macro': 0.5194144838212634}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38117b0d70>
<numpy.flatiter object at 0x7f38117b0d70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38117b0d70>
<numpy.flatiter object at 0x7f38117b0d70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38117b0d70>
<numpy.flatiter object at 0x7f38117b0d70>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38117b0d70>
<numpy.flatiter object at 0x7f38117b0d70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38117b0d70>
<numpy.flatiter object at 0x7f38117b0d70>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:10:42,457][__main__][INFO] - Saved best model at epoch 15 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:10:42,557][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 16 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:42,943][__main__][INFO] - Train Epoch: 16 [0/13 (0%)]	Loss: 0.490857
Epoch 16 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 16 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 16 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 16 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 16 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 16 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 16 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 16 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 16 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 16 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 16 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:10:48,136][__main__][INFO] - Epoch 16: Val Loss: 1.1264, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.47841478696741857, 'f1_weighted': 0.6272860368743641, 'precision_macro': 0.5058397683397683, 'recall_macro': 0.47343990755007703}
Epoch 17 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:48,500][__main__][INFO] - Train Epoch: 17 [0/13 (0%)]	Loss: 0.526483
Epoch 17 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 17 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 17 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 17 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 17 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 17 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 17 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 17 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 17 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 17 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 17 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:10:53,699][__main__][INFO] - Epoch 17: Val Loss: 0.8259, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6062799394257812, 'f1_weighted': 0.7194640729950548, 'precision_macro': 0.704861111111111, 'recall_macro': 0.5875963020030817}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f7867290>
<numpy.flatiter object at 0x7f36f7867290>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f4c530>
<numpy.flatiter object at 0x7f3811f4c530>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f4c530>
<numpy.flatiter object at 0x7f3811f4c530>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f4c530>
<numpy.flatiter object at 0x7f3811f4c530>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f4c530>
<numpy.flatiter object at 0x7f3811f4c530>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:10:53,761][__main__][INFO] - Saved best model at epoch 17 with accuracy: 0.7525
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:10:53,863][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 18 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:54,249][__main__][INFO] - Train Epoch: 18 [0/13 (0%)]	Loss: 0.504339
Epoch 18 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 18 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 18 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 18 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 18 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 18 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 18 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 18 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 18 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 18 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 18 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:10:59,435][__main__][INFO] - Epoch 18: Val Loss: 0.7590, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6504201680672269, 'f1_weighted': 0.7016889924286547, 'precision_macro': 0.6641414141414141, 'recall_macro': 0.6403697996918336}
Epoch 19 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:10:59,792][__main__][INFO] - Train Epoch: 19 [0/13 (0%)]	Loss: 0.427380
Epoch 19 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 19 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 19 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 19 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 19 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 19 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 19 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 19 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 19 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 19 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 19 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:11:04,989][__main__][INFO] - Epoch 19: Val Loss: 0.9955, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5641068784493202, 'f1_weighted': 0.6907623189294297, 'precision_macro': 0.6089511754068716, 'recall_macro': 0.5483436055469955}
Epoch 20 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:05,348][__main__][INFO] - Train Epoch: 20 [0/13 (0%)]	Loss: 0.479387
Epoch 20 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 20 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 20 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 20 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 20 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 20 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 20 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 20 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 20 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 20 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.88it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.93it/s]Epoch 20 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.94it/s]                                                             [2025-05-30 15:11:10,563][__main__][INFO] - Epoch 20: Val Loss: 0.8978, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.6158295214637579, 'f1_weighted': 0.6642660307550812, 'precision_macro': 0.6670447670901392, 'recall_macro': 0.6049306625577813}
Epoch 21 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:10,919][__main__][INFO] - Train Epoch: 21 [0/13 (0%)]	Loss: 0.596333
Epoch 21 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 21 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 21 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 21 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 21 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 21 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 21 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 21 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 21 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 21 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 21 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:11:16,126][__main__][INFO] - Epoch 21: Val Loss: 0.7925, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.6093511268143621, 'f1_weighted': 0.7025178883434561, 'precision_macro': 0.6429512516469038, 'recall_macro': 0.5953389830508474}
Epoch 22 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:16,489][__main__][INFO] - Train Epoch: 22 [0/13 (0%)]	Loss: 0.418864
Epoch 22 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 22 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 22 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 22 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 22 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 22 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 22 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 22 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 22 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 22 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 22 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:11:21,702][__main__][INFO] - Epoch 22: Val Loss: 0.9068, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5599376114081996, 'f1_weighted': 0.6851891071460087, 'precision_macro': 0.5558106277284359, 'recall_macro': 0.5810862865947611}
Epoch 23 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:22,066][__main__][INFO] - Train Epoch: 23 [0/13 (0%)]	Loss: 0.356197
Epoch 23 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 23 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 23 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 23 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 23 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 23 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 23 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 23 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 23 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 23 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 23 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:11:27,270][__main__][INFO] - Epoch 23: Val Loss: 1.0287, Accuracy: 0.5050, Metrics: {'accuracy': 0.504950495049505, 'f1_macro': 0.5514145731776279, 'f1_weighted': 0.5161416553151694, 'precision_macro': 0.56993006993007, 'recall_macro': 0.6480739599383668}
Epoch 24 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:27,635][__main__][INFO] - Train Epoch: 24 [0/13 (0%)]	Loss: 0.907331
Epoch 24 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 24 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 24 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 24 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 24 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 24 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 24 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 24 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 24 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 24 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 24 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:11:32,838][__main__][INFO] - Epoch 24: Val Loss: 0.8091, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6368366927190456, 'f1_weighted': 0.7208596877787325, 'precision_macro': 0.6927632226928001, 'recall_macro': 0.6140408320493066}
Epoch 25 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:33,195][__main__][INFO] - Train Epoch: 25 [0/13 (0%)]	Loss: 0.441445
Epoch 25 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 25 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 25 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 25 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 25 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 25 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 25 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 25 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 25 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 25 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 25 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:11:38,407][__main__][INFO] - Epoch 25: Val Loss: 0.8720, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.6039855072463768, 'f1_weighted': 0.697775864542976, 'precision_macro': 0.6201975108225108, 'recall_macro': 0.5993644067796611}
Epoch 26 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:38,771][__main__][INFO] - Train Epoch: 26 [0/13 (0%)]	Loss: 0.214984
Epoch 26 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 26 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 26 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 26 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 26 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 26 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 26 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 26 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 26 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 26 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 26 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:11:43,994][__main__][INFO] - Epoch 26: Val Loss: 0.7967, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5936868686868687, 'f1_weighted': 0.7085608560856086, 'precision_macro': 0.8151223776223777, 'recall_macro': 0.5812981510015408}
Epoch 27 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:44,351][__main__][INFO] - Train Epoch: 27 [0/13 (0%)]	Loss: 0.276061
Epoch 27 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 27 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 27 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 27 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 27 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 27 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 27 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 27 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 27 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 27 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 27 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 27 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 27 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 27 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 27 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:11:49,557][__main__][INFO] - Epoch 27: Val Loss: 0.9179, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6169312169312169, 'f1_weighted': 0.713960919901514, 'precision_macro': 0.8508771929824561, 'recall_macro': 0.5895608628659477}
Epoch 28 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:11:49,914][__main__][INFO] - Train Epoch: 28 [0/13 (0%)]	Loss: 0.637235
Epoch 28 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 28 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 28 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 28 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 28 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 28 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 28 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 28 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 28 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 28 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 28 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 28 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 28 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 28 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 28 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:11:55,122][__main__][INFO] - Epoch 28: Val Loss: 0.9910, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5366588599594313, 'f1_weighted': 0.6777604119317948, 'precision_macro': 0.5491071428571428, 'recall_macro': 0.5379044684129429}
[2025-05-30 15:11:55,124][__main__][INFO] - Early stopping triggered after 28 epochs
[2025-05-30 15:11:55,124][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7525
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f7867290>
<numpy.flatiter object at 0x7f36f7867290>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f4b750>
<numpy.flatiter object at 0x7f3811f4b750>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f4b750>
<numpy.flatiter object at 0x7f3811f4b750>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f4c530>
<numpy.flatiter object at 0x7f3811f4c530>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f4c530>
<numpy.flatiter object at 0x7f3811f4c530>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            Validation Loss ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        Validation f1_macro ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá
wandb:     Validation f1_weighted ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: Validation precision_macro ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñÖ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.75248
wandb:                 Train Loss 0.63723
wandb:        Validation Accuracy 0.72277
wandb:            Validation Loss 0.99099
wandb:        Validation accuracy 0.72277
wandb:        Validation f1_macro 0.53666
wandb:     Validation f1_weighted 0.67776
wandb: Validation precision_macro 0.54911
wandb:    Validation recall_macro 0.5379
wandb: 
wandb: üöÄ View run firm-sweep-2 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/q7owujig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_150908-q7owujig/logs
wandb: Agent Starting Run: skywvhtb with config:
wandb: 	Fdropout_rate: 0.38366479610803406
wandb: 	Fnum_heads: 1
wandb: 	Fnum_layers: 8
wandb: 	Mdropout_rate: 0.3637347797942963
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 8
wandb: 	learning_rate: 0.037069459471940305
wandb: 	pretrained_model_name: nvidia/biomegatron-345m-uncased
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_151201-skywvhtb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/skywvhtb
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
wandb:                                                                                
wandb: üöÄ View run leafy-sweep-3 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/skywvhtb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_151201-skywvhtb/logs
wandb: ERROR Run skywvhtb errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 406, in hf_raise_for_status
wandb: ERROR     response.raise_for_status()
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
wandb: ERROR     raise HTTPError(http_error_msg, response=self)
wandb: ERROR requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 342, in cached_file
wandb: ERROR     resolved_file = hf_hub_download(
wandb: ERROR                     ^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
wandb: ERROR     return _hf_hub_download_to_cache_dir(
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
wandb: ERROR     _raise_on_head_call_error(head_call_error, force_download, local_files_only)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1482, in _raise_on_head_call_error
wandb: ERROR     raise head_call_error
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
wandb: ERROR     metadata = get_hf_file_metadata(
wandb: ERROR                ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
wandb: ERROR     r = _request_wrapper(
wandb: ERROR         ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
wandb: ERROR     response = _request_wrapper(
wandb: ERROR                ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 302, in _request_wrapper
wandb: ERROR     hf_raise_for_status(response)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 454, in hf_raise_for_status
wandb: ERROR     raise _format(RepositoryNotFoundError, message, response) from e
wandb: ERROR huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-68394c32-37dac08d4c023d3575cebee4;1dd44b48-3b59-45dc-823a-7b90864aeb42)
wandb: ERROR 
wandb: ERROR Repository Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json.
wandb: ERROR Please make sure you specified the correct `repo_id` and `repo_type`.
wandb: ERROR If you are trying to access a private or gated repo, make sure you are authenticated.
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
wandb: ERROR     return _target_(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/src/data/dataset.py", line 155, in __init__
wandb: ERROR     self.tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 881, in from_pretrained
wandb: ERROR     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
wandb: ERROR                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 713, in get_tokenizer_config
wandb: ERROR     resolved_config_file = cached_file(
wandb: ERROR                            ^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 365, in cached_file
wandb: ERROR     raise EnvironmentError(
wandb: ERROR OSError: nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
wandb: ERROR If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 299, in sweep_train
wandb: ERROR     train(config)
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 54, in train
wandb: ERROR     train_dataset = hydra.utils.instantiate(config.data.caller, data = train_data)
wandb: ERROR                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
wandb: ERROR     return instantiate_node(
wandb: ERROR            ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
wandb: ERROR     return _call_target(_target_, partial, args, kwargs, full_key)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
wandb: ERROR     raise InstantiationException(msg) from e
wandb: ERROR hydra.errors.InstantiationException: Error in call to target 'src.data.dataset.TBIDataset2stream':
wandb: ERROR OSError("nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`")
wandb: ERROR full_key: default_sweep.data.caller
wandb: ERROR 
wandb: Agent Starting Run: cwr0mgvm with config:
wandb: 	Fdropout_rate: 0.3714595818165124
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 6
wandb: 	Mdropout_rate: 0.1542474141619516
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 8
wandb: 	learning_rate: 0.09527600766792768
wandb: 	pretrained_model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_151207-cwr0mgvm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/cwr0mgvm
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Training started...
Epoch 0 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:10,884][__main__][INFO] - Train Epoch: 0 [0/51 (0%)]	Loss: 1.348006
Epoch 0 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  8.78it/s]Epoch 0 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  8.60it/s]Epoch 0 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  8.95it/s]Epoch 0 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.14it/s]Epoch 0 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.26it/s]Epoch 0 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.28it/s]Epoch 0 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.29it/s]Epoch 0 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.32it/s]Epoch 0 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.33it/s]Epoch 0 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.36it/s]Epoch 0 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.35it/s]Epoch 0 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.38it/s]Epoch 0 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.38it/s]Epoch 0 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.42it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.45it/s]Epoch 0 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.49it/s]Epoch 0 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.50it/s]Epoch 0 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.53it/s]Epoch 0 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.53it/s]Epoch 0 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.53it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.50it/s]Epoch 0 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.54it/s]Epoch 0 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.53it/s]Epoch 0 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.56it/s]Epoch 0 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.55it/s]Epoch 0 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.51it/s]Epoch 0 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.51it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.49it/s]Epoch 0 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.50it/s]Epoch 0 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.51it/s]Epoch 0 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.49it/s]Epoch 0 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.51it/s]Epoch 0 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.52it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.51it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.53it/s]Epoch 0 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.55it/s]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.54it/s]Epoch 0 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.52it/s]Epoch 0 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.52it/s]Epoch 0 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.51it/s]Epoch 0 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.49it/s]Epoch 0 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.49it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.49it/s]Epoch 0 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.50it/s]Epoch 0 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.49it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.49it/s]Epoch 0 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.50it/s]Epoch 0 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.47it/s]Epoch 0 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.47it/s]                                                                Epoch 0 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 0 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.17it/s]Epoch 0 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.20it/s]Epoch 0 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.23it/s]Epoch 0 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.29it/s]Epoch 0 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.36it/s]Epoch 0 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.32it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:17,364][__main__][INFO] - Epoch 0: Val Loss: 1.3965, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748fd4750>
<numpy.flatiter object at 0x7f3748fd4750>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811ee1a60>
<numpy.flatiter object at 0x7f3811ee1a60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811ee1a60>
<numpy.flatiter object at 0x7f3811ee1a60>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811ee2060>
<numpy.flatiter object at 0x7f3811ee2060>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811ee2060>
<numpy.flatiter object at 0x7f3811ee2060>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:12:17,424][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.1980
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:12:17,520][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:12:17,552][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:17,657][__main__][INFO] - Train Epoch: 1 [0/51 (0%)]	Loss: 1.408184
Epoch 1 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.65it/s]Epoch 1 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.60it/s]Epoch 1 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.57it/s]Epoch 1 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.56it/s]Epoch 1 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.56it/s]Epoch 1 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.60it/s]Epoch 1 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.52it/s]Epoch 1 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.53it/s]Epoch 1 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.54it/s]Epoch 1 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.56it/s]Epoch 1 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.57it/s]Epoch 1 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.58it/s]Epoch 1 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.57it/s]Epoch 1 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.52it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.51it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.52it/s]Epoch 1 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.55it/s]Epoch 1 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.55it/s]Epoch 1 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.41it/s]Epoch 1 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.45it/s]Epoch 1 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.44it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.46it/s]Epoch 1 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.48it/s]Epoch 1 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.48it/s]Epoch 1 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.45it/s]Epoch 1 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.47it/s]Epoch 1 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.47it/s]Epoch 1 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.47it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.46it/s]Epoch 1 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.47it/s]Epoch 1 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.48it/s]Epoch 1 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.50it/s]Epoch 1 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.51it/s]Epoch 1 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.49it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.50it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.50it/s]Epoch 1 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.51it/s]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.52it/s]Epoch 1 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.50it/s]Epoch 1 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.49it/s]Epoch 1 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.46it/s]Epoch 1 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.47it/s]Epoch 1 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.47it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.43it/s]Epoch 1 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.45it/s]Epoch 1 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.40it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.45it/s]Epoch 1 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.44it/s]Epoch 1 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.45it/s]Epoch 1 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.46it/s]                                                                Epoch 1 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 1 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.29it/s]Epoch 1 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.24it/s]Epoch 1 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.28it/s]Epoch 1 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.33it/s]Epoch 1 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.37it/s]Epoch 1 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.38it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:24,111][__main__][INFO] - Epoch 1: Val Loss: 1.1163, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370266e460>
<numpy.flatiter object at 0x7f370266e460>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370267e100>
<numpy.flatiter object at 0x7f370267e100>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370267e100>
<numpy.flatiter object at 0x7f370267e100>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370267e700>
<numpy.flatiter object at 0x7f370267e700>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370267e700>
<numpy.flatiter object at 0x7f370267e700>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:12:24,191][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:12:24,294][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:24,430][__main__][INFO] - Train Epoch: 2 [0/51 (0%)]	Loss: 0.844145
Epoch 2 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.62it/s]Epoch 2 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.30it/s]Epoch 2 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.46it/s]Epoch 2 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.50it/s]Epoch 2 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.57it/s]Epoch 2 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.61it/s]Epoch 2 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:06,  7.33it/s]Epoch 2 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:01<00:06,  6.40it/s]Epoch 2 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:01<00:07,  5.90it/s]Epoch 2 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:07,  5.52it/s]Epoch 2 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:07,  5.35it/s]Epoch 2 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:07,  5.22it/s]Epoch 2 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:02<00:07,  5.15it/s]Epoch 2 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:02<00:07,  5.03it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:02<00:07,  4.96it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:02<00:07,  4.98it/s]Epoch 2 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:02<00:06,  4.99it/s]Epoch 2 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:03<00:06,  4.94it/s]Epoch 2 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:03<00:06,  4.90it/s]Epoch 2 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:03<00:06,  4.95it/s]Epoch 2 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:03<00:06,  4.97it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:03<00:05,  4.94it/s]Epoch 2 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:04<00:05,  4.90it/s]Epoch 2 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:04<00:05,  4.95it/s]Epoch 2 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:04<00:05,  4.96it/s]Epoch 2 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:04<00:05,  4.94it/s]Epoch 2 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:04<00:04,  4.90it/s]Epoch 2 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:05<00:04,  4.95it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:05<00:04,  4.97it/s]Epoch 2 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:05<00:04,  4.94it/s]Epoch 2 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:05<00:04,  4.90it/s]Epoch 2 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:05<00:03,  5.65it/s]Epoch 2 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:05<00:02,  6.44it/s]Epoch 2 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:06<00:02,  7.15it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:06<00:02,  7.76it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:06<00:01,  8.23it/s]Epoch 2 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:06<00:01,  8.61it/s]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:06<00:01,  8.90it/s]Epoch 2 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:06<00:01,  9.10it/s]Epoch 2 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:06<00:01,  9.25it/s]Epoch 2 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:06<00:01,  9.33it/s]Epoch 2 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:06<00:00,  9.39it/s]Epoch 2 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:06<00:00,  9.45it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:07<00:00,  9.51it/s]Epoch 2 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:07<00:00,  9.52it/s]Epoch 2 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:07<00:00,  9.53it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:07<00:00,  9.52it/s]Epoch 2 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:07<00:00,  9.52it/s]Epoch 2 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:07<00:00,  9.51it/s]Epoch 2 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:07<00:00,  9.50it/s]                                                                Epoch 2 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 2 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.16it/s]Epoch 2 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.20it/s]Epoch 2 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.28it/s]Epoch 2 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.32it/s]Epoch 2 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.34it/s]Epoch 2 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.34it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:33,316][__main__][INFO] - Epoch 2: Val Loss: 1.1388, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:33,428][__main__][INFO] - Train Epoch: 3 [0/51 (0%)]	Loss: 1.073447
Epoch 3 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.29it/s]Epoch 3 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.40it/s]Epoch 3 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.09it/s]Epoch 3 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.24it/s]Epoch 3 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.33it/s]Epoch 3 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.40it/s]Epoch 3 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.45it/s]Epoch 3 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.49it/s]Epoch 3 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.50it/s]Epoch 3 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.36it/s]Epoch 3 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.40it/s]Epoch 3 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.43it/s]Epoch 3 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.44it/s]Epoch 3 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.43it/s]Epoch 3 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.43it/s]Epoch 3 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.41it/s]Epoch 3 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.43it/s]Epoch 3 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.41it/s]Epoch 3 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.43it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.44it/s]Epoch 3 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.43it/s]Epoch 3 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.41it/s]Epoch 3 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.42it/s]Epoch 3 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 3 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 3 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.41it/s]Epoch 3 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.42it/s]Epoch 3 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.41it/s]Epoch 3 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 3 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.42it/s]Epoch 3 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.45it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.43it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.42it/s]Epoch 3 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.42it/s]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.41it/s]Epoch 3 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 3 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 3 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.42it/s]Epoch 3 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.42it/s]Epoch 3 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.43it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.44it/s]Epoch 3 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.42it/s]Epoch 3 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.44it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.45it/s]Epoch 3 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.43it/s]Epoch 3 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.41it/s]Epoch 3 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.41it/s]                                                                Epoch 3 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 3 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.24it/s]Epoch 3 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.16it/s]Epoch 3 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.21it/s]Epoch 3 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.26it/s]Epoch 3 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 3 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.32it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:39,934][__main__][INFO] - Epoch 3: Val Loss: 1.1771, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:40,049][__main__][INFO] - Train Epoch: 4 [0/51 (0%)]	Loss: 1.224927
Epoch 4 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.06it/s]Epoch 4 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.27it/s]Epoch 4 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.44it/s]Epoch 4 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.53it/s]Epoch 4 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.56it/s]Epoch 4 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.52it/s]Epoch 4 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.52it/s]Epoch 4 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.52it/s]Epoch 4 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.53it/s]Epoch 4 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.53it/s]Epoch 4 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.51it/s]Epoch 4 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.50it/s]Epoch 4 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.49it/s]Epoch 4 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.49it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.48it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.46it/s]Epoch 4 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.45it/s]Epoch 4 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.45it/s]Epoch 4 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.47it/s]Epoch 4 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.44it/s]Epoch 4 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.42it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.41it/s]Epoch 4 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.43it/s]Epoch 4 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.39it/s]Epoch 4 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.40it/s]Epoch 4 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 4 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.42it/s]Epoch 4 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.43it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.43it/s]Epoch 4 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.43it/s]Epoch 4 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.44it/s]Epoch 4 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.45it/s]Epoch 4 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.42it/s]Epoch 4 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.43it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.43it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.44it/s]Epoch 4 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.44it/s]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.43it/s]Epoch 4 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.44it/s]Epoch 4 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.44it/s]Epoch 4 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.45it/s]Epoch 4 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.44it/s]Epoch 4 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.43it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.40it/s]Epoch 4 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.39it/s]Epoch 4 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.40it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.42it/s]Epoch 4 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.43it/s]Epoch 4 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.44it/s]Epoch 4 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.45it/s]                                                                Epoch 4 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 4 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.24it/s]Epoch 4 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:01,  9.91it/s]Epoch 4 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.10it/s]Epoch 4 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.20it/s]Epoch 4 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.25it/s]Epoch 4 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.29it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.84it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:46,542][__main__][INFO] - Epoch 4: Val Loss: 1.0448, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.1891025641025641, 'f1_weighted': 0.44186341711094185, 'precision_macro': 0.15206185567010308, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:46,657][__main__][INFO] - Train Epoch: 5 [0/51 (0%)]	Loss: 0.881883
Epoch 5 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.10it/s]Epoch 5 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.27it/s]Epoch 5 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.34it/s]Epoch 5 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.42it/s]Epoch 5 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.48it/s]Epoch 5 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.46it/s]Epoch 5 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.48it/s]Epoch 5 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.45it/s]Epoch 5 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.47it/s]Epoch 5 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.46it/s]Epoch 5 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.45it/s]Epoch 5 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.46it/s]Epoch 5 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.47it/s]Epoch 5 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.46it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.42it/s]Epoch 5 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.43it/s]Epoch 5 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.44it/s]Epoch 5 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.43it/s]Epoch 5 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.40it/s]Epoch 5 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.42it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.41it/s]Epoch 5 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 5 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.29it/s]Epoch 5 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.33it/s]Epoch 5 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.37it/s]Epoch 5 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.39it/s]Epoch 5 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.40it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.42it/s]Epoch 5 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.44it/s]Epoch 5 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.43it/s]Epoch 5 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.42it/s]Epoch 5 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 5 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.42it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.44it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.43it/s]Epoch 5 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.42it/s]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.45it/s]Epoch 5 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.44it/s]Epoch 5 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.43it/s]Epoch 5 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.43it/s]Epoch 5 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.45it/s]Epoch 5 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.43it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.22it/s]Epoch 5 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.28it/s]Epoch 5 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.33it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.35it/s]Epoch 5 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.36it/s]Epoch 5 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.35it/s]Epoch 5 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.36it/s]                                                                Epoch 5 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 5 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.25it/s]Epoch 5 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.20it/s]Epoch 5 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 5 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.26it/s]Epoch 5 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 5 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.31it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:53,164][__main__][INFO] - Epoch 5: Val Loss: 1.1764, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:53,278][__main__][INFO] - Train Epoch: 6 [0/51 (0%)]	Loss: 1.148885
Epoch 6 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.26it/s]Epoch 6 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.42it/s]Epoch 6 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.43it/s]Epoch 6 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.46it/s]Epoch 6 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.38it/s]Epoch 6 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Epoch 6 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.42it/s]Epoch 6 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.44it/s]Epoch 6 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.41it/s]Epoch 6 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.40it/s]Epoch 6 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.43it/s]Epoch 6 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.44it/s]Epoch 6 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.40it/s]Epoch 6 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.42it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.43it/s]Epoch 6 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.42it/s]Epoch 6 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.42it/s]Epoch 6 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.39it/s]Epoch 6 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.36it/s]Epoch 6 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.37it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 6 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.38it/s]Epoch 6 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 6 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 6 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.38it/s]Epoch 6 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 6 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.40it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.37it/s]Epoch 6 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 6 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 6 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 6 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 6 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.42it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.43it/s]Epoch 6 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.36it/s]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 6 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 6 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.41it/s]Epoch 6 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.39it/s]Epoch 6 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.39it/s]Epoch 6 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.41it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.42it/s]Epoch 6 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.41it/s]Epoch 6 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.39it/s]Epoch 6 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.42it/s]Epoch 6 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.41it/s]Epoch 6 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                Epoch 6 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 6 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.15it/s]Epoch 6 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.16it/s]Epoch 6 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.13it/s]Epoch 6 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.14it/s]Epoch 6 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.17it/s]Epoch 6 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.21it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:12:59,801][__main__][INFO] - Epoch 6: Val Loss: 1.1259, Accuracy: 0.5149, Metrics: {'accuracy': 0.5148514851485149, 'f1_macro': 0.2754726890756303, 'f1_weighted': 0.4733234878109659, 'precision_macro': 0.25265330188679247, 'recall_macro': 0.3442796610169492}
Epoch 7 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:12:59,912][__main__][INFO] - Train Epoch: 7 [0/51 (0%)]	Loss: 1.175412
Epoch 7 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.16it/s]Epoch 7 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.37it/s]Epoch 7 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.45it/s]Epoch 7 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.47it/s]Epoch 7 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.45it/s]Epoch 7 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.43it/s]Epoch 7 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.44it/s]Epoch 7 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.43it/s]Epoch 7 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.20it/s]Epoch 7 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.29it/s]Epoch 7 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.34it/s]Epoch 7 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.35it/s]Epoch 7 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.36it/s]Epoch 7 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.41it/s]Epoch 7 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.39it/s]Epoch 7 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.40it/s]Epoch 7 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.42it/s]Epoch 7 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.42it/s]Epoch 7 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.41it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.41it/s]Epoch 7 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.42it/s]Epoch 7 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.41it/s]Epoch 7 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.39it/s]Epoch 7 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.38it/s]Epoch 7 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.41it/s]Epoch 7 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.42it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.40it/s]Epoch 7 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 7 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.39it/s]Epoch 7 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 7 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.38it/s]Epoch 7 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.38it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.38it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.39it/s]Epoch 7 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.39it/s]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 7 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 7 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 7 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 7 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 7 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.39it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 7 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 7 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.39it/s]Epoch 7 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.35it/s]Epoch 7 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.36it/s]Epoch 7 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.38it/s]                                                                Epoch 7 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 7 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.28it/s]Epoch 7 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.17it/s]Epoch 7 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.20it/s]Epoch 7 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.26it/s]Epoch 7 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.24it/s]Epoch 7 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.24it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:06,435][__main__][INFO] - Epoch 7: Val Loss: 1.2347, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:06,546][__main__][INFO] - Train Epoch: 8 [0/51 (0%)]	Loss: 1.065273
Epoch 8 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.31it/s]Epoch 8 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.37it/s]Epoch 8 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.35it/s]Epoch 8 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.38it/s]Epoch 8 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.41it/s]Epoch 8 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.41it/s]Epoch 8 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.41it/s]Epoch 8 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.41it/s]Epoch 8 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.42it/s]Epoch 8 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.43it/s]Epoch 8 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.43it/s]Epoch 8 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.41it/s]Epoch 8 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.41it/s]Epoch 8 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.42it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.28it/s]Epoch 8 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.31it/s]Epoch 8 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.35it/s]Epoch 8 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.36it/s]Epoch 8 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.36it/s]Epoch 8 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.39it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.42it/s]Epoch 8 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 8 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.39it/s]Epoch 8 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 8 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.40it/s]Epoch 8 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 8 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 8 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.42it/s]Epoch 8 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 8 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.41it/s]Epoch 8 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 8 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.40it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.40it/s]Epoch 8 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.41it/s]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.42it/s]Epoch 8 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.36it/s]Epoch 8 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.33it/s]Epoch 8 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 8 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.39it/s]Epoch 8 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 8 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 8 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.40it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.40it/s]Epoch 8 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.40it/s]Epoch 8 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.42it/s]Epoch 8 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.42it/s]                                                                Epoch 8 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 8 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.31it/s]Epoch 8 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.20it/s]Epoch 8 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 8 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.29it/s]Epoch 8 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 8 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.33it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:13,060][__main__][INFO] - Epoch 8: Val Loss: 1.3743, Accuracy: 0.1485, Metrics: {'accuracy': 0.1485148514851485, 'f1_macro': 0.1442481884057971, 'f1_weighted': 0.06284079494906013, 'precision_macro': 0.11568627450980393, 'recall_macro': 0.34090909090909094}
Epoch 9 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:13,167][__main__][INFO] - Train Epoch: 9 [0/51 (0%)]	Loss: 1.181495
Epoch 9 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.52it/s]Epoch 9 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.53it/s]Epoch 9 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.55it/s]Epoch 9 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.52it/s]Epoch 9 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.49it/s]Epoch 9 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.46it/s]Epoch 9 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.48it/s]Epoch 9 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.47it/s]Epoch 9 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.48it/s]Epoch 9 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.44it/s]Epoch 9 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.43it/s]Epoch 9 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.40it/s]Epoch 9 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.41it/s]Epoch 9 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.40it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.38it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.38it/s]Epoch 9 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.37it/s]Epoch 9 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.37it/s]Epoch 9 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.38it/s]Epoch 9 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.40it/s]Epoch 9 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.40it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.36it/s]Epoch 9 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.37it/s]Epoch 9 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.39it/s]Epoch 9 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 9 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.35it/s]Epoch 9 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.37it/s]Epoch 9 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.38it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.38it/s]Epoch 9 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 9 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 9 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 9 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 9 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.41it/s]Epoch 9 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.41it/s]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.40it/s]Epoch 9 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.39it/s]Epoch 9 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 9 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 9 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.37it/s]Epoch 9 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.36it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 9 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 9 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.43it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.41it/s]Epoch 9 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.33it/s]Epoch 9 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.37it/s]Epoch 9 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                Epoch 9 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 9 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.24it/s]Epoch 9 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.28it/s]Epoch 9 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.10it/s]Epoch 9 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.16it/s]Epoch 9 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.24it/s]Epoch 9 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.24it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:19,689][__main__][INFO] - Epoch 9: Val Loss: 1.1834, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18670886075949367, 'f1_weighted': 0.43627020929941096, 'precision_macro': 0.14898989898989898, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:19,799][__main__][INFO] - Train Epoch: 10 [0/51 (0%)]	Loss: 1.303413
Epoch 10 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.19it/s]Epoch 10 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.00it/s]Epoch 10 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.17it/s]Epoch 10 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.29it/s]Epoch 10 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.35it/s]Epoch 10 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.41it/s]Epoch 10 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.45it/s]Epoch 10 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.44it/s]Epoch 10 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.43it/s]Epoch 10 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.42it/s]Epoch 10 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.41it/s]Epoch 10 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.40it/s]Epoch 10 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.40it/s]Epoch 10 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.40it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.40it/s]Epoch 10 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.37it/s]Epoch 10 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.37it/s]Epoch 10 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.38it/s]Epoch 10 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 10 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.35it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.37it/s]Epoch 10 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.41it/s]Epoch 10 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.43it/s]Epoch 10 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.42it/s]Epoch 10 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 10 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.42it/s]Epoch 10 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.43it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.42it/s]Epoch 10 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.40it/s]Epoch 10 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.39it/s]Epoch 10 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.38it/s]Epoch 10 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 10 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.38it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.38it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.41it/s]Epoch 10 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.43it/s]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 10 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.41it/s]Epoch 10 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.42it/s]Epoch 10 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.43it/s]Epoch 10 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.42it/s]Epoch 10 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.41it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 10 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.41it/s]Epoch 10 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.41it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.40it/s]Epoch 10 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.39it/s]Epoch 10 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.41it/s]Epoch 10 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.36it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 10 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.23it/s]Epoch 10 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.20it/s]Epoch 10 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 10 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.28it/s]Epoch 10 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.29it/s]Epoch 10 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.29it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:26,316][__main__][INFO] - Epoch 10: Val Loss: 1.1065, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 11 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:26,423][__main__][INFO] - Train Epoch: 11 [0/51 (0%)]	Loss: 0.324492
Epoch 11 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.56it/s]Epoch 11 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.56it/s]Epoch 11 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.56it/s]Epoch 11 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.54it/s]Epoch 11 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.53it/s]Epoch 11 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.52it/s]Epoch 11 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.52it/s]Epoch 11 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.53it/s]Epoch 11 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.54it/s]Epoch 11 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.52it/s]Epoch 11 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.48it/s]Epoch 11 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.49it/s]Epoch 11 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.49it/s]Epoch 11 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.50it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.48it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.44it/s]Epoch 11 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.44it/s]Epoch 11 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.44it/s]Epoch 11 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.42it/s]Epoch 11 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.39it/s]Epoch 11 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 11 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.41it/s]Epoch 11 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.39it/s]Epoch 11 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 11 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.38it/s]Epoch 11 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 11 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.40it/s]Epoch 11 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.41it/s]Epoch 11 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.43it/s]Epoch 11 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 11 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 11 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.42it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 11 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.16it/s]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.23it/s]Epoch 11 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.24it/s]Epoch 11 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.30it/s]Epoch 11 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.33it/s]Epoch 11 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.31it/s]Epoch 11 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.34it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.36it/s]Epoch 11 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.36it/s]Epoch 11 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.33it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.36it/s]Epoch 11 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.37it/s]Epoch 11 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.37it/s]Epoch 11 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.34it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 11 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.99it/s]Epoch 11 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.07it/s]Epoch 11 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.14it/s]Epoch 11 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.20it/s]Epoch 11 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.24it/s]Epoch 11 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.27it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.81it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:32,943][__main__][INFO] - Epoch 11: Val Loss: 1.1204, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:33,050][__main__][INFO] - Train Epoch: 12 [0/51 (0%)]	Loss: 1.301136
Epoch 12 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.54it/s]Epoch 12 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.56it/s]Epoch 12 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.55it/s]Epoch 12 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.53it/s]Epoch 12 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.56it/s]Epoch 12 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.54it/s]Epoch 12 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.58it/s]Epoch 12 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.54it/s]Epoch 12 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.49it/s]Epoch 12 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.47it/s]Epoch 12 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.44it/s]Epoch 12 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.46it/s]Epoch 12 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.44it/s]Epoch 12 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.43it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.44it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.41it/s]Epoch 12 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.39it/s]Epoch 12 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.38it/s]Epoch 12 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.40it/s]Epoch 12 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.42it/s]Epoch 12 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.40it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.28it/s]Epoch 12 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:03,  9.33it/s]Epoch 12 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.37it/s]Epoch 12 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.37it/s]Epoch 12 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.30it/s]Epoch 12 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.35it/s]Epoch 12 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.35it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.33it/s]Epoch 12 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.34it/s]Epoch 12 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.35it/s]Epoch 12 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.31it/s]Epoch 12 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.32it/s]Epoch 12 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.35it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.36it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 12 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 12 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 12 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.37it/s]Epoch 12 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 12 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 12 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.27it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.31it/s]Epoch 12 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.35it/s]Epoch 12 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.36it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.36it/s]Epoch 12 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.38it/s]Epoch 12 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 12 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 12 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.17it/s]Epoch 12 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.15it/s]Epoch 12 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.23it/s]Epoch 12 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.26it/s]Epoch 12 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.28it/s]Epoch 12 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:39,571][__main__][INFO] - Epoch 12: Val Loss: 1.1517, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 13 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:39,685][__main__][INFO] - Train Epoch: 13 [0/51 (0%)]	Loss: 0.669666
Epoch 13 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.20it/s]Epoch 13 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.14it/s]Epoch 13 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.29it/s]Epoch 13 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.37it/s]Epoch 13 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.41it/s]Epoch 13 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Epoch 13 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.40it/s]Epoch 13 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.42it/s]Epoch 13 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.44it/s]Epoch 13 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.42it/s]Epoch 13 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.37it/s]Epoch 13 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.36it/s]Epoch 13 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.37it/s]Epoch 13 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.35it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.36it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.37it/s]Epoch 13 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.39it/s]Epoch 13 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.37it/s]Epoch 13 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 13 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.37it/s]Epoch 13 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.39it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 13 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 13 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.41it/s]Epoch 13 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 13 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.33it/s]Epoch 13 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.35it/s]Epoch 13 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.34it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.34it/s]Epoch 13 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.35it/s]Epoch 13 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.37it/s]Epoch 13 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 13 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.38it/s]Epoch 13 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.36it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.22it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.25it/s]Epoch 13 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.29it/s]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  8.98it/s]Epoch 13 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.10it/s]Epoch 13 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.19it/s]Epoch 13 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.23it/s]Epoch 13 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.29it/s]Epoch 13 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.31it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.33it/s]Epoch 13 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.33it/s]Epoch 13 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.34it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.36it/s]Epoch 13 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.36it/s]Epoch 13 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.35it/s]Epoch 13 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.36it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 13 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.20it/s]Epoch 13 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.12it/s]Epoch 13 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.12it/s]Epoch 13 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.20it/s]Epoch 13 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.21it/s]Epoch 13 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.24it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:46,240][__main__][INFO] - Epoch 13: Val Loss: 1.1514, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 14 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:46,348][__main__][INFO] - Train Epoch: 14 [0/51 (0%)]	Loss: 0.790386
Epoch 14 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.47it/s]Epoch 14 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.01it/s]Epoch 14 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.20it/s]Epoch 14 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.33it/s]Epoch 14 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.40it/s]Epoch 14 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Epoch 14 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.45it/s]Epoch 14 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.45it/s]Epoch 14 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.45it/s]Epoch 14 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.46it/s]Epoch 14 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.46it/s]Epoch 14 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.46it/s]Epoch 14 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.44it/s]Epoch 14 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.44it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.39it/s]Epoch 14 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.38it/s]Epoch 14 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.39it/s]Epoch 14 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.39it/s]Epoch 14 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.36it/s]Epoch 14 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.37it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 14 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.37it/s]Epoch 14 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.36it/s]Epoch 14 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.39it/s]Epoch 14 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.42it/s]Epoch 14 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.42it/s]Epoch 14 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.41it/s]Epoch 14 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.41it/s]Epoch 14 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 14 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.37it/s]Epoch 14 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.37it/s]Epoch 14 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.35it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.34it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.36it/s]Epoch 14 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.39it/s]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.40it/s]Epoch 14 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.36it/s]Epoch 14 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.36it/s]Epoch 14 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.36it/s]Epoch 14 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.35it/s]Epoch 14 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.33it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.36it/s]Epoch 14 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.39it/s]Epoch 14 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.38it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.37it/s]Epoch 14 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.36it/s]Epoch 14 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 14 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 14 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.20it/s]Epoch 14 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.19it/s]Epoch 14 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.22it/s]Epoch 14 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 14 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 14 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.27it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:52,873][__main__][INFO] - Epoch 14: Val Loss: 1.0448, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.32575757575757575, 'f1_weighted': 0.568106810681068, 'precision_macro': 0.28864970645792565, 'recall_macro': 0.37457627118644066}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381259e840>
<numpy.flatiter object at 0x7f381259e840>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38125ae0d0>
<numpy.flatiter object at 0x7f38125ae0d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38125ae0d0>
<numpy.flatiter object at 0x7f38125ae0d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38125ae6d0>
<numpy.flatiter object at 0x7f38125ae6d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38125ae6d0>
<numpy.flatiter object at 0x7f38125ae6d0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:13:52,937][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.6436
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:13:53,048][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:53,195][__main__][INFO] - Train Epoch: 15 [0/51 (0%)]	Loss: 1.191954
Epoch 15 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.50it/s]Epoch 15 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.45it/s]Epoch 15 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.46it/s]Epoch 15 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.47it/s]Epoch 15 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.40it/s]Epoch 15 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.46it/s]Epoch 15 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.49it/s]Epoch 15 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.47it/s]Epoch 15 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.45it/s]Epoch 15 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.43it/s]Epoch 15 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.43it/s]Epoch 15 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.45it/s]Epoch 15 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.44it/s]Epoch 15 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.37it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.36it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.39it/s]Epoch 15 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.38it/s]Epoch 15 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.36it/s]Epoch 15 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 15 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.40it/s]Epoch 15 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.37it/s]Epoch 15 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.39it/s]Epoch 15 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.39it/s]Epoch 15 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.37it/s]Epoch 15 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.31it/s]Epoch 15 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.35it/s]Epoch 15 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.35it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.33it/s]Epoch 15 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 15 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.36it/s]Epoch 15 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.36it/s]Epoch 15 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.36it/s]Epoch 15 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.36it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 15 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 15 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.40it/s]Epoch 15 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 15 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.38it/s]Epoch 15 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 15 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 15 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.36it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.36it/s]Epoch 15 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.36it/s]Epoch 15 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.41it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.39it/s]Epoch 15 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.38it/s]Epoch 15 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.34it/s]Epoch 15 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.32it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 15 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.24it/s]Epoch 15 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.18it/s]Epoch 15 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.15it/s]Epoch 15 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.21it/s]Epoch 15 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 15 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.27it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:13:59,723][__main__][INFO] - Epoch 15: Val Loss: 1.0809, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.20754245754245754, 'f1_weighted': 0.4552477225744553, 'precision_macro': 0.19429824561403508, 'recall_macro': 0.2582627118644068}
Epoch 16 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:13:59,830][__main__][INFO] - Train Epoch: 16 [0/51 (0%)]	Loss: 1.235931
Epoch 16 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.63it/s]Epoch 16 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.56it/s]Epoch 16 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.54it/s]Epoch 16 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.45it/s]Epoch 16 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.45it/s]Epoch 16 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.47it/s]Epoch 16 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.48it/s]Epoch 16 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.47it/s]Epoch 16 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.44it/s]Epoch 16 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.45it/s]Epoch 16 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.45it/s]Epoch 16 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.44it/s]Epoch 16 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.38it/s]Epoch 16 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.16it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.24it/s]Epoch 16 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.22it/s]Epoch 16 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.27it/s]Epoch 16 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.26it/s]Epoch 16 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.31it/s]Epoch 16 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.34it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.34it/s]Epoch 16 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.35it/s]Epoch 16 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.38it/s]Epoch 16 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.41it/s]Epoch 16 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.36it/s]Epoch 16 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.37it/s]Epoch 16 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 16 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 16 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 16 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 16 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 16 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.36it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.36it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 16 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 16 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.36it/s]Epoch 16 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.37it/s]Epoch 16 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.31it/s]Epoch 16 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.31it/s]Epoch 16 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.32it/s]Epoch 16 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.36it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 16 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 16 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.37it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.37it/s]Epoch 16 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.40it/s]Epoch 16 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.36it/s]Epoch 16 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 16 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.18it/s]Epoch 16 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.12it/s]Epoch 16 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.23it/s]Epoch 16 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 16 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 16 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:14:06,365][__main__][INFO] - Epoch 16: Val Loss: 1.1141, Accuracy: 0.5050, Metrics: {'accuracy': 0.504950495049505, 'f1_macro': 0.2700735294117647, 'f1_weighted': 0.47097262667443207, 'precision_macro': 0.25559947299077734, 'recall_macro': 0.3065870570107858}
Epoch 17 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:06,473][__main__][INFO] - Train Epoch: 17 [0/51 (0%)]	Loss: 1.194244
Epoch 17 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.53it/s]Epoch 17 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.18it/s]Epoch 17 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.31it/s]Epoch 17 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.33it/s]Epoch 17 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.34it/s]Epoch 17 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.38it/s]Epoch 17 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.41it/s]Epoch 17 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.43it/s]Epoch 17 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.41it/s]Epoch 17 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.41it/s]Epoch 17 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.40it/s]Epoch 17 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.39it/s]Epoch 17 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.36it/s]Epoch 17 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.37it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.37it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.35it/s]Epoch 17 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.34it/s]Epoch 17 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.34it/s]Epoch 17 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.36it/s]Epoch 17 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.35it/s]Epoch 17 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.37it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 17 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.39it/s]Epoch 17 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.38it/s]Epoch 17 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 17 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 17 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 17 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.37it/s]Epoch 17 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 17 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 17 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.36it/s]Epoch 17 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.35it/s]Epoch 17 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.38it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.36it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.35it/s]Epoch 17 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.37it/s]Epoch 17 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 17 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.37it/s]Epoch 17 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.38it/s]Epoch 17 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.39it/s]Epoch 17 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 17 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.39it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.34it/s]Epoch 17 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.35it/s]Epoch 17 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.34it/s]Epoch 17 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.35it/s]Epoch 17 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.38it/s]Epoch 17 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 17 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.01it/s]Epoch 17 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.07it/s]Epoch 17 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.13it/s]Epoch 17 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.13it/s]Epoch 17 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.16it/s]Epoch 17 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.01it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:14:13,028][__main__][INFO] - Epoch 17: Val Loss: 0.9931, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3833333333333333, 'f1_weighted': 0.5768976897689769, 'precision_macro': 0.4540895061728395, 'recall_macro': 0.3804699537750385}
Epoch 18 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:13,138][__main__][INFO] - Train Epoch: 18 [0/51 (0%)]	Loss: 0.864282
Epoch 18 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.42it/s]Epoch 18 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.47it/s]Epoch 18 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.42it/s]Epoch 18 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.41it/s]Epoch 18 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.42it/s]Epoch 18 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.41it/s]Epoch 18 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.41it/s]Epoch 18 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.40it/s]Epoch 18 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.41it/s]Epoch 18 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.39it/s]Epoch 18 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.38it/s]Epoch 18 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.39it/s]Epoch 18 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.38it/s]Epoch 18 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.38it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.37it/s]Epoch 18 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.35it/s]Epoch 18 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.34it/s]Epoch 18 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.34it/s]Epoch 18 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.36it/s]Epoch 18 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.35it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.33it/s]Epoch 18 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:03,  9.31it/s]Epoch 18 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.34it/s]Epoch 18 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.35it/s]Epoch 18 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.35it/s]Epoch 18 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.14it/s]Epoch 18 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.20it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.24it/s]Epoch 18 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.30it/s]Epoch 18 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.31it/s]Epoch 18 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.33it/s]Epoch 18 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.36it/s]Epoch 18 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.36it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.37it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.35it/s]Epoch 18 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.32it/s]Epoch 18 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.35it/s]Epoch 18 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.35it/s]Epoch 18 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.36it/s]Epoch 18 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.32it/s]Epoch 18 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.34it/s]Epoch 18 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.32it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.34it/s]Epoch 18 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.37it/s]Epoch 18 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.36it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.35it/s]Epoch 18 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.36it/s]Epoch 18 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.38it/s]Epoch 18 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.38it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 18 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.96it/s]Epoch 18 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.09it/s]Epoch 18 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.14it/s]Epoch 18 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.19it/s]Epoch 18 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.23it/s]Epoch 18 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.27it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.80it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:14:19,685][__main__][INFO] - Epoch 18: Val Loss: 0.9736, Accuracy: 0.5446, Metrics: {'accuracy': 0.5445544554455446, 'f1_macro': 0.3082065255039601, 'f1_weighted': 0.4975241237611188, 'precision_macro': 0.28643048128342247, 'recall_macro': 0.3605161787365177}
Epoch 19 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:19,793][__main__][INFO] - Train Epoch: 19 [0/51 (0%)]	Loss: 0.603499
Epoch 19 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.45it/s]Epoch 19 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.56it/s]Epoch 19 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.53it/s]Epoch 19 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.46it/s]Epoch 19 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.46it/s]Epoch 19 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.45it/s]Epoch 19 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.39it/s]Epoch 19 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.03it/s]Epoch 19 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.10it/s]Epoch 19 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.14it/s]Epoch 19 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  8.46it/s]Epoch 19 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  8.50it/s]Epoch 19 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  8.15it/s]Epoch 19 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:04,  8.50it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:04,  8.74it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  8.94it/s]Epoch 19 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.09it/s]Epoch 19 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.20it/s]Epoch 19 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.27it/s]Epoch 19 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.28it/s]Epoch 19 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.35it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.40it/s]Epoch 19 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 19 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 19 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.41it/s]Epoch 19 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 19 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.37it/s]Epoch 19 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:03<00:02,  9.35it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 19 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.43it/s]Epoch 19 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.43it/s]Epoch 19 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.43it/s]Epoch 19 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.44it/s]Epoch 19 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.46it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.44it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.41it/s]Epoch 19 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:04<00:01,  9.40it/s]Epoch 19 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.41it/s]Epoch 19 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.42it/s]Epoch 19 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.33it/s]Epoch 19 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.35it/s]Epoch 19 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.34it/s]Epoch 19 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 19 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 19 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.43it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.42it/s]Epoch 19 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.41it/s]Epoch 19 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.42it/s]Epoch 19 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.41it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 19 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.20it/s]Epoch 19 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.13it/s]Epoch 19 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.19it/s]Epoch 19 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.22it/s]Epoch 19 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.23it/s]Epoch 19 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.25it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:14:26,392][__main__][INFO] - Epoch 19: Val Loss: 0.8921, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.4433943414322251, 'f1_weighted': 0.6109406257121877, 'precision_macro': 0.46321070234113715, 'recall_macro': 0.45277349768875197}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370265f2c0>
<numpy.flatiter object at 0x7f370265f2c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f5d21280>
<numpy.flatiter object at 0x7f36f5d21280>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5d21280>
<numpy.flatiter object at 0x7f36f5d21280>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f5d21880>
<numpy.flatiter object at 0x7f36f5d21880>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5d21880>
<numpy.flatiter object at 0x7f36f5d21880>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:14:26,455][__main__][INFO] - Saved best model at epoch 19 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:14:26,553][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 20 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:26,690][__main__][INFO] - Train Epoch: 20 [0/51 (0%)]	Loss: 0.835649
Epoch 20 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.56it/s]Epoch 20 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.55it/s]Epoch 20 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.54it/s]Epoch 20 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.51it/s]Epoch 20 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.51it/s]Epoch 20 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.55it/s]Epoch 20 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.52it/s]Epoch 20 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.46it/s]Epoch 20 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.39it/s]Epoch 20 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.32it/s]Epoch 20 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.31it/s]Epoch 20 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.32it/s]Epoch 20 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.04it/s]Epoch 20 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:04,  9.15it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.20it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.14it/s]Epoch 20 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.21it/s]Epoch 20 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  8.98it/s]Epoch 20 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.06it/s]Epoch 20 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.17it/s]Epoch 20 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.19it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.24it/s]Epoch 20 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:03,  9.28it/s]Epoch 20 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.35it/s]Epoch 20 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.39it/s]Epoch 20 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.38it/s]Epoch 20 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 20 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:03<00:02,  9.40it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.37it/s]Epoch 20 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.35it/s]Epoch 20 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 20 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 20 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 20 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.36it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.37it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.36it/s]Epoch 20 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.35it/s]Epoch 20 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 20 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 20 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 20 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.39it/s]Epoch 20 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.35it/s]Epoch 20 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 20 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 20 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.40it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.43it/s]Epoch 20 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.41it/s]Epoch 20 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.43it/s]Epoch 20 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.43it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 20 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.23it/s]Epoch 20 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.19it/s]Epoch 20 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 20 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 20 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.28it/s]Epoch 20 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:14:33,237][__main__][INFO] - Epoch 20: Val Loss: 0.8697, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.4638524474538016, 'f1_weighted': 0.6080233076206478, 'precision_macro': 0.5080357142857143, 'recall_macro': 0.4526771956856702}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63d4dc0>
<numpy.flatiter object at 0x7f36f63d4dc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702abae40>
<numpy.flatiter object at 0x7f3702abae40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702abae40>
<numpy.flatiter object at 0x7f3702abae40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702abb440>
<numpy.flatiter object at 0x7f3702abb440>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702abb440>
<numpy.flatiter object at 0x7f3702abb440>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:14:33,298][__main__][INFO] - Saved best model at epoch 20 with accuracy: 0.6634
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:14:33,397][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:14:33,428][__main__][INFO] - Saved model at epoch 20
Epoch 21 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:33,533][__main__][INFO] - Train Epoch: 21 [0/51 (0%)]	Loss: 0.723121
Epoch 21 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.65it/s]Epoch 21 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.23it/s]Epoch 21 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.34it/s]Epoch 21 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.35it/s]Epoch 21 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.38it/s]Epoch 21 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Epoch 21 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.46it/s]Epoch 21 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.50it/s]Epoch 21 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.50it/s]Epoch 21 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.48it/s]Epoch 21 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.48it/s]Epoch 21 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.51it/s]Epoch 21 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.52it/s]Epoch 21 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.53it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.53it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.52it/s]Epoch 21 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.53it/s]Epoch 21 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.55it/s]Epoch 21 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.54it/s]Epoch 21 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.54it/s]Epoch 21 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.50it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.51it/s]Epoch 21 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.54it/s]Epoch 21 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.53it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.54it/s]Epoch 21 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.54it/s]Epoch 21 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.54it/s]Epoch 21 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.52it/s]Epoch 21 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.52it/s]Epoch 21 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.50it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.50it/s]Epoch 21 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.44it/s]Epoch 21 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.41it/s]Epoch 21 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.42it/s]Epoch 21 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.46it/s]Epoch 21 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.49it/s]Epoch 21 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.26it/s]Epoch 21 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.35it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.42it/s]Epoch 21 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.46it/s]Epoch 21 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.47it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.50it/s]Epoch 21 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.52it/s]Epoch 21 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.54it/s]Epoch 21 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.54it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 21 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.25it/s]Epoch 21 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.18it/s]Epoch 21 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 21 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.27it/s]Epoch 21 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.28it/s]Epoch 21 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.31it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:14:39,998][__main__][INFO] - Epoch 21: Val Loss: 0.9254, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.4421503593145384, 'f1_weighted': 0.5781379132938169, 'precision_macro': 0.42625, 'recall_macro': 0.49337442218798155}
Epoch 22 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:40,106][__main__][INFO] - Train Epoch: 22 [0/51 (0%)]	Loss: 0.414823
Epoch 22 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.49it/s]Epoch 22 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.15it/s]Epoch 22 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.28it/s]Epoch 22 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.31it/s]Epoch 22 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.33it/s]Epoch 22 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.38it/s]Epoch 22 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.40it/s]Epoch 22 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 22 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.36it/s]Epoch 22 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.40it/s]Epoch 22 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.40it/s]Epoch 22 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.40it/s]Epoch 22 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.39it/s]Epoch 22 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.40it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.40it/s]Epoch 22 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.38it/s]Epoch 22 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.40it/s]Epoch 22 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.41it/s]Epoch 22 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.42it/s]Epoch 22 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.37it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 22 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.41it/s]Epoch 22 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.41it/s]Epoch 22 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.40it/s]Epoch 22 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 22 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.41it/s]Epoch 22 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.42it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 22 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.37it/s]Epoch 22 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.37it/s]Epoch 22 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 22 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 22 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.38it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.39it/s]Epoch 22 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 22 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 22 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 22 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.40it/s]Epoch 22 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 22 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.39it/s]Epoch 22 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.40it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.40it/s]Epoch 22 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 22 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.40it/s]Epoch 22 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.37it/s]Epoch 22 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.36it/s]Epoch 22 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.19it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 22 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.19it/s]Epoch 22 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.18it/s]Epoch 22 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.24it/s]Epoch 22 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.27it/s]Epoch 22 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.29it/s]Epoch 22 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.31it/s]                                                               [2025-05-30 15:14:46,635][__main__][INFO] - Epoch 22: Val Loss: 0.8125, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6290357142857143, 'f1_weighted': 0.6911838755304102, 'precision_macro': 0.6856060606060606, 'recall_macro': 0.6053543913713405}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119fef00>
<numpy.flatiter object at 0x7f3811a2cf00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63f77f0>
<numpy.flatiter object at 0x7f36f63f77f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63f77f0>
<numpy.flatiter object at 0x7f36f63f77f0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63fe2b0>
<numpy.flatiter object at 0x7f36f63fe2b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63fe2b0>
<numpy.flatiter object at 0x7f36f63fe2b0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:14:46,697][__main__][INFO] - Saved best model at epoch 22 with accuracy: 0.7030
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:14:46,796][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 23 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:46,933][__main__][INFO] - Train Epoch: 23 [0/51 (0%)]	Loss: 0.351151
Epoch 23 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.55it/s]Epoch 23 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.53it/s]Epoch 23 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.54it/s]Epoch 23 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.49it/s]Epoch 23 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.47it/s]Epoch 23 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.46it/s]Epoch 23 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.44it/s]Epoch 23 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.42it/s]Epoch 23 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.41it/s]Epoch 23 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.42it/s]Epoch 23 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.42it/s]Epoch 23 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.41it/s]Epoch 23 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.40it/s]Epoch 23 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.41it/s]Epoch 23 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.40it/s]Epoch 23 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.43it/s]Epoch 23 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.44it/s]Epoch 23 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.42it/s]Epoch 23 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.40it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.42it/s]Epoch 23 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 23 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.37it/s]Epoch 23 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.35it/s]Epoch 23 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.36it/s]Epoch 23 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 23 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.34it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.36it/s]Epoch 23 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 23 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.41it/s]Epoch 23 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.20it/s]Epoch 23 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.27it/s]Epoch 23 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.32it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.33it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.36it/s]Epoch 23 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.39it/s]Epoch 23 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.42it/s]Epoch 23 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 23 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.38it/s]Epoch 23 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.40it/s]Epoch 23 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.42it/s]Epoch 23 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.39it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 23 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.39it/s]Epoch 23 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.38it/s]Epoch 23 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.37it/s]Epoch 23 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.39it/s]Epoch 23 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.41it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 23 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.26it/s]Epoch 23 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.22it/s]Epoch 23 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.24it/s]Epoch 23 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.27it/s]Epoch 23 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 23 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.31it/s]                                                               [2025-05-30 15:14:53,449][__main__][INFO] - Epoch 23: Val Loss: 0.8850, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.6032381030135857, 'f1_weighted': 0.6706406351713495, 'precision_macro': 0.6616987179487179, 'recall_macro': 0.5763289676425271}
Epoch 24 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:14:53,556][__main__][INFO] - Train Epoch: 24 [0/51 (0%)]	Loss: 1.524251
Epoch 24 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.46it/s]Epoch 24 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.45it/s]Epoch 24 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.47it/s]Epoch 24 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.18it/s]Epoch 24 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.32it/s]Epoch 24 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.37it/s]Epoch 24 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.39it/s]Epoch 24 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 24 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.37it/s]Epoch 24 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.38it/s]Epoch 24 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.39it/s]Epoch 24 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.39it/s]Epoch 24 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.37it/s]Epoch 24 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.37it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.38it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.36it/s]Epoch 24 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.36it/s]Epoch 24 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.38it/s]Epoch 24 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.39it/s]Epoch 24 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.37it/s]Epoch 24 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.36it/s]Epoch 24 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.38it/s]Epoch 24 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.36it/s]Epoch 24 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.37it/s]Epoch 24 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.38it/s]Epoch 24 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.39it/s]Epoch 24 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.38it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 24 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.40it/s]Epoch 24 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.39it/s]Epoch 24 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 24 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 24 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.43it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.40it/s]Epoch 24 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 24 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.41it/s]Epoch 24 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 24 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 24 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.41it/s]Epoch 24 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.42it/s]Epoch 24 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.44it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.41it/s]Epoch 24 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.39it/s]Epoch 24 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.38it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.40it/s]Epoch 24 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.40it/s]Epoch 24 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 24 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 24 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.96it/s]Epoch 24 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.08it/s]Epoch 24 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.15it/s]Epoch 24 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.20it/s]Epoch 24 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.26it/s]Epoch 24 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.28it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.83it/s]                                                               [2025-05-30 15:15:00,089][__main__][INFO] - Epoch 24: Val Loss: 0.8392, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.5625216888374783, 'f1_weighted': 0.6574165802930785, 'precision_macro': 0.6590090090090089, 'recall_macro': 0.5476117103235748}
Epoch 25 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:00,197][__main__][INFO] - Train Epoch: 25 [0/51 (0%)]	Loss: 1.057895
Epoch 25 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.49it/s]Epoch 25 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.54it/s]Epoch 25 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.55it/s]Epoch 25 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.53it/s]Epoch 25 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.52it/s]Epoch 25 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.53it/s]Epoch 25 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.54it/s]Epoch 25 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.56it/s]Epoch 25 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.50it/s]Epoch 25 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.43it/s]Epoch 25 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.42it/s]Epoch 25 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.44it/s]Epoch 25 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.44it/s]Epoch 25 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.42it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.41it/s]Epoch 25 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.42it/s]Epoch 25 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.39it/s]Epoch 25 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.39it/s]Epoch 25 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 25 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.37it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.36it/s]Epoch 25 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.36it/s]Epoch 25 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.36it/s]Epoch 25 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.36it/s]Epoch 25 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.33it/s]Epoch 25 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.35it/s]Epoch 25 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.36it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.38it/s]Epoch 25 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.37it/s]Epoch 25 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 25 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 25 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.41it/s]Epoch 25 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.40it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.41it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.42it/s]Epoch 25 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.41it/s]Epoch 25 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 25 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.41it/s]Epoch 25 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.41it/s]Epoch 25 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.42it/s]Epoch 25 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 25 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.40it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.41it/s]Epoch 25 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.43it/s]Epoch 25 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.43it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.42it/s]Epoch 25 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.43it/s]Epoch 25 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.43it/s]Epoch 25 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.42it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 25 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.97it/s]Epoch 25 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.08it/s]Epoch 25 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.19it/s]Epoch 25 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.24it/s]Epoch 25 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.27it/s]Epoch 25 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.28it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.82it/s]                                                               [2025-05-30 15:15:06,704][__main__][INFO] - Epoch 25: Val Loss: 0.8448, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.5587206612396993, 'f1_weighted': 0.6404871023171643, 'precision_macro': 0.606456043956044, 'recall_macro': 0.5452234206471495}
Epoch 26 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:06,816][__main__][INFO] - Train Epoch: 26 [0/51 (0%)]	Loss: 0.554236
Epoch 26 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.18it/s]Epoch 26 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  8.99it/s]Epoch 26 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.20it/s]Epoch 26 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.31it/s]Epoch 26 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.28it/s]Epoch 26 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.33it/s]Epoch 26 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.37it/s]Epoch 26 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.29it/s]Epoch 26 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.31it/s]Epoch 26 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.30it/s]Epoch 26 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.35it/s]Epoch 26 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.35it/s]Epoch 26 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.38it/s]Epoch 26 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.24it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.28it/s]Epoch 26 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.33it/s]Epoch 26 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.36it/s]Epoch 26 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 26 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.36it/s]Epoch 26 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.37it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 26 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.38it/s]Epoch 26 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.39it/s]Epoch 26 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.40it/s]Epoch 26 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 26 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 26 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.41it/s]Epoch 26 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.42it/s]Epoch 26 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.43it/s]Epoch 26 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.42it/s]Epoch 26 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.42it/s]Epoch 26 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.42it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.41it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.41it/s]Epoch 26 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.40it/s]Epoch 26 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.41it/s]Epoch 26 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.42it/s]Epoch 26 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.41it/s]Epoch 26 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 26 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 26 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.42it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.43it/s]Epoch 26 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.41it/s]Epoch 26 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.42it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.43it/s]Epoch 26 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.45it/s]Epoch 26 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.43it/s]Epoch 26 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.43it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 26 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.10it/s]Epoch 26 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.12it/s]Epoch 26 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.22it/s]Epoch 26 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.25it/s]Epoch 26 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.28it/s]Epoch 26 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.29it/s]                                                               [2025-05-30 15:15:13,342][__main__][INFO] - Epoch 26: Val Loss: 0.8106, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.5542929292929293, 'f1_weighted': 0.6555155515551556, 'precision_macro': 0.7576276463262765, 'recall_macro': 0.5476117103235748}
Epoch 27 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:13,455][__main__][INFO] - Train Epoch: 27 [0/51 (0%)]	Loss: 0.228386
Epoch 27 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.01it/s]Epoch 27 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  8.93it/s]Epoch 27 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.17it/s]Epoch 27 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.26it/s]Epoch 27 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.30it/s]Epoch 27 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.34it/s]Epoch 27 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.36it/s]Epoch 27 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.35it/s]Epoch 27 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.35it/s]Epoch 27 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.37it/s]Epoch 27 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.38it/s]Epoch 27 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.36it/s]Epoch 27 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.34it/s]Epoch 27 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.36it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.38it/s]Epoch 27 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.36it/s]Epoch 27 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.36it/s]Epoch 27 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.38it/s]Epoch 27 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 27 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 27 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.39it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.41it/s]Epoch 27 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.39it/s]Epoch 27 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.38it/s]Epoch 27 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.37it/s]Epoch 27 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.40it/s]Epoch 27 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.39it/s]Epoch 27 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.38it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.40it/s]Epoch 27 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.41it/s]Epoch 27 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 27 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.38it/s]Epoch 27 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 27 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 27 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.40it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.39it/s]Epoch 27 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.36it/s]Epoch 27 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 27 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 27 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.37it/s]Epoch 27 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 27 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 27 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.41it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.40it/s]Epoch 27 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 27 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.43it/s]Epoch 27 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.43it/s]Epoch 27 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.41it/s]Epoch 27 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 27 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 27 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 27 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.99it/s]Epoch 27 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.11it/s]Epoch 27 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.16it/s]Epoch 27 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.24it/s]Epoch 27 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.25it/s]Epoch 27 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.27it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.82it/s]                                                               [2025-05-30 15:15:19,985][__main__][INFO] - Epoch 27: Val Loss: 0.8134, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.5624274099883856, 'f1_weighted': 0.650578995181748, 'precision_macro': 0.6064854299928927, 'recall_macro': 0.5556625577812019}
Epoch 28 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:20,098][__main__][INFO] - Train Epoch: 28 [0/51 (0%)]	Loss: 0.419241
Epoch 28 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.12it/s]Epoch 28 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.26it/s]Epoch 28 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.31it/s]Epoch 28 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.34it/s]Epoch 28 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.38it/s]Epoch 28 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Epoch 28 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.41it/s]Epoch 28 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 28 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.40it/s]Epoch 28 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.40it/s]Epoch 28 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.38it/s]Epoch 28 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.37it/s]Epoch 28 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.37it/s]Epoch 28 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.40it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.39it/s]Epoch 28 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.25it/s]Epoch 28 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.31it/s]Epoch 28 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.32it/s]Epoch 28 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.34it/s]Epoch 28 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.37it/s]Epoch 28 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.39it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 28 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.38it/s]Epoch 28 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 28 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.42it/s]Epoch 28 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 28 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.39it/s]Epoch 28 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.37it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.40it/s]Epoch 28 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 28 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 28 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 28 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.42it/s]Epoch 28 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 28 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.34it/s]Epoch 28 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.37it/s]Epoch 28 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 28 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.39it/s]Epoch 28 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.38it/s]Epoch 28 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 28 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.37it/s]Epoch 28 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.37it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.40it/s]Epoch 28 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.41it/s]Epoch 28 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.40it/s]Epoch 28 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.39it/s]Epoch 28 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.41it/s]Epoch 28 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.41it/s]Epoch 28 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                 Epoch 28 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 28 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.17it/s]Epoch 28 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.24it/s]Epoch 28 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 28 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.28it/s]Epoch 28 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.29it/s]Epoch 28 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.29it/s]                                                               [2025-05-30 15:15:26,619][__main__][INFO] - Epoch 28: Val Loss: 0.8130, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.615942513368984, 'f1_weighted': 0.6904630168899244, 'precision_macro': 0.6805011889518932, 'recall_macro': 0.5930662557781202}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37492bfb00>
<numpy.flatiter object at 0x7f37492bfb00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f374930df00>
<numpy.flatiter object at 0x7f374930df00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374930df00>
<numpy.flatiter object at 0x7f374930df00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374930e500>
<numpy.flatiter object at 0x7f374930e500>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374930e500>
<numpy.flatiter object at 0x7f374930e500>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:15:26,686][__main__][INFO] - Saved best model at epoch 28 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:15:26,786][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 29 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:26,925][__main__][INFO] - Train Epoch: 29 [0/51 (0%)]	Loss: 0.719782
Epoch 29 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.43it/s]Epoch 29 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.47it/s]Epoch 29 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.47it/s]Epoch 29 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.40it/s]Epoch 29 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.40it/s]Epoch 29 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.41it/s]Epoch 29 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.43it/s]Epoch 29 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.37it/s]Epoch 29 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.38it/s]Epoch 29 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.40it/s]Epoch 29 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.43it/s]Epoch 29 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.41it/s]Epoch 29 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.39it/s]Epoch 29 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.40it/s]Epoch 29 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.39it/s]Epoch 29 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.36it/s]Epoch 29 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.37it/s]Epoch 29 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.40it/s]Epoch 29 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.34it/s]Epoch 29 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.35it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.37it/s]Epoch 29 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.38it/s]Epoch 29 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.36it/s]Epoch 29 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.37it/s]Epoch 29 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 29 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.42it/s]Epoch 29 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.41it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.41it/s]Epoch 29 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.40it/s]Epoch 29 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.42it/s]Epoch 29 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.41it/s]Epoch 29 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 29 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 29 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.40it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.36it/s]Epoch 29 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.35it/s]Epoch 29 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 29 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 29 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.36it/s]Epoch 29 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.35it/s]Epoch 29 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.36it/s]Epoch 29 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.37it/s]Epoch 29 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 29 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 29 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.36it/s]Epoch 29 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.35it/s]Epoch 29 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.37it/s]Epoch 29 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.38it/s]                                                                 Epoch 29 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 29 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.20it/s]Epoch 29 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.14it/s]Epoch 29 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.20it/s]Epoch 29 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 29 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.27it/s]Epoch 29 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:15:33,449][__main__][INFO] - Epoch 29: Val Loss: 1.0124, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.5849361703398971, 'f1_weighted': 0.6329023023568255, 'precision_macro': 0.575734917791568, 'recall_macro': 0.6064714946070878}
Epoch 30 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:33,563][__main__][INFO] - Train Epoch: 30 [0/51 (0%)]	Loss: 0.581205
Epoch 30 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.32it/s]Epoch 30 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.37it/s]Epoch 30 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.40it/s]Epoch 30 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.39it/s]Epoch 30 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.42it/s]Epoch 30 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.43it/s]Epoch 30 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.44it/s]Epoch 30 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.44it/s]Epoch 30 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.41it/s]Epoch 30 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.42it/s]Epoch 30 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.43it/s]Epoch 30 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.41it/s]Epoch 30 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.39it/s]Epoch 30 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 30 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.42it/s]Epoch 30 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.40it/s]Epoch 30 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.34it/s]Epoch 30 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 30 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.35it/s]Epoch 30 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.36it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 30 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.41it/s]Epoch 30 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.36it/s]Epoch 30 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.36it/s]Epoch 30 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 30 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 30 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 30 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 30 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  8.73it/s]Epoch 30 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  8.91it/s]Epoch 30 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.10it/s]Epoch 30 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.23it/s]Epoch 30 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.33it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 30 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.39it/s]Epoch 30 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 30 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.37it/s]Epoch 30 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.38it/s]Epoch 30 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.41it/s]Epoch 30 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.45it/s]Epoch 30 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.49it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.50it/s]Epoch 30 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.49it/s]Epoch 30 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.42it/s]Epoch 30 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.44it/s]Epoch 30 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.48it/s]Epoch 30 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.51it/s]Epoch 30 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.49it/s]                                                                 Epoch 30 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 30 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.26it/s]Epoch 30 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.25it/s]Epoch 30 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.27it/s]Epoch 30 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.28it/s]Epoch 30 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.29it/s]Epoch 30 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:15:40,088][__main__][INFO] - Epoch 30: Val Loss: 0.8317, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5761216819356354, 'f1_weighted': 0.6589965973341521, 'precision_macro': 0.6331168831168832, 'recall_macro': 0.5618644067796611}
Epoch 31 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:40,201][__main__][INFO] - Train Epoch: 31 [0/51 (0%)]	Loss: 0.422254
Epoch 31 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.03it/s]Epoch 31 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.23it/s]Epoch 31 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.29it/s]Epoch 31 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.35it/s]Epoch 31 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.40it/s]Epoch 31 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.42it/s]Epoch 31 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.40it/s]Epoch 31 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.41it/s]Epoch 31 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.42it/s]Epoch 31 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.41it/s]Epoch 31 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.44it/s]Epoch 31 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.44it/s]Epoch 31 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.42it/s]Epoch 31 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.43it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.43it/s]Epoch 31 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.41it/s]Epoch 31 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.40it/s]Epoch 31 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.42it/s]Epoch 31 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.42it/s]Epoch 31 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.43it/s]Epoch 31 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.39it/s]Epoch 31 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.41it/s]Epoch 31 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 31 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.39it/s]Epoch 31 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.40it/s]Epoch 31 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.41it/s]Epoch 31 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.41it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 31 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.40it/s]Epoch 31 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.43it/s]Epoch 31 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.44it/s]Epoch 31 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.43it/s]Epoch 31 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 31 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.39it/s]Epoch 31 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 31 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 31 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.42it/s]Epoch 31 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.43it/s]Epoch 31 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.41it/s]Epoch 31 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 31 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.41it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.41it/s]Epoch 31 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 31 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.38it/s]Epoch 31 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.39it/s]Epoch 31 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.40it/s]Epoch 31 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 31 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                 Epoch 31 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 31 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.09it/s]Epoch 31 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.08it/s]Epoch 31 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.20it/s]Epoch 31 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.23it/s]Epoch 31 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.25it/s]Epoch 31 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.29it/s]                                                               [2025-05-30 15:15:46,714][__main__][INFO] - Epoch 31: Val Loss: 0.8045, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5472689472689473, 'f1_weighted': 0.64983429735905, 'precision_macro': 0.6267699781577164, 'recall_macro': 0.5433744221879816}
Epoch 32 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:46,824][__main__][INFO] - Train Epoch: 32 [0/51 (0%)]	Loss: 0.545390
Epoch 32 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.26it/s]Epoch 32 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.41it/s]Epoch 32 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.49it/s]Epoch 32 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.52it/s]Epoch 32 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.48it/s]Epoch 32 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.45it/s]Epoch 32 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.44it/s]Epoch 32 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.41it/s]Epoch 32 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.42it/s]Epoch 32 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.43it/s]Epoch 32 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.41it/s]Epoch 32 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.42it/s]Epoch 32 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.43it/s]Epoch 32 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.38it/s]Epoch 32 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.37it/s]Epoch 32 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.39it/s]Epoch 32 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.37it/s]Epoch 32 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 32 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.39it/s]Epoch 32 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.39it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.35it/s]Epoch 32 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.36it/s]Epoch 32 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.36it/s]Epoch 32 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.41it/s]Epoch 32 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 32 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 32 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 32 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.39it/s]Epoch 32 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 32 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.38it/s]Epoch 32 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.39it/s]Epoch 32 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 32 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.37it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.39it/s]Epoch 32 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.37it/s]Epoch 32 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 32 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 32 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 32 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.40it/s]Epoch 32 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 32 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.39it/s]Epoch 32 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 32 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.40it/s]Epoch 32 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.38it/s]Epoch 32 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.39it/s]Epoch 32 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 32 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.36it/s]                                                                 Epoch 32 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 32 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.94it/s]Epoch 32 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.01it/s]Epoch 32 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.12it/s]Epoch 32 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.20it/s]Epoch 32 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.22it/s]Epoch 32 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.28it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.81it/s]                                                               [2025-05-30 15:15:53,350][__main__][INFO] - Epoch 32: Val Loss: 0.7778, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.5436785436785437, 'f1_weighted': 0.642029038068642, 'precision_macro': 0.5889351259069568, 'recall_macro': 0.5391371340523883}
Epoch 33 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:15:53,464][__main__][INFO] - Train Epoch: 33 [0/51 (0%)]	Loss: 0.395083
Epoch 33 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.27it/s]Epoch 33 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.34it/s]Epoch 33 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.38it/s]Epoch 33 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.38it/s]Epoch 33 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.40it/s]Epoch 33 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.43it/s]Epoch 33 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.42it/s]Epoch 33 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.42it/s]Epoch 33 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.37it/s]Epoch 33 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.40it/s]Epoch 33 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.41it/s]Epoch 33 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.42it/s]Epoch 33 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.41it/s]Epoch 33 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.43it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 33 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.42it/s]Epoch 33 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.40it/s]Epoch 33 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.41it/s]Epoch 33 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.42it/s]Epoch 33 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.43it/s]Epoch 33 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.41it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 33 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 33 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.41it/s]Epoch 33 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.40it/s]Epoch 33 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 33 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 33 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.41it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.40it/s]Epoch 33 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.39it/s]Epoch 33 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.39it/s]Epoch 33 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 33 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.41it/s]Epoch 33 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 33 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.41it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.42it/s]Epoch 33 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.41it/s]Epoch 33 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 33 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.41it/s]Epoch 33 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.41it/s]Epoch 33 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 33 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.37it/s]Epoch 33 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.37it/s]Epoch 33 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.10it/s]Epoch 33 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.20it/s]Epoch 33 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.25it/s]Epoch 33 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.28it/s]Epoch 33 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.32it/s]Epoch 33 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 33 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 33 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.15it/s]Epoch 33 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.15it/s]Epoch 33 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.20it/s]Epoch 33 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.25it/s]Epoch 33 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.27it/s]Epoch 33 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:15:59,990][__main__][INFO] - Epoch 33: Val Loss: 0.8974, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.5005950104126823, 'f1_weighted': 0.6313952573377954, 'precision_macro': 0.5149597238204834, 'recall_macro': 0.5125963020030817}
Epoch 34 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:00,108][__main__][INFO] - Train Epoch: 34 [0/51 (0%)]	Loss: 0.891358
Epoch 34 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  8.95it/s]Epoch 34 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.21it/s]Epoch 34 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.31it/s]Epoch 34 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.37it/s]Epoch 34 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.39it/s]Epoch 34 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.37it/s]Epoch 34 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.38it/s]Epoch 34 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 34 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.40it/s]Epoch 34 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.37it/s]Epoch 34 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.36it/s]Epoch 34 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.35it/s]Epoch 34 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.36it/s]Epoch 34 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.36it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.37it/s]Epoch 34 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.38it/s]Epoch 34 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.38it/s]Epoch 34 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.37it/s]Epoch 34 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 34 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.40it/s]Epoch 34 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.39it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 34 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.39it/s]Epoch 34 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 34 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.36it/s]Epoch 34 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.35it/s]Epoch 34 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 34 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.38it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.38it/s]Epoch 34 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 34 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.34it/s]Epoch 34 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.37it/s]Epoch 34 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.36it/s]Epoch 34 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.36it/s]Epoch 34 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.38it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 34 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.37it/s]Epoch 34 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 34 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 34 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.40it/s]Epoch 34 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.40it/s]Epoch 34 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 34 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.41it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.41it/s]Epoch 34 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 34 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 34 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.41it/s]Epoch 34 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.40it/s]Epoch 34 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.39it/s]Epoch 34 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 34 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 34 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.18it/s]Epoch 34 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.13it/s]Epoch 34 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.22it/s]Epoch 34 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 34 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.25it/s]Epoch 34 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.26it/s]                                                               [2025-05-30 15:16:06,635][__main__][INFO] - Epoch 34: Val Loss: 0.9221, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.6264784174539382, 'f1_weighted': 0.6838712411352833, 'precision_macro': 0.6584975369458128, 'recall_macro': 0.6216679506933744}
Epoch 35 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:06,748][__main__][INFO] - Train Epoch: 35 [0/51 (0%)]	Loss: 0.962499
Epoch 35 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.27it/s]Epoch 35 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.39it/s]Epoch 35 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.44it/s]Epoch 35 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.38it/s]Epoch 35 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.36it/s]Epoch 35 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.40it/s]Epoch 35 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.39it/s]Epoch 35 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 35 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.38it/s]Epoch 35 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.40it/s]Epoch 35 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.40it/s]Epoch 35 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.39it/s]Epoch 35 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.40it/s]Epoch 35 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.40it/s]Epoch 35 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.40it/s]Epoch 35 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.40it/s]Epoch 35 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.40it/s]Epoch 35 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.39it/s]Epoch 35 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 35 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.40it/s]Epoch 35 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 35 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.37it/s]Epoch 35 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 35 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.40it/s]Epoch 35 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.37it/s]Epoch 35 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.36it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.38it/s]Epoch 35 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.40it/s]Epoch 35 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 35 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 35 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 35 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 35 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.38it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.38it/s]Epoch 35 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 35 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 35 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.35it/s]Epoch 35 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.35it/s]Epoch 35 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 35 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 35 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.37it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.36it/s]Epoch 35 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 35 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 35 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.40it/s]Epoch 35 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.39it/s]Epoch 35 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.41it/s]Epoch 35 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.42it/s]                                                                 Epoch 35 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 35 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.12it/s]Epoch 35 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.15it/s]Epoch 35 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.22it/s]Epoch 35 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.25it/s]Epoch 35 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 35 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:16:13,270][__main__][INFO] - Epoch 35: Val Loss: 0.9340, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.6129197235513025, 'f1_weighted': 0.6716085924381912, 'precision_macro': 0.6363636363636364, 'recall_macro': 0.5988443759630201}
Epoch 36 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:13,386][__main__][INFO] - Train Epoch: 36 [0/51 (0%)]	Loss: 0.436729
Epoch 36 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.04it/s]Epoch 36 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.23it/s]Epoch 36 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.29it/s]Epoch 36 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.34it/s]Epoch 36 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.36it/s]Epoch 36 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.35it/s]Epoch 36 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.37it/s]Epoch 36 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.44it/s]Epoch 36 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.46it/s]Epoch 36 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.49it/s]Epoch 36 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.50it/s]Epoch 36 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.50it/s]Epoch 36 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.50it/s]Epoch 36 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.53it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.54it/s]Epoch 36 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.49it/s]Epoch 36 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.44it/s]Epoch 36 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.46it/s]Epoch 36 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.42it/s]Epoch 36 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.44it/s]Epoch 36 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.43it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.40it/s]Epoch 36 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.41it/s]Epoch 36 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.42it/s]Epoch 36 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.40it/s]Epoch 36 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.40it/s]Epoch 36 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 36 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.37it/s]Epoch 36 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 36 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 36 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 36 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 36 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 36 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.42it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.41it/s]Epoch 36 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.40it/s]Epoch 36 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.40it/s]Epoch 36 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.42it/s]Epoch 36 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.42it/s]Epoch 36 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.41it/s]Epoch 36 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 36 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.42it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.41it/s]Epoch 36 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.40it/s]Epoch 36 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.38it/s]Epoch 36 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.40it/s]Epoch 36 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.41it/s]Epoch 36 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 36 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.40it/s]                                                                 Epoch 36 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 36 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.14it/s]Epoch 36 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.13it/s]Epoch 36 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.19it/s]Epoch 36 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.21it/s]Epoch 36 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 36 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:16:19,891][__main__][INFO] - Epoch 36: Val Loss: 0.7861, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.5737900365887982, 'f1_weighted': 0.6571675198479601, 'precision_macro': 0.5946969696969697, 'recall_macro': 0.5658898305084746}
Epoch 37 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:20,005][__main__][INFO] - Train Epoch: 37 [0/51 (0%)]	Loss: 0.371660
Epoch 37 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.04it/s]Epoch 37 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.25it/s]Epoch 37 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.36it/s]Epoch 37 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.39it/s]Epoch 37 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.36it/s]Epoch 37 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.37it/s]Epoch 37 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.40it/s]Epoch 37 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.42it/s]Epoch 37 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.41it/s]Epoch 37 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.37it/s]Epoch 37 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.38it/s]Epoch 37 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.38it/s]Epoch 37 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.37it/s]Epoch 37 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.36it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.37it/s]Epoch 37 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.36it/s]Epoch 37 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.34it/s]Epoch 37 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.35it/s]Epoch 37 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.31it/s]Epoch 37 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.29it/s]Epoch 37 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.31it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.31it/s]Epoch 37 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:03,  9.33it/s]Epoch 37 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.34it/s]Epoch 37 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.36it/s]Epoch 37 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.38it/s]Epoch 37 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 37 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.37it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 37 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 37 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.37it/s]Epoch 37 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.37it/s]Epoch 37 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.38it/s]Epoch 37 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 37 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.36it/s]Epoch 37 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.33it/s]Epoch 37 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.34it/s]Epoch 37 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.34it/s]Epoch 37 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.34it/s]Epoch 37 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.36it/s]Epoch 37 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.36it/s]Epoch 37 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.36it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.35it/s]Epoch 37 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.35it/s]Epoch 37 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.35it/s]Epoch 37 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.34it/s]Epoch 37 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.37it/s]Epoch 37 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.38it/s]Epoch 37 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.36it/s]                                                                 Epoch 37 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 37 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.91it/s]Epoch 37 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.02it/s]Epoch 37 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.10it/s]Epoch 37 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.18it/s]Epoch 37 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.19it/s]Epoch 37 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.23it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.79it/s]                                                               [2025-05-30 15:16:26,550][__main__][INFO] - Epoch 37: Val Loss: 0.7584, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5702970693428709, 'f1_weighted': 0.6775521357185631, 'precision_macro': 0.6541982323232324, 'recall_macro': 0.564348998459168}
Epoch 38 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:26,657][__main__][INFO] - Train Epoch: 38 [0/51 (0%)]	Loss: 0.420159
Epoch 38 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.49it/s]Epoch 38 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.43it/s]Epoch 38 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.40it/s]Epoch 38 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.42it/s]Epoch 38 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.39it/s]Epoch 38 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.40it/s]Epoch 38 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.26it/s]Epoch 38 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.33it/s]Epoch 38 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.35it/s]Epoch 38 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.41it/s]Epoch 38 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.39it/s]Epoch 38 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.41it/s]Epoch 38 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.41it/s]Epoch 38 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.41it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.44it/s]Epoch 38 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.46it/s]Epoch 38 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.45it/s]Epoch 38 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.43it/s]Epoch 38 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.45it/s]Epoch 38 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.47it/s]Epoch 38 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.50it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.50it/s]Epoch 38 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.50it/s]Epoch 38 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.48it/s]Epoch 38 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.46it/s]Epoch 38 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.46it/s]Epoch 38 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.46it/s]Epoch 38 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.44it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.45it/s]Epoch 38 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.42it/s]Epoch 38 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 38 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 38 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.41it/s]Epoch 38 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.41it/s]Epoch 38 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.41it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 38 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 38 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 38 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.36it/s]Epoch 38 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.35it/s]Epoch 38 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 38 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 38 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.36it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.37it/s]Epoch 38 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.39it/s]Epoch 38 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.37it/s]Epoch 38 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.33it/s]Epoch 38 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.35it/s]Epoch 38 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.38it/s]Epoch 38 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.35it/s]                                                                 Epoch 38 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 38 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.10it/s]Epoch 38 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.10it/s]Epoch 38 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.16it/s]Epoch 38 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.19it/s]Epoch 38 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.24it/s]Epoch 38 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.25it/s]                                                               [2025-05-30 15:16:33,179][__main__][INFO] - Epoch 38: Val Loss: 0.9062, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.5722756270842395, 'f1_weighted': 0.656990053072293, 'precision_macro': 0.7938172043010753, 'recall_macro': 0.5619607087827427}
Epoch 39 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:33,286][__main__][INFO] - Train Epoch: 39 [0/51 (0%)]	Loss: 0.143498
Epoch 39 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.52it/s]Epoch 39 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.18it/s]Epoch 39 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.29it/s]Epoch 39 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.35it/s]Epoch 39 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.36it/s]Epoch 39 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.36it/s]Epoch 39 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.40it/s]Epoch 39 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.41it/s]Epoch 39 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.38it/s]Epoch 39 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.39it/s]Epoch 39 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.41it/s]Epoch 39 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.40it/s]Epoch 39 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.38it/s]Epoch 39 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.38it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.37it/s]Epoch 39 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.35it/s]Epoch 39 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.31it/s]Epoch 39 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.34it/s]Epoch 39 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.36it/s]Epoch 39 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 39 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.36it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.35it/s]Epoch 39 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.38it/s]Epoch 39 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.35it/s]Epoch 39 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.34it/s]Epoch 39 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.35it/s]Epoch 39 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.36it/s]Epoch 39 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.34it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.34it/s]Epoch 39 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 39 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.32it/s]Epoch 39 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.31it/s]Epoch 39 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.33it/s]Epoch 39 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.35it/s]Epoch 39 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.33it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.34it/s]Epoch 39 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.36it/s]Epoch 39 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.37it/s]Epoch 39 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.35it/s]Epoch 39 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.35it/s]Epoch 39 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.36it/s]Epoch 39 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 39 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.33it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.34it/s]Epoch 39 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.37it/s]Epoch 39 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.36it/s]Epoch 39 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.35it/s]Epoch 39 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.34it/s]Epoch 39 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.37it/s]Epoch 39 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 39 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 39 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.14it/s]Epoch 39 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.15it/s]Epoch 39 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.22it/s]Epoch 39 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.23it/s]Epoch 39 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 39 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.27it/s]                                                               [2025-05-30 15:16:39,831][__main__][INFO] - Epoch 39: Val Loss: 0.7905, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6081022260912822, 'f1_weighted': 0.6826265389876882, 'precision_macro': 0.6545454545454545, 'recall_macro': 0.588828967642527}
Epoch 40 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:39,946][__main__][INFO] - Train Epoch: 40 [0/51 (0%)]	Loss: 0.308257
Epoch 40 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.14it/s]Epoch 40 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.03it/s]Epoch 40 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.24it/s]Epoch 40 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.32it/s]Epoch 40 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.37it/s]Epoch 40 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.43it/s]Epoch 40 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.49it/s]Epoch 40 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.50it/s]Epoch 40 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.46it/s]Epoch 40 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.43it/s]Epoch 40 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.42it/s]Epoch 40 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.44it/s]Epoch 40 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.42it/s]Epoch 40 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.40it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.40it/s]Epoch 40 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.40it/s]Epoch 40 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.39it/s]Epoch 40 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.39it/s]Epoch 40 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.39it/s]Epoch 40 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 40 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.37it/s]Epoch 40 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 40 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.42it/s]Epoch 40 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.41it/s]Epoch 40 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 40 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.41it/s]Epoch 40 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.41it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.41it/s]Epoch 40 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.36it/s]Epoch 40 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 40 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.40it/s]Epoch 40 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 40 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.33it/s]Epoch 40 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.36it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.38it/s]Epoch 40 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.38it/s]Epoch 40 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 40 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 40 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.40it/s]Epoch 40 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.40it/s]Epoch 40 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 40 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 40 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 40 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.36it/s]Epoch 40 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.37it/s]Epoch 40 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.38it/s]Epoch 40 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.36it/s]Epoch 40 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.36it/s]                                                                 Epoch 40 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 40 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.15it/s]Epoch 40 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.13it/s]Epoch 40 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.22it/s]Epoch 40 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.24it/s]Epoch 40 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 40 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:16:46,468][__main__][INFO] - Epoch 40: Val Loss: 1.0846, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.495687786448656, 'f1_weighted': 0.6142786798189295, 'precision_macro': 0.611820141883433, 'recall_macro': 0.5060862865947612}
Epoch 41 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:46,576][__main__][INFO] - Train Epoch: 41 [0/51 (0%)]	Loss: 0.931287
Epoch 41 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.46it/s]Epoch 41 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.11it/s]Epoch 41 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.28it/s]Epoch 41 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.34it/s]Epoch 41 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.36it/s]Epoch 41 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.39it/s]Epoch 41 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.42it/s]Epoch 41 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.44it/s]Epoch 41 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.42it/s]Epoch 41 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.42it/s]Epoch 41 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.42it/s]Epoch 41 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.43it/s]Epoch 41 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.41it/s]Epoch 41 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 41 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.39it/s]Epoch 41 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.40it/s]Epoch 41 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.39it/s]Epoch 41 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.40it/s]Epoch 41 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.37it/s]Epoch 41 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.38it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.32it/s]Epoch 41 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:03,  9.31it/s]Epoch 41 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.32it/s]Epoch 41 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.34it/s]Epoch 41 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.37it/s]Epoch 41 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 41 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.32it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.32it/s]Epoch 41 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.33it/s]Epoch 41 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.37it/s]Epoch 41 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.35it/s]Epoch 41 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.35it/s]Epoch 41 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.38it/s]Epoch 41 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.37it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 41 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.37it/s]Epoch 41 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.40it/s]Epoch 41 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.40it/s]Epoch 41 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 41 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 41 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.40it/s]Epoch 41 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.40it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.39it/s]Epoch 41 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.39it/s]Epoch 41 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 41 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.40it/s]Epoch 41 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.39it/s]Epoch 41 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.36it/s]Epoch 41 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.39it/s]                                                                 Epoch 41 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 41 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.98it/s]Epoch 41 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.09it/s]Epoch 41 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.17it/s]Epoch 41 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.24it/s]Epoch 41 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.26it/s]Epoch 41 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.29it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.83it/s]                                                               [2025-05-30 15:16:53,107][__main__][INFO] - Epoch 41: Val Loss: 0.8380, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5330532893032893, 'f1_weighted': 0.6387943922597389, 'precision_macro': 0.6288875598086124, 'recall_macro': 0.526848998459168}
Epoch 42 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:53,215][__main__][INFO] - Train Epoch: 42 [0/51 (0%)]	Loss: 0.784523
Epoch 42 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.44it/s]Epoch 42 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.13it/s]Epoch 42 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.22it/s]Epoch 42 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.26it/s]Epoch 42 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.32it/s]Epoch 42 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.36it/s]Epoch 42 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.38it/s]Epoch 42 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.42it/s]Epoch 42 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.44it/s]Epoch 42 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.48it/s]Epoch 42 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.51it/s]Epoch 42 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.53it/s]Epoch 42 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.50it/s]Epoch 42 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.51it/s]Epoch 42 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.52it/s]Epoch 42 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.54it/s]Epoch 42 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.53it/s]Epoch 42 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.50it/s]Epoch 42 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.47it/s]Epoch 42 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.46it/s]Epoch 42 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.43it/s]Epoch 42 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.44it/s]Epoch 42 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 42 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 42 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.41it/s]Epoch 42 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.40it/s]Epoch 42 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 42 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.38it/s]Epoch 42 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.38it/s]Epoch 42 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 42 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.36it/s]Epoch 42 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.37it/s]Epoch 42 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.37it/s]Epoch 42 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.38it/s]Epoch 42 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.36it/s]Epoch 42 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.37it/s]Epoch 42 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.39it/s]Epoch 42 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.36it/s]Epoch 42 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.35it/s]Epoch 42 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.37it/s]Epoch 42 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.33it/s]Epoch 42 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.33it/s]Epoch 42 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.33it/s]Epoch 42 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.36it/s]Epoch 42 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.36it/s]Epoch 42 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.34it/s]Epoch 42 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.35it/s]Epoch 42 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.38it/s]Epoch 42 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.39it/s]Epoch 42 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.38it/s]                                                                 Epoch 42 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 42 [Val]:   8%|‚ñä         | 1/13 [00:00<00:01,  9.96it/s]Epoch 42 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 10.07it/s]Epoch 42 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:00, 10.16it/s]Epoch 42 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:00<00:00, 10.24it/s]Epoch 42 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:00<00:00, 10.25it/s]Epoch 42 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:01<00:00, 10.29it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:01<00:00, 10.84it/s]                                                               [2025-05-30 15:16:59,733][__main__][INFO] - Epoch 42: Val Loss: 0.8655, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.6256438196941629, 'f1_weighted': 0.6966377056143012, 'precision_macro': 0.7004560530679933, 'recall_macro': 0.6095916795069337}
Epoch 43 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:16:59,847][__main__][INFO] - Train Epoch: 43 [0/51 (0%)]	Loss: 0.339367
Epoch 43 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  8.95it/s]Epoch 43 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  8.95it/s]Epoch 43 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.11it/s]Epoch 43 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.20it/s]Epoch 43 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.28it/s]Epoch 43 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.33it/s]Epoch 43 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.36it/s]Epoch 43 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.37it/s]Epoch 43 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.40it/s]Epoch 43 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.38it/s]Epoch 43 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.38it/s]Epoch 43 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.37it/s]Epoch 43 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.36it/s]Epoch 43 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.38it/s]Epoch 43 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.38it/s]Epoch 43 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.36it/s]Epoch 43 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.37it/s]Epoch 43 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.38it/s]Epoch 43 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.37it/s]Epoch 43 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.38it/s]Epoch 43 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.41it/s]Epoch 43 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.42it/s]Epoch 43 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.42it/s]Epoch 43 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.37it/s]Epoch 43 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.39it/s]Epoch 43 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.41it/s]Epoch 43 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 43 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.38it/s]Epoch 43 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.39it/s]Epoch 43 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.41it/s]Epoch 43 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.40it/s]Epoch 43 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.38it/s]Epoch 43 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.38it/s]Epoch 43 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 43 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 43 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.38it/s]Epoch 43 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.36it/s]Epoch 43 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.38it/s]Epoch 43 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.37it/s]Epoch 43 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.36it/s]Epoch 43 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.37it/s]Epoch 43 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 43 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.30it/s]Epoch 43 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.31it/s]Epoch 43 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.33it/s]Epoch 43 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.34it/s]Epoch 43 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.34it/s]Epoch 43 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.37it/s]Epoch 43 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.40it/s]Epoch 43 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.41it/s]                                                                 Epoch 43 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 43 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.17it/s]Epoch 43 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.22it/s]Epoch 43 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.24it/s]Epoch 43 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.28it/s]Epoch 43 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.28it/s]Epoch 43 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.30it/s]                                                               [2025-05-30 15:17:06,377][__main__][INFO] - Epoch 43: Val Loss: 0.8176, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.6183664327927191, 'f1_weighted': 0.6744815877276439, 'precision_macro': 0.6631138635375924, 'recall_macro': 0.6009052388289676}
Epoch 44 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:17:06,491][__main__][INFO] - Train Epoch: 44 [0/51 (0%)]	Loss: 0.432598
Epoch 44 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.12it/s]Epoch 44 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.02it/s]Epoch 44 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.19it/s]Epoch 44 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.31it/s]Epoch 44 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.37it/s]Epoch 44 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.37it/s]Epoch 44 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.37it/s]Epoch 44 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 44 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.40it/s]Epoch 44 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.38it/s]Epoch 44 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.37it/s]Epoch 44 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.37it/s]Epoch 44 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.39it/s]Epoch 44 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.38it/s]Epoch 44 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.36it/s]Epoch 44 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.38it/s]Epoch 44 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.38it/s]Epoch 44 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.35it/s]Epoch 44 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.35it/s]Epoch 44 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.36it/s]Epoch 44 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.41it/s]Epoch 44 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 44 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.35it/s]Epoch 44 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.37it/s]Epoch 44 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.38it/s]Epoch 44 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.37it/s]Epoch 44 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.38it/s]Epoch 44 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 44 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.40it/s]Epoch 44 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.38it/s]Epoch 44 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.38it/s]Epoch 44 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.39it/s]Epoch 44 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.40it/s]Epoch 44 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.39it/s]Epoch 44 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.39it/s]Epoch 44 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.40it/s]Epoch 44 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.41it/s]Epoch 44 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.39it/s]Epoch 44 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 44 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 44 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.41it/s]Epoch 44 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.37it/s]Epoch 44 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.38it/s]Epoch 44 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.38it/s]Epoch 44 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.41it/s]Epoch 44 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.39it/s]Epoch 44 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.38it/s]Epoch 44 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.40it/s]Epoch 44 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.42it/s]Epoch 44 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 44 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 44 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.14it/s]Epoch 44 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.16it/s]Epoch 44 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 44 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.26it/s]Epoch 44 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.28it/s]Epoch 44 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.27it/s]                                                               [2025-05-30 15:17:13,019][__main__][INFO] - Epoch 44: Val Loss: 0.8864, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.5628205128205128, 'f1_weighted': 0.6637725310992638, 'precision_macro': 0.6583786343793756, 'recall_macro': 0.5456471494607088}
Epoch 45 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:17:13,126][__main__][INFO] - Train Epoch: 45 [0/51 (0%)]	Loss: 0.619611
Epoch 45 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.36it/s]Epoch 45 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.13it/s]Epoch 45 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.25it/s]Epoch 45 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.29it/s]Epoch 45 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.33it/s]Epoch 45 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.34it/s]Epoch 45 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.35it/s]Epoch 45 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.39it/s]Epoch 45 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.39it/s]Epoch 45 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.39it/s]Epoch 45 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.40it/s]Epoch 45 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.42it/s]Epoch 45 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.42it/s]Epoch 45 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.39it/s]Epoch 45 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.40it/s]Epoch 45 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.41it/s]Epoch 45 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.41it/s]Epoch 45 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.41it/s]Epoch 45 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.41it/s]Epoch 45 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.42it/s]Epoch 45 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.42it/s]Epoch 45 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.42it/s]Epoch 45 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 45 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.41it/s]Epoch 45 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.41it/s]Epoch 45 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.39it/s]Epoch 45 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.39it/s]Epoch 45 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.39it/s]Epoch 45 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.42it/s]Epoch 45 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.41it/s]Epoch 45 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.37it/s]Epoch 45 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.38it/s]Epoch 45 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.38it/s]Epoch 45 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.38it/s]Epoch 45 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.38it/s]Epoch 45 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.40it/s]Epoch 45 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.40it/s]Epoch 45 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.36it/s]Epoch 45 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.36it/s]Epoch 45 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.35it/s]Epoch 45 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.34it/s]Epoch 45 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.33it/s]Epoch 45 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.35it/s]Epoch 45 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.37it/s]Epoch 45 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 45 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.37it/s]Epoch 45 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.37it/s]Epoch 45 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.39it/s]Epoch 45 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.38it/s]Epoch 45 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 45 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 45 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.16it/s]Epoch 45 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.19it/s]Epoch 45 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.25it/s]Epoch 45 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.27it/s]Epoch 45 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.30it/s]Epoch 45 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:17:19,654][__main__][INFO] - Epoch 45: Val Loss: 0.8519, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.5537538053931497, 'f1_weighted': 0.6431870173145939, 'precision_macro': 0.6220851370851371, 'recall_macro': 0.5596879815100154}
Epoch 46 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:17:19,762][__main__][INFO] - Train Epoch: 46 [0/51 (0%)]	Loss: 0.645786
Epoch 46 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.50it/s]Epoch 46 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.54it/s]Epoch 46 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.41it/s]Epoch 46 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.46it/s]Epoch 46 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.47it/s]Epoch 46 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.51it/s]Epoch 46 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.48it/s]Epoch 46 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.46it/s]Epoch 46 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.45it/s]Epoch 46 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.46it/s]Epoch 46 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.45it/s]Epoch 46 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.45it/s]Epoch 46 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.45it/s]Epoch 46 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.44it/s]Epoch 46 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.41it/s]Epoch 46 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.39it/s]Epoch 46 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.37it/s]Epoch 46 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.38it/s]Epoch 46 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.40it/s]Epoch 46 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.40it/s]Epoch 46 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.36it/s]Epoch 46 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.38it/s]Epoch 46 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.40it/s]Epoch 46 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.40it/s]Epoch 46 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.24it/s]Epoch 46 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.29it/s]Epoch 46 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.30it/s]Epoch 46 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.31it/s]Epoch 46 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.35it/s]Epoch 46 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.37it/s]Epoch 46 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.34it/s]Epoch 46 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.34it/s]Epoch 46 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.35it/s]Epoch 46 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.33it/s]Epoch 46 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.34it/s]Epoch 46 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.36it/s]Epoch 46 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.37it/s]Epoch 46 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.36it/s]Epoch 46 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.35it/s]Epoch 46 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.37it/s]Epoch 46 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.40it/s]Epoch 46 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.38it/s]Epoch 46 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.35it/s]Epoch 46 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.35it/s]Epoch 46 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.37it/s]Epoch 46 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.35it/s]Epoch 46 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  9.36it/s]Epoch 46 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.35it/s]Epoch 46 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.36it/s]Epoch 46 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.34it/s]                                                                 Epoch 46 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 46 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.17it/s]Epoch 46 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.12it/s]Epoch 46 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.20it/s]Epoch 46 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.21it/s]Epoch 46 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.25it/s]Epoch 46 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.24it/s]                                                               [2025-05-30 15:17:26,294][__main__][INFO] - Epoch 46: Val Loss: 0.8152, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.6043438416422288, 'f1_weighted': 0.6713110827211755, 'precision_macro': 0.6516608391608392, 'recall_macro': 0.5886171032357473}
Epoch 47 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:17:26,402][__main__][INFO] - Train Epoch: 47 [0/51 (0%)]	Loss: 0.789219
Epoch 47 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.51it/s]Epoch 47 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.47it/s]Epoch 47 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.48it/s]Epoch 47 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.49it/s]Epoch 47 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.49it/s]Epoch 47 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.49it/s]Epoch 47 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.48it/s]Epoch 47 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.49it/s]Epoch 47 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.49it/s]Epoch 47 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.51it/s]Epoch 47 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.51it/s]Epoch 47 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.50it/s]Epoch 47 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.50it/s]Epoch 47 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.49it/s]Epoch 47 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.50it/s]Epoch 47 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.47it/s]Epoch 47 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.46it/s]Epoch 47 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.48it/s]Epoch 47 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.47it/s]Epoch 47 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.49it/s]Epoch 47 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.48it/s]Epoch 47 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.46it/s]Epoch 47 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.46it/s]Epoch 47 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.46it/s]Epoch 47 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.45it/s]Epoch 47 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.42it/s]Epoch 47 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.42it/s]Epoch 47 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.41it/s]Epoch 47 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.41it/s]Epoch 47 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.37it/s]Epoch 47 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.37it/s]Epoch 47 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.37it/s]Epoch 47 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.38it/s]Epoch 47 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.35it/s]Epoch 47 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.33it/s]Epoch 47 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.35it/s]Epoch 47 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.33it/s]Epoch 47 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:04<00:01,  9.36it/s]Epoch 47 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.38it/s]Epoch 47 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.39it/s]Epoch 47 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.38it/s]Epoch 47 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.39it/s]Epoch 47 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.40it/s]Epoch 47 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.39it/s]Epoch 47 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.38it/s]Epoch 47 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.38it/s]Epoch 47 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.37it/s]Epoch 47 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  9.38it/s]Epoch 47 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.37it/s]Epoch 47 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.37it/s]                                                                 Epoch 47 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 47 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.20it/s]Epoch 47 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.12it/s]Epoch 47 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.18it/s]Epoch 47 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.22it/s]Epoch 47 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.26it/s]Epoch 47 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.28it/s]                                                               [2025-05-30 15:17:32,907][__main__][INFO] - Epoch 47: Val Loss: 0.8163, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.5648066485753053, 'f1_weighted': 0.6576400177331166, 'precision_macro': 0.6312121212121212, 'recall_macro': 0.5495762711864407}
[2025-05-30 15:17:32,909][__main__][INFO] - Early stopping triggered after 47 epochs
[2025-05-30 15:17:32,909][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7129
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f5f35d80>
<numpy.flatiter object at 0x7f36f5f35d80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37492c5c40>
<numpy.flatiter object at 0x7f37492c5c40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492c5c40>
<numpy.flatiter object at 0x7f37492c5c40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37492c6240>
<numpy.flatiter object at 0x7f37492c6240>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492c6240>
<numpy.flatiter object at 0x7f37492c6240>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
wandb:        Validation Accuracy ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:            Validation Loss ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb:        Validation accuracy ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:        Validation f1_macro ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá
wandb:     Validation f1_weighted ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà
wandb: Validation precision_macro ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.71287
wandb:                 Train Loss 0.78922
wandb:        Validation Accuracy 0.69307
wandb:            Validation Loss 0.81632
wandb:        Validation accuracy 0.69307
wandb:        Validation f1_macro 0.56481
wandb:     Validation f1_weighted 0.65764
wandb: Validation precision_macro 0.63121
wandb:    Validation recall_macro 0.54958
wandb: 
wandb: üöÄ View run chocolate-sweep-4 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/cwr0mgvm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 7 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_151207-cwr0mgvm/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ovqesxlh with config:
wandb: 	Fdropout_rate: 0.10362742739109096
wandb: 	Fnum_heads: 1
wandb: 	Fnum_layers: 1
wandb: 	Mdropout_rate: 0.2869486184265002
wandb: 	Mnum_layers: 2
wandb: 	batch_size: 16
wandb: 	learning_rate: 0.01989597349677291
wandb: 	pretrained_model_name: nvidia/biomegatron-345m-uncased
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_151746-ovqesxlh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/ovqesxlh
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
wandb:                                                                                
wandb: üöÄ View run splendid-sweep-5 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/ovqesxlh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_151746-ovqesxlh/logs
wandb: ERROR Run ovqesxlh errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 406, in hf_raise_for_status
wandb: ERROR     response.raise_for_status()
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
wandb: ERROR     raise HTTPError(http_error_msg, response=self)
wandb: ERROR requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 342, in cached_file
wandb: ERROR     resolved_file = hf_hub_download(
wandb: ERROR                     ^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
wandb: ERROR     return _hf_hub_download_to_cache_dir(
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
wandb: ERROR     _raise_on_head_call_error(head_call_error, force_download, local_files_only)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1482, in _raise_on_head_call_error
wandb: ERROR     raise head_call_error
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
wandb: ERROR     metadata = get_hf_file_metadata(
wandb: ERROR                ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
wandb: ERROR     r = _request_wrapper(
wandb: ERROR         ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
wandb: ERROR     response = _request_wrapper(
wandb: ERROR                ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 302, in _request_wrapper
wandb: ERROR     hf_raise_for_status(response)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 454, in hf_raise_for_status
wandb: ERROR     raise _format(RepositoryNotFoundError, message, response) from e
wandb: ERROR huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-68394d8b-1cbbff6960546fad1de86fda;5a9ee3f1-ea38-4bf0-b15d-ebbaee80ff26)
wandb: ERROR 
wandb: ERROR Repository Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json.
wandb: ERROR Please make sure you specified the correct `repo_id` and `repo_type`.
wandb: ERROR If you are trying to access a private or gated repo, make sure you are authenticated.
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
wandb: ERROR     return _target_(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/src/data/dataset.py", line 155, in __init__
wandb: ERROR     self.tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 881, in from_pretrained
wandb: ERROR     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
wandb: ERROR                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 713, in get_tokenizer_config
wandb: ERROR     resolved_config_file = cached_file(
wandb: ERROR                            ^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 365, in cached_file
wandb: ERROR     raise EnvironmentError(
wandb: ERROR OSError: nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
wandb: ERROR If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 299, in sweep_train
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 54, in train
wandb: ERROR     train_dataset = hydra.utils.instantiate(config.data.caller, data = train_data)
wandb: ERROR                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
wandb: ERROR     return instantiate_node(
wandb: ERROR            ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
wandb: ERROR     return _call_target(_target_, partial, args, kwargs, full_key)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
wandb: ERROR     raise InstantiationException(msg) from e
wandb: ERROR hydra.errors.InstantiationException: Error in call to target 'src.data.dataset.TBIDataset2stream':
wandb: ERROR OSError("nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`")
wandb: ERROR full_key: default_sweep.data.caller
wandb: ERROR 
wandb: Agent Starting Run: 8xcy0suj with config:
wandb: 	Fdropout_rate: 0.4115747386900577
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 1
wandb: 	Mdropout_rate: 0.17821544870961714
wandb: 	Mnum_layers: 1
wandb: 	batch_size: 4
wandb: 	learning_rate: 0.03213433976782025
wandb: 	pretrained_model_name: dmis-lab/biobert-base-cased-v1.1
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_151752-8xcy0suj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/8xcy0suj
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Training started...
Epoch 0 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:17:56,637][__main__][INFO] - Train Epoch: 0 [0/101 (0%)]	Loss: 1.473122
Epoch 0 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.38it/s]Epoch 0 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.67it/s]Epoch 0 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.32it/s]Epoch 0 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.61it/s]Epoch 0 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.32it/s]Epoch 0 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.52it/s]Epoch 0 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.47it/s]Epoch 0 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.61it/s]Epoch 0 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.75it/s]Epoch 0 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.83it/s]Epoch 0 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.84it/s]Epoch 0 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.71it/s]Epoch 0 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.64it/s]Epoch 0 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.63it/s]Epoch 0 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.64it/s]Epoch 0 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.65it/s]Epoch 0 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.68it/s]Epoch 0 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.70it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.74it/s]Epoch 0 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.75it/s]Epoch 0 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.77it/s]Epoch 0 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.76it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.74it/s]Epoch 0 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.68it/s]Epoch 0 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.68it/s]Epoch 0 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.68it/s]Epoch 0 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.67it/s]Epoch 0 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.71it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.75it/s]Epoch 0 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.72it/s]Epoch 0 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.71it/s]Epoch 0 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.77it/s]Epoch 0 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.72it/s]Epoch 0 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.68it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.64it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.62it/s]Epoch 0 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.65it/s]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.69it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.72it/s]Epoch 0 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.77it/s]Epoch 0 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.79it/s]Epoch 0 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.79it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.78it/s]Epoch 0 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.77it/s]Epoch 0 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.70it/s]Epoch 0 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.72it/s]Epoch 0 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.75it/s]Epoch 0 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.77it/s]Epoch 0 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.79it/s]Epoch 0 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:05<00:00, 16.78it/s][2025-05-30 15:18:02,618][__main__][INFO] - Train Epoch: 0 [100/101 (99%)]	Loss: 2.226707
                                                                  Epoch 0 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 0 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 18.02it/s]Epoch 0 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.96it/s]Epoch 0 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.89it/s]Epoch 0 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.89it/s]Epoch 0 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.98it/s]Epoch 0 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 18.08it/s]Epoch 0 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.10it/s]Epoch 0 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.17it/s]Epoch 0 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:00<00:00, 18.19it/s]Epoch 0 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.24it/s]Epoch 0 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.23it/s]Epoch 0 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.23it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:04,033][__main__][INFO] - Epoch 0: Val Loss: 1.2026, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38122b63c0>
<numpy.flatiter object at 0x7f38122bcb40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702d09880>
<numpy.flatiter object at 0x7f3702d09880>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702d09880>
<numpy.flatiter object at 0x7f3702d09880>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702d09e80>
<numpy.flatiter object at 0x7f3702d09e80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702d09e80>
<numpy.flatiter object at 0x7f3702d09e80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:18:04,092][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:18:04,206][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:18:04,238][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:04,298][__main__][INFO] - Train Epoch: 1 [0/101 (0%)]	Loss: 1.287750
Epoch 1 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 17.16it/s]Epoch 1 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 17.05it/s]Epoch 1 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 17.05it/s]Epoch 1 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 17.09it/s]Epoch 1 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 17.13it/s]Epoch 1 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 17.13it/s]Epoch 1 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.99it/s]Epoch 1 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.83it/s]Epoch 1 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.79it/s]Epoch 1 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.75it/s]Epoch 1 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.72it/s]Epoch 1 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.70it/s]Epoch 1 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.71it/s]Epoch 1 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.75it/s]Epoch 1 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.79it/s]Epoch 1 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.78it/s]Epoch 1 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.73it/s]Epoch 1 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.71it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.67it/s]Epoch 1 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.64it/s]Epoch 1 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.68it/s]Epoch 1 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.26it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.41it/s]Epoch 1 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.48it/s]Epoch 1 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:02<00:03, 16.50it/s]Epoch 1 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.52it/s]Epoch 1 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.56it/s]Epoch 1 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.58it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.59it/s]Epoch 1 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.63it/s]Epoch 1 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.24it/s]Epoch 1 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.32it/s]Epoch 1 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.37it/s]Epoch 1 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.44it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.49it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.54it/s]Epoch 1 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.60it/s]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.66it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.68it/s]Epoch 1 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.71it/s]Epoch 1 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.73it/s]Epoch 1 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.67it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.66it/s]Epoch 1 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.65it/s]Epoch 1 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.61it/s]Epoch 1 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.59it/s]Epoch 1 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.59it/s]Epoch 1 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.62it/s]Epoch 1 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.64it/s]Epoch 1 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.63it/s][2025-05-30 15:18:10,294][__main__][INFO] - Train Epoch: 1 [100/101 (99%)]	Loss: 1.016793
                                                                  Epoch 1 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 1 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.47it/s]Epoch 1 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.72it/s]Epoch 1 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.74it/s]Epoch 1 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.75it/s]Epoch 1 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.83it/s]Epoch 1 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.99it/s]Epoch 1 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.03it/s]Epoch 1 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.11it/s]Epoch 1 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.14it/s]Epoch 1 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.18it/s]Epoch 1 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.18it/s]Epoch 1 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.17it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:11,715][__main__][INFO] - Epoch 1: Val Loss: 1.1148, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2673611111111111, 'f1_weighted': 0.5174642464246424, 'precision_macro': 0.2457720588235294, 'recall_macro': 0.3040254237288136}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811803960>
<numpy.flatiter object at 0x7f3811803960>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38122bcb40>
<numpy.flatiter object at 0x7f3748799900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811792930>
<numpy.flatiter object at 0x7f38121f1ec0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38122bcb40>
<numpy.flatiter object at 0x7f3748799900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811792930>
<numpy.flatiter object at 0x7f38121f1ec0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:18:11,783][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.6139
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:18:11,878][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:11,971][__main__][INFO] - Train Epoch: 2 [0/101 (0%)]	Loss: 1.322483
Epoch 2 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 16.08it/s]Epoch 2 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.46it/s]Epoch 2 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.63it/s]Epoch 2 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.65it/s]Epoch 2 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.70it/s]Epoch 2 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.72it/s]Epoch 2 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.76it/s]Epoch 2 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.73it/s]Epoch 2 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.65it/s]Epoch 2 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.62it/s]Epoch 2 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.63it/s]Epoch 2 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.58it/s]Epoch 2 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.56it/s]Epoch 2 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.58it/s]Epoch 2 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.57it/s]Epoch 2 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.58it/s]Epoch 2 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.54it/s]Epoch 2 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.57it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.61it/s]Epoch 2 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.53it/s]Epoch 2 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.56it/s]Epoch 2 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.61it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.66it/s]Epoch 2 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.65it/s]Epoch 2 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.46it/s]Epoch 2 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.53it/s]Epoch 2 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.60it/s]Epoch 2 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.63it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.63it/s]Epoch 2 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.61it/s]Epoch 2 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.57it/s]Epoch 2 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.52it/s]Epoch 2 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.55it/s]Epoch 2 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.54it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.57it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.57it/s]Epoch 2 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.62it/s]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.64it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.65it/s]Epoch 2 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.65it/s]Epoch 2 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.68it/s]Epoch 2 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.70it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.69it/s]Epoch 2 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.69it/s]Epoch 2 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.66it/s]Epoch 2 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.56it/s]Epoch 2 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.55it/s]Epoch 2 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.56it/s]Epoch 2 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.56it/s]Epoch 2 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.55it/s][2025-05-30 15:18:17,988][__main__][INFO] - Train Epoch: 2 [100/101 (99%)]	Loss: 0.401575
                                                                  Epoch 2 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 2 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.23it/s]Epoch 2 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.72it/s]Epoch 2 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.70it/s]Epoch 2 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.92it/s]Epoch 2 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 18.01it/s]Epoch 2 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 18.10it/s]Epoch 2 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.14it/s]Epoch 2 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.18it/s]Epoch 2 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:00<00:00, 18.22it/s]Epoch 2 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.21it/s]Epoch 2 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.20it/s]Epoch 2 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.20it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:19,408][__main__][INFO] - Epoch 2: Val Loss: 0.7998, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4534722222222222, 'f1_weighted': 0.5935918591859185, 'precision_macro': 0.49701213818860873, 'recall_macro': 0.4608436055469954}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f46a8100>
<numpy.flatiter object at 0x7f36f46a8100>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3753bf3180>
<numpy.flatiter object at 0x7f3753bf3180>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3753bf3180>
<numpy.flatiter object at 0x7f3753bf3180>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f5f49080>
<numpy.flatiter object at 0x7f36f5f49080>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5f49080>
<numpy.flatiter object at 0x7f36f5f49080>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:18:19,475][__main__][INFO] - Saved best model at epoch 2 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:18:19,573][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 3 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:19,666][__main__][INFO] - Train Epoch: 3 [0/101 (0%)]	Loss: 0.606687
Epoch 3 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.79it/s]Epoch 3 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.75it/s]Epoch 3 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.22it/s]Epoch 3 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.45it/s]Epoch 3 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.58it/s]Epoch 3 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.58it/s]Epoch 3 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.59it/s]Epoch 3 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.54it/s]Epoch 3 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.57it/s]Epoch 3 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.59it/s]Epoch 3 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.58it/s]Epoch 3 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.58it/s]Epoch 3 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.57it/s]Epoch 3 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.61it/s]Epoch 3 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.62it/s]Epoch 3 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.66it/s]Epoch 3 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.64it/s]Epoch 3 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.69it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.70it/s]Epoch 3 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.70it/s]Epoch 3 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.71it/s]Epoch 3 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.67it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.61it/s]Epoch 3 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.56it/s]Epoch 3 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.55it/s]Epoch 3 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.55it/s]Epoch 3 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.54it/s]Epoch 3 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.55it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.53it/s]Epoch 3 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.44it/s]Epoch 3 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.50it/s]Epoch 3 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.53it/s]Epoch 3 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.56it/s]Epoch 3 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.58it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.60it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.62it/s]Epoch 3 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.64it/s]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.68it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.69it/s]Epoch 3 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.67it/s]Epoch 3 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.64it/s]Epoch 3 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.65it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.61it/s]Epoch 3 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.57it/s]Epoch 3 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.55it/s]Epoch 3 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.59it/s]Epoch 3 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.60it/s]Epoch 3 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.61it/s]Epoch 3 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.63it/s]Epoch 3 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.65it/s][2025-05-30 15:18:25,681][__main__][INFO] - Train Epoch: 3 [100/101 (99%)]	Loss: 0.595391
                                                                  Epoch 3 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 3 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.73it/s]Epoch 3 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.81it/s]Epoch 3 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.74it/s]Epoch 3 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.76it/s]Epoch 3 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.91it/s]Epoch 3 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 18.05it/s]Epoch 3 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.09it/s]Epoch 3 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.13it/s]Epoch 3 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:00<00:00, 18.13it/s]Epoch 3 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.19it/s]Epoch 3 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.23it/s]Epoch 3 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.18it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:27,099][__main__][INFO] - Epoch 3: Val Loss: 0.9734, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.22650375939849626, 'f1_weighted': 0.4740936499665004, 'precision_macro': 0.21841397849462366, 'recall_macro': 0.2707627118644068}
Epoch 4 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:27,169][__main__][INFO] - Train Epoch: 4 [0/101 (0%)]	Loss: 0.773178
Epoch 4 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.76it/s]Epoch 4 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.41it/s]Epoch 4 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.52it/s]Epoch 4 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.57it/s]Epoch 4 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.55it/s]Epoch 4 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.55it/s]Epoch 4 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.59it/s]Epoch 4 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.58it/s]Epoch 4 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.57it/s]Epoch 4 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.56it/s]Epoch 4 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.48it/s]Epoch 4 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.51it/s]Epoch 4 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.47it/s]Epoch 4 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.50it/s]Epoch 4 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.52it/s]Epoch 4 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.53it/s]Epoch 4 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.54it/s]Epoch 4 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.57it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.60it/s]Epoch 4 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.59it/s]Epoch 4 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.59it/s]Epoch 4 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.65it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.64it/s]Epoch 4 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.68it/s]Epoch 4 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.66it/s]Epoch 4 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.68it/s]Epoch 4 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.68it/s]Epoch 4 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.66it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.62it/s]Epoch 4 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.56it/s]Epoch 4 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.54it/s]Epoch 4 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.57it/s]Epoch 4 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.56it/s]Epoch 4 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.58it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.61it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.62it/s]Epoch 4 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.64it/s]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.66it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.58it/s]Epoch 4 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.60it/s]Epoch 4 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.59it/s]Epoch 4 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.59it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.58it/s]Epoch 4 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.57it/s]Epoch 4 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.54it/s]Epoch 4 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.55it/s]Epoch 4 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.59it/s]Epoch 4 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.60it/s]Epoch 4 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.63it/s]Epoch 4 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.65it/s][2025-05-30 15:18:33,182][__main__][INFO] - Train Epoch: 4 [100/101 (99%)]	Loss: 0.293725
                                                                  Epoch 4 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 4 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.23it/s]Epoch 4 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.55it/s]Epoch 4 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.58it/s]Epoch 4 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.45it/s]Epoch 4 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.71it/s]Epoch 4 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.82it/s]Epoch 4 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.93it/s]Epoch 4 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.96it/s]Epoch 4 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.05it/s]Epoch 4 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.05it/s]Epoch 4 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.07it/s]Epoch 4 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.06it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:34,617][__main__][INFO] - Epoch 4: Val Loss: 0.9441, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.34506302521008403, 'f1_weighted': 0.5347158665446377, 'precision_macro': 0.28273809523809523, 'recall_macro': 0.46032357473035435}
Epoch 5 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:34,678][__main__][INFO] - Train Epoch: 5 [0/101 (0%)]	Loss: 0.182904
Epoch 5 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 17.09it/s]Epoch 5 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 17.10it/s]Epoch 5 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 17.09it/s]Epoch 5 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 17.10it/s]Epoch 5 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 17.09it/s]Epoch 5 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 17.09it/s]Epoch 5 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 17.09it/s]Epoch 5 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.98it/s]Epoch 5 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.97it/s]Epoch 5 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.89it/s]Epoch 5 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.83it/s]Epoch 5 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.80it/s]Epoch 5 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.78it/s]Epoch 5 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.76it/s]Epoch 5 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.72it/s]Epoch 5 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.67it/s]Epoch 5 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.67it/s]Epoch 5 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.68it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.67it/s]Epoch 5 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.63it/s]Epoch 5 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.54it/s]Epoch 5 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.52it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.51it/s]Epoch 5 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.52it/s]Epoch 5 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:02<00:03, 16.52it/s]Epoch 5 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.51it/s]Epoch 5 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.51it/s]Epoch 5 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.52it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.50it/s]Epoch 5 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.49it/s]Epoch 5 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.52it/s]Epoch 5 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.55it/s]Epoch 5 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.54it/s]Epoch 5 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.57it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.59it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.44it/s]Epoch 5 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.46it/s]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.51it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.51it/s]Epoch 5 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.54it/s]Epoch 5 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.58it/s]Epoch 5 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.57it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.55it/s]Epoch 5 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.60it/s]Epoch 5 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.64it/s]Epoch 5 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.65it/s]Epoch 5 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.64it/s]Epoch 5 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.61it/s]Epoch 5 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.60it/s]Epoch 5 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.59it/s][2025-05-30 15:18:40,673][__main__][INFO] - Train Epoch: 5 [100/101 (99%)]	Loss: 1.324101
                                                                  Epoch 5 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 5 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.87it/s]Epoch 5 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.81it/s]Epoch 5 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.75it/s]Epoch 5 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.82it/s]Epoch 5 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.97it/s]Epoch 5 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 18.01it/s]Epoch 5 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.05it/s]Epoch 5 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.08it/s]Epoch 5 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.08it/s]Epoch 5 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.10it/s]Epoch 5 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.11it/s]Epoch 5 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.11it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:42,094][__main__][INFO] - Epoch 5: Val Loss: 1.0333, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.30646005300383183, 'f1_weighted': 0.520030531437202, 'precision_macro': 0.4602272727272727, 'recall_macro': 0.3162172573189523}
Epoch 6 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:42,155][__main__][INFO] - Train Epoch: 6 [0/101 (0%)]	Loss: 0.567981
Epoch 6 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.99it/s]Epoch 6 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.90it/s]Epoch 6 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.80it/s]Epoch 6 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.69it/s]Epoch 6 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.67it/s]Epoch 6 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.65it/s]Epoch 6 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.61it/s]Epoch 6 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.63it/s]Epoch 6 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.61it/s]Epoch 6 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.63it/s]Epoch 6 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.64it/s]Epoch 6 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.59it/s]Epoch 6 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.56it/s]Epoch 6 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.58it/s]Epoch 6 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.59it/s]Epoch 6 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.62it/s]Epoch 6 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.52it/s]Epoch 6 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.59it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.59it/s]Epoch 6 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.57it/s]Epoch 6 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.55it/s]Epoch 6 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.59it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.52it/s]Epoch 6 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.52it/s]Epoch 6 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.47it/s]Epoch 6 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.54it/s]Epoch 6 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.57it/s]Epoch 6 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.58it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.55it/s]Epoch 6 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.56it/s]Epoch 6 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.55it/s]Epoch 6 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.52it/s]Epoch 6 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.47it/s]Epoch 6 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.47it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.47it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.49it/s]Epoch 6 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.49it/s]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.48it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.48it/s]Epoch 6 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.48it/s]Epoch 6 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.48it/s]Epoch 6 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.50it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.51it/s]Epoch 6 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.53it/s]Epoch 6 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.50it/s]Epoch 6 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.53it/s]Epoch 6 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.55it/s]Epoch 6 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.59it/s]Epoch 6 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.61it/s]Epoch 6 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.63it/s][2025-05-30 15:18:48,182][__main__][INFO] - Train Epoch: 6 [100/101 (99%)]	Loss: 0.371355
                                                                  Epoch 6 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 6 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.84it/s]Epoch 6 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.84it/s]Epoch 6 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.71it/s]Epoch 6 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.82it/s]Epoch 6 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.93it/s]Epoch 6 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 18.05it/s]Epoch 6 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.03it/s]Epoch 6 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.02it/s]Epoch 6 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.05it/s]Epoch 6 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.91it/s]Epoch 6 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.00it/s]Epoch 6 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.05it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:49,608][__main__][INFO] - Epoch 6: Val Loss: 0.8930, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.38317634746206175, 'f1_weighted': 0.5488080990202632, 'precision_macro': 0.4207251082251082, 'recall_macro': 0.39462634822804316}
Epoch 7 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:49,669][__main__][INFO] - Train Epoch: 7 [0/101 (0%)]	Loss: 0.572105
Epoch 7 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 17.03it/s]Epoch 7 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.87it/s]Epoch 7 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.85it/s]Epoch 7 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.92it/s]Epoch 7 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.99it/s]Epoch 7 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 17.03it/s]Epoch 7 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 17.01it/s]Epoch 7 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.99it/s]Epoch 7 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 17.01it/s]Epoch 7 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 17.00it/s]Epoch 7 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.99it/s]Epoch 7 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.92it/s]Epoch 7 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.91it/s]Epoch 7 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.93it/s]Epoch 7 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.93it/s]Epoch 7 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.98it/s]Epoch 7 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:03, 16.96it/s]Epoch 7 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.90it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.85it/s]Epoch 7 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.91it/s]Epoch 7 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.95it/s]Epoch 7 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.96it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.96it/s]Epoch 7 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.97it/s]Epoch 7 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:02<00:03, 16.98it/s]Epoch 7 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.98it/s]Epoch 7 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 17.02it/s]Epoch 7 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.97it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.95it/s]Epoch 7 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.85it/s]Epoch 7 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.81it/s]Epoch 7 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.75it/s]Epoch 7 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.71it/s]Epoch 7 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.68it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.66it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.65it/s]Epoch 7 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.63it/s]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.64it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.64it/s]Epoch 7 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.62it/s]Epoch 7 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.62it/s]Epoch 7 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:04<00:01, 16.59it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.54it/s]Epoch 7 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.53it/s]Epoch 7 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.52it/s]Epoch 7 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.52it/s]Epoch 7 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.51it/s]Epoch 7 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.50it/s]Epoch 7 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.49it/s]Epoch 7 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:05<00:00, 16.46it/s][2025-05-30 15:18:55,617][__main__][INFO] - Train Epoch: 7 [100/101 (99%)]	Loss: 0.546545
                                                                  Epoch 7 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 7 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.79it/s]Epoch 7 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.76it/s]Epoch 7 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.71it/s]Epoch 7 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.70it/s]Epoch 7 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.85it/s]Epoch 7 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.96it/s]Epoch 7 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 18.02it/s]Epoch 7 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 18.02it/s]Epoch 7 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.07it/s]Epoch 7 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.06it/s]Epoch 7 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.08it/s]Epoch 7 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.10it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:18:57,042][__main__][INFO] - Epoch 7: Val Loss: 0.8495, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.4222728528030931, 'f1_weighted': 0.5969473997938319, 'precision_macro': 0.5288296041308089, 'recall_macro': 0.4074345146379045}
Epoch 8 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:18:57,104][__main__][INFO] - Train Epoch: 8 [0/101 (0%)]	Loss: 0.249274
Epoch 8 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.98it/s]Epoch 8 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 17.02it/s]Epoch 8 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 17.03it/s]Epoch 8 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 17.02it/s]Epoch 8 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.96it/s]Epoch 8 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.91it/s]Epoch 8 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.88it/s]Epoch 8 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.89it/s]Epoch 8 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.94it/s]Epoch 8 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.98it/s]Epoch 8 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.95it/s]Epoch 8 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.97it/s]Epoch 8 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.90it/s]Epoch 8 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.81it/s]Epoch 8 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.76it/s]Epoch 8 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.68it/s]Epoch 8 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.32it/s]Epoch 8 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.41it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.41it/s]Epoch 8 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.43it/s]Epoch 8 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.44it/s]Epoch 8 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.46it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.46it/s]Epoch 8 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.45it/s]Epoch 8 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:02<00:03, 16.47it/s]Epoch 8 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.50it/s]Epoch 8 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.53it/s]Epoch 8 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.48it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.47it/s]Epoch 8 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.50it/s]Epoch 8 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.49it/s]Epoch 8 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.52it/s]Epoch 8 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.54it/s]Epoch 8 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.54it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.52it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.53it/s]Epoch 8 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.53it/s]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.56it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.55it/s]Epoch 8 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.55it/s]Epoch 8 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.53it/s]Epoch 8 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.53it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.49it/s]Epoch 8 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.49it/s]Epoch 8 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.47it/s]Epoch 8 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.49it/s]Epoch 8 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.50it/s]Epoch 8 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.47it/s]Epoch 8 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.42it/s]Epoch 8 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.08it/s][2025-05-30 15:19:03,129][__main__][INFO] - Train Epoch: 8 [100/101 (99%)]	Loss: 0.779843
                                                                  Epoch 8 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 8 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.31it/s]Epoch 8 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.53it/s]Epoch 8 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.50it/s]Epoch 8 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.59it/s]Epoch 8 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.76it/s]Epoch 8 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.84it/s]Epoch 8 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.92it/s]Epoch 8 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.92it/s]Epoch 8 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.96it/s]Epoch 8 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.97it/s]Epoch 8 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.00it/s]Epoch 8 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.00it/s]                                                              [2025-05-30 15:19:04,565][__main__][INFO] - Epoch 8: Val Loss: 0.8603, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.46061253561253557, 'f1_weighted': 0.6406391921243407, 'precision_macro': 0.5157894736842106, 'recall_macro': 0.4531972265023113}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703391280>
<numpy.flatiter object at 0x7f3703391280>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703379300>
<numpy.flatiter object at 0x7f3703379300>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703379300>
<numpy.flatiter object at 0x7f3703379300>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703379900>
<numpy.flatiter object at 0x7f3703379900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703379900>
<numpy.flatiter object at 0x7f3703379900>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:19:04,632][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.6931
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:19:04,730][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:04,824][__main__][INFO] - Train Epoch: 9 [0/101 (0%)]	Loss: 0.528720
Epoch 9 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.68it/s]Epoch 9 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 16.11it/s]Epoch 9 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.18it/s]Epoch 9 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.36it/s]Epoch 9 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.46it/s]Epoch 9 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.52it/s]Epoch 9 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.56it/s]Epoch 9 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.51it/s]Epoch 9 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.55it/s]Epoch 9 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.55it/s]Epoch 9 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.56it/s]Epoch 9 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.59it/s]Epoch 9 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.57it/s]Epoch 9 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.58it/s]Epoch 9 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.60it/s]Epoch 9 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.63it/s]Epoch 9 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.60it/s]Epoch 9 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.59it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.56it/s]Epoch 9 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.49it/s]Epoch 9 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.45it/s]Epoch 9 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.49it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.49it/s]Epoch 9 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.46it/s]Epoch 9 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.45it/s]Epoch 9 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.47it/s]Epoch 9 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.47it/s]Epoch 9 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.46it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.46it/s]Epoch 9 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.47it/s]Epoch 9 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.45it/s]Epoch 9 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.46it/s]Epoch 9 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.47it/s]Epoch 9 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.46it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.44it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.46it/s]Epoch 9 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.48it/s]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.43it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.43it/s]Epoch 9 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.44it/s]Epoch 9 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.44it/s]Epoch 9 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.47it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.46it/s]Epoch 9 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.46it/s]Epoch 9 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.39it/s]Epoch 9 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.43it/s]Epoch 9 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.46it/s]Epoch 9 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.43it/s]Epoch 9 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.44it/s]Epoch 9 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.47it/s][2025-05-30 15:19:10,881][__main__][INFO] - Train Epoch: 9 [100/101 (99%)]	Loss: 0.607495
                                                                  Epoch 9 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 9 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.57it/s]Epoch 9 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.63it/s]Epoch 9 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.63it/s]Epoch 9 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.69it/s]Epoch 9 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.84it/s]Epoch 9 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.91it/s]Epoch 9 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.96it/s]Epoch 9 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.94it/s]Epoch 9 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.01it/s]Epoch 9 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.03it/s]Epoch 9 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.07it/s]Epoch 9 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.06it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:12,310][__main__][INFO] - Epoch 9: Val Loss: 1.2085, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2950409463148317, 'f1_weighted': 0.48572509662249214, 'precision_macro': 0.4005102040816326, 'recall_macro': 0.3181818181818182}
Epoch 10 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:12,380][__main__][INFO] - Train Epoch: 10 [0/101 (0%)]	Loss: 0.630530
Epoch 10 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.41it/s]Epoch 10 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 16.15it/s]Epoch 10 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.37it/s]Epoch 10 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.47it/s]Epoch 10 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.60it/s]Epoch 10 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.61it/s]Epoch 10 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.58it/s]Epoch 10 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.53it/s]Epoch 10 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.49it/s]Epoch 10 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.46it/s]Epoch 10 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.47it/s]Epoch 10 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.47it/s]Epoch 10 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.48it/s]Epoch 10 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.49it/s]Epoch 10 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.45it/s]Epoch 10 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.46it/s]Epoch 10 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.45it/s]Epoch 10 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.46it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.46it/s]Epoch 10 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.44it/s]Epoch 10 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.42it/s]Epoch 10 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.41it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.41it/s]Epoch 10 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.37it/s]Epoch 10 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.38it/s]Epoch 10 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.36it/s]Epoch 10 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.35it/s]Epoch 10 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.41it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.43it/s]Epoch 10 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.42it/s]Epoch 10 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.40it/s]Epoch 10 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.42it/s]Epoch 10 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.40it/s]Epoch 10 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.43it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.47it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.47it/s]Epoch 10 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.46it/s]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.47it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.45it/s]Epoch 10 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.45it/s]Epoch 10 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.42it/s]Epoch 10 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.41it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.37it/s]Epoch 10 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.42it/s]Epoch 10 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.47it/s]Epoch 10 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.45it/s]Epoch 10 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.48it/s]Epoch 10 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.50it/s]Epoch 10 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.51it/s]Epoch 10 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.47it/s][2025-05-30 15:19:18,450][__main__][INFO] - Train Epoch: 10 [100/101 (99%)]	Loss: 0.755758
                                                                   Epoch 10 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 10 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.06it/s]Epoch 10 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.50it/s]Epoch 10 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.48it/s]Epoch 10 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.60it/s]Epoch 10 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.78it/s]Epoch 10 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.87it/s]Epoch 10 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.86it/s]Epoch 10 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.89it/s]Epoch 10 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.93it/s]Epoch 10 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.95it/s]Epoch 10 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.96it/s]Epoch 10 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.00it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:19,888][__main__][INFO] - Epoch 10: Val Loss: 0.8310, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3935613682092555, 'f1_weighted': 0.5835408490547245, 'precision_macro': 0.5216867469879518, 'recall_macro': 0.3847072419106317}
Epoch 11 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:19,958][__main__][INFO] - Train Epoch: 11 [0/101 (0%)]	Loss: 0.552921
Epoch 11 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 16.08it/s]Epoch 11 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.33it/s]Epoch 11 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.44it/s]Epoch 11 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.51it/s]Epoch 11 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.47it/s]Epoch 11 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.36it/s]Epoch 11 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.35it/s]Epoch 11 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.37it/s]Epoch 11 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.36it/s]Epoch 11 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.32it/s]Epoch 11 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.32it/s]Epoch 11 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.35it/s]Epoch 11 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.36it/s]Epoch 11 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.37it/s]Epoch 11 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.39it/s]Epoch 11 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.43it/s]Epoch 11 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.47it/s]Epoch 11 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.45it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.42it/s]Epoch 11 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.42it/s]Epoch 11 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.45it/s]Epoch 11 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.45it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.42it/s]Epoch 11 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.37it/s]Epoch 11 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.36it/s]Epoch 11 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.37it/s]Epoch 11 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.43it/s]Epoch 11 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.44it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.47it/s]Epoch 11 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.46it/s]Epoch 11 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.48it/s]Epoch 11 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.24it/s]Epoch 11 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.34it/s]Epoch 11 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.42it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.48it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.52it/s]Epoch 11 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.52it/s]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.51it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.48it/s]Epoch 11 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.47it/s]Epoch 11 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.45it/s]Epoch 11 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.01it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.22it/s]Epoch 11 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.34it/s]Epoch 11 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.43it/s]Epoch 11 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.47it/s]Epoch 11 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.51it/s]Epoch 11 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.59it/s]Epoch 11 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.58it/s]Epoch 11 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.59it/s][2025-05-30 15:19:26,037][__main__][INFO] - Train Epoch: 11 [100/101 (99%)]	Loss: 1.164594
                                                                   Epoch 11 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 11 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.90it/s]Epoch 11 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.81it/s]Epoch 11 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.67it/s]Epoch 11 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.70it/s]Epoch 11 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.67it/s]Epoch 11 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.68it/s]Epoch 11 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.67it/s]Epoch 11 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.66it/s]Epoch 11 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.43it/s]Epoch 11 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.63it/s]Epoch 11 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.77it/s]Epoch 11 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.85it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:27,482][__main__][INFO] - Epoch 11: Val Loss: 0.9450, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.39701768819415884, 'f1_weighted': 0.563624959781046, 'precision_macro': 0.4225352112676056, 'recall_macro': 0.3985362095531587}
Epoch 12 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:27,545][__main__][INFO] - Train Epoch: 12 [0/101 (0%)]	Loss: 0.608994
Epoch 12 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 16.03it/s]Epoch 12 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.47it/s]Epoch 12 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.61it/s]Epoch 12 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.62it/s]Epoch 12 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.60it/s]Epoch 12 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.58it/s]Epoch 12 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.63it/s]Epoch 12 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.31it/s]Epoch 12 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.41it/s]Epoch 12 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.47it/s]Epoch 12 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.49it/s]Epoch 12 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.50it/s]Epoch 12 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.48it/s]Epoch 12 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.44it/s]Epoch 12 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.43it/s]Epoch 12 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.40it/s]Epoch 12 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.35it/s]Epoch 12 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.40it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.43it/s]Epoch 12 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.38it/s]Epoch 12 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.45it/s]Epoch 12 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.48it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.49it/s]Epoch 12 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.43it/s]Epoch 12 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.46it/s]Epoch 12 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.46it/s]Epoch 12 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.43it/s]Epoch 12 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.43it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.45it/s]Epoch 12 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.46it/s]Epoch 12 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.46it/s]Epoch 12 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.46it/s]Epoch 12 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.43it/s]Epoch 12 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.44it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.38it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.40it/s]Epoch 12 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.45it/s]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.46it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.45it/s]Epoch 12 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.45it/s]Epoch 12 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.46it/s]Epoch 12 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.44it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.44it/s]Epoch 12 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.47it/s]Epoch 12 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.40it/s]Epoch 12 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.42it/s]Epoch 12 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.41it/s]Epoch 12 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.41it/s]Epoch 12 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.40it/s]Epoch 12 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.40it/s][2025-05-30 15:19:33,617][__main__][INFO] - Train Epoch: 12 [100/101 (99%)]	Loss: 1.593401
                                                                   Epoch 12 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 12 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.75it/s]Epoch 12 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.73it/s]Epoch 12 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.63it/s]Epoch 12 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.65it/s]Epoch 12 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.66it/s]Epoch 12 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.71it/s]Epoch 12 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.76it/s]Epoch 12 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.84it/s]Epoch 12 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.87it/s]Epoch 12 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.96it/s]Epoch 12 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.99it/s]Epoch 12 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.02it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:35,052][__main__][INFO] - Epoch 12: Val Loss: 0.7764, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.40325385847906764, 'f1_weighted': 0.6076662335438294, 'precision_macro': 0.5485347985347986, 'recall_macro': 0.40774268104776584}
Epoch 13 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:35,122][__main__][INFO] - Train Epoch: 13 [0/101 (0%)]	Loss: 0.800856
Epoch 13 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.80it/s]Epoch 13 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.27it/s]Epoch 13 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.43it/s]Epoch 13 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.46it/s]Epoch 13 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.49it/s]Epoch 13 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.55it/s]Epoch 13 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.56it/s]Epoch 13 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.57it/s]Epoch 13 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.55it/s]Epoch 13 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.45it/s]Epoch 13 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.46it/s]Epoch 13 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.50it/s]Epoch 13 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.50it/s]Epoch 13 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.46it/s]Epoch 13 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.52it/s]Epoch 13 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.57it/s]Epoch 13 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.58it/s]Epoch 13 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.60it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.57it/s]Epoch 13 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.54it/s]Epoch 13 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.51it/s]Epoch 13 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.50it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.49it/s]Epoch 13 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.50it/s]Epoch 13 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.49it/s]Epoch 13 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.45it/s]Epoch 13 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.43it/s]Epoch 13 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.42it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.40it/s]Epoch 13 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.35it/s]Epoch 13 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.39it/s]Epoch 13 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.39it/s]Epoch 13 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.43it/s]Epoch 13 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.46it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.46it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.45it/s]Epoch 13 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.46it/s]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.46it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.45it/s]Epoch 13 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.43it/s]Epoch 13 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.45it/s]Epoch 13 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.46it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.46it/s]Epoch 13 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.45it/s]Epoch 13 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.47it/s]Epoch 13 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.44it/s]Epoch 13 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.47it/s]Epoch 13 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.52it/s]Epoch 13 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.51it/s]Epoch 13 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.50it/s][2025-05-30 15:19:41,177][__main__][INFO] - Train Epoch: 13 [100/101 (99%)]	Loss: 0.482162
                                                                   Epoch 13 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 13 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.06it/s]Epoch 13 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.47it/s]Epoch 13 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.49it/s]Epoch 13 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.63it/s]Epoch 13 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.75it/s]Epoch 13 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.81it/s]Epoch 13 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.88it/s]Epoch 13 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.96it/s]Epoch 13 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.98it/s]Epoch 13 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.04it/s]Epoch 13 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.04it/s]Epoch 13 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.02it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:42,611][__main__][INFO] - Epoch 13: Val Loss: 0.8539, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.42588804888152443, 'f1_weighted': 0.5949186675088387, 'precision_macro': 0.48418674698795183, 'recall_macro': 0.41766178736517723}
Epoch 14 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:42,688][__main__][INFO] - Train Epoch: 14 [0/101 (0%)]	Loss: 0.329559
Epoch 14 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.27it/s]Epoch 14 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.94it/s]Epoch 14 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.21it/s]Epoch 14 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.36it/s]Epoch 14 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.41it/s]Epoch 14 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.44it/s]Epoch 14 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.41it/s]Epoch 14 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.38it/s]Epoch 14 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.36it/s]Epoch 14 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.38it/s]Epoch 14 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.35it/s]Epoch 14 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.34it/s]Epoch 14 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.38it/s]Epoch 14 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.39it/s]Epoch 14 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.41it/s]Epoch 14 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.39it/s]Epoch 14 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.39it/s]Epoch 14 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.37it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.38it/s]Epoch 14 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.40it/s]Epoch 14 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.42it/s]Epoch 14 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.42it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.45it/s]Epoch 14 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.45it/s]Epoch 14 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.45it/s]Epoch 14 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.43it/s]Epoch 14 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.44it/s]Epoch 14 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.89it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.09it/s]Epoch 14 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.17it/s]Epoch 14 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.25it/s]Epoch 14 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.22it/s]Epoch 14 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.29it/s]Epoch 14 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.32it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.30it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.32it/s]Epoch 14 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.31it/s]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.33it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.32it/s]Epoch 14 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.35it/s]Epoch 14 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 16.36it/s]Epoch 14 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.38it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.40it/s]Epoch 14 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.43it/s]Epoch 14 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.44it/s]Epoch 14 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.43it/s]Epoch 14 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.45it/s]Epoch 14 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.42it/s]Epoch 14 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.43it/s]Epoch 14 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.45it/s][2025-05-30 15:19:48,784][__main__][INFO] - Train Epoch: 14 [100/101 (99%)]	Loss: 0.862790
                                                                   Epoch 14 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 14 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.08it/s]Epoch 14 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.46it/s]Epoch 14 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.48it/s]Epoch 14 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.58it/s]Epoch 14 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.72it/s]Epoch 14 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.86it/s]Epoch 14 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.93it/s]Epoch 14 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.98it/s]Epoch 14 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.99it/s]Epoch 14 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.02it/s]Epoch 14 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.00it/s]Epoch 14 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.01it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:50,221][__main__][INFO] - Epoch 14: Val Loss: 0.8205, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.49565580618212196, 'f1_weighted': 0.6624564712110309, 'precision_macro': 0.5143822393822394, 'recall_macro': 0.4966872110939907}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702f003c0>
<numpy.flatiter object at 0x7f3702f13700>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702f08be0>
<numpy.flatiter object at 0x7f3702f08be0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f08be0>
<numpy.flatiter object at 0x7f3702f08be0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702f091e0>
<numpy.flatiter object at 0x7f3702f091e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f091e0>
<numpy.flatiter object at 0x7f3702f091e0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:19:50,284][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:19:50,384][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:50,479][__main__][INFO] - Train Epoch: 15 [0/101 (0%)]	Loss: 0.891889
Epoch 15 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.52it/s]Epoch 15 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.58it/s]Epoch 15 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.52it/s]Epoch 15 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.51it/s]Epoch 15 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.48it/s]Epoch 15 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.48it/s]Epoch 15 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.42it/s]Epoch 15 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.12it/s]Epoch 15 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.23it/s]Epoch 15 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.34it/s]Epoch 15 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.39it/s]Epoch 15 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.43it/s]Epoch 15 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.49it/s]Epoch 15 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.48it/s]Epoch 15 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.50it/s]Epoch 15 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.56it/s]Epoch 15 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.56it/s]Epoch 15 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.53it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.21it/s]Epoch 15 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.30it/s]Epoch 15 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.41it/s]Epoch 15 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.47it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.45it/s]Epoch 15 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.51it/s]Epoch 15 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.52it/s]Epoch 15 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.53it/s]Epoch 15 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.54it/s]Epoch 15 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.54it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.51it/s]Epoch 15 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.51it/s]Epoch 15 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.50it/s]Epoch 15 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.46it/s]Epoch 15 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.46it/s]Epoch 15 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.44it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.43it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.44it/s]Epoch 15 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.45it/s]Epoch 15 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.46it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.44it/s]Epoch 15 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.45it/s]Epoch 15 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.45it/s]Epoch 15 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.46it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.43it/s]Epoch 15 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.41it/s]Epoch 15 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.44it/s]Epoch 15 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.45it/s]Epoch 15 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.37it/s]Epoch 15 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.42it/s]Epoch 15 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.46it/s]Epoch 15 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.48it/s][2025-05-30 15:19:56,548][__main__][INFO] - Train Epoch: 15 [100/101 (99%)]	Loss: 0.997119
                                                                   Epoch 15 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 15 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.49it/s]Epoch 15 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.58it/s]Epoch 15 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.46it/s]Epoch 15 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.56it/s]Epoch 15 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.45it/s]Epoch 15 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.63it/s]Epoch 15 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.70it/s]Epoch 15 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.82it/s]Epoch 15 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.84it/s]Epoch 15 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.86it/s]Epoch 15 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.94it/s]Epoch 15 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.96it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:19:57,990][__main__][INFO] - Epoch 15: Val Loss: 0.8226, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.49673357568094406, 'f1_weighted': 0.6518044881775992, 'precision_macro': 0.5154798761609907, 'recall_macro': 0.49441448382126346}
Epoch 16 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:19:58,052][__main__][INFO] - Train Epoch: 16 [0/101 (0%)]	Loss: 0.828308
Epoch 16 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.75it/s]Epoch 16 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.86it/s]Epoch 16 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.82it/s]Epoch 16 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.84it/s]Epoch 16 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.85it/s]Epoch 16 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.88it/s]Epoch 16 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.86it/s]Epoch 16 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.83it/s]Epoch 16 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.80it/s]Epoch 16 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.81it/s]Epoch 16 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.80it/s]Epoch 16 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.85it/s]Epoch 16 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.90it/s]Epoch 16 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.88it/s]Epoch 16 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.76it/s]Epoch 16 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.78it/s]Epoch 16 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.74it/s]Epoch 16 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.77it/s]Epoch 16 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.80it/s]Epoch 16 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.83it/s]Epoch 16 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.86it/s]Epoch 16 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.84it/s]Epoch 16 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.84it/s]Epoch 16 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.81it/s]Epoch 16 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:02<00:03, 16.84it/s]Epoch 16 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.80it/s]Epoch 16 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.73it/s]Epoch 16 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.70it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.70it/s]Epoch 16 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.65it/s]Epoch 16 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.60it/s]Epoch 16 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.59it/s]Epoch 16 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.54it/s]Epoch 16 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.51it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.46it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.46it/s]Epoch 16 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.50it/s]Epoch 16 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.49it/s]Epoch 16 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.51it/s]Epoch 16 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.47it/s]Epoch 16 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.50it/s]Epoch 16 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.48it/s]Epoch 16 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.49it/s]Epoch 16 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.46it/s]Epoch 16 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.49it/s]Epoch 16 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.50it/s]Epoch 16 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.52it/s]Epoch 16 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.51it/s]Epoch 16 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.48it/s]Epoch 16 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.44it/s][2025-05-30 15:20:04,044][__main__][INFO] - Train Epoch: 16 [100/101 (99%)]	Loss: 0.724683
                                                                   Epoch 16 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 16 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.80it/s]Epoch 16 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.74it/s]Epoch 16 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.66it/s]Epoch 16 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.68it/s]Epoch 16 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.80it/s]Epoch 16 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.90it/s]Epoch 16 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.95it/s]Epoch 16 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.98it/s]Epoch 16 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.00it/s]Epoch 16 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.05it/s]Epoch 16 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.07it/s]Epoch 16 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.03it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:20:05,471][__main__][INFO] - Epoch 16: Val Loss: 0.8522, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5743726872484671, 'f1_weighted': 0.6898751458485936, 'precision_macro': 0.5654761904761905, 'recall_macro': 0.587384437596302}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37035f4df0>
<numpy.flatiter object at 0x7f37035f4df0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702effc20>
<numpy.flatiter object at 0x7f3702effc20>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702effc20>
<numpy.flatiter object at 0x7f3702effc20>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702f00220>
<numpy.flatiter object at 0x7f3702f00220>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f00220>
<numpy.flatiter object at 0x7f3702f00220>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:20:05,529][__main__][INFO] - Saved best model at epoch 16 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:20:05,628][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 17 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:20:05,719][__main__][INFO] - Train Epoch: 17 [0/101 (0%)]	Loss: 0.095273
Epoch 17 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 17.00it/s]Epoch 17 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.98it/s]Epoch 17 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.92it/s]Epoch 17 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.85it/s]Epoch 17 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.80it/s]Epoch 17 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.69it/s]Epoch 17 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.69it/s]Epoch 17 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.69it/s]Epoch 17 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.65it/s]Epoch 17 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.68it/s]Epoch 17 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.65it/s]Epoch 17 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.62it/s]Epoch 17 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.57it/s]Epoch 17 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.55it/s]Epoch 17 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.51it/s]Epoch 17 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.47it/s]Epoch 17 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.44it/s]Epoch 17 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.42it/s]Epoch 17 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.44it/s]Epoch 17 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.44it/s]Epoch 17 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.01it/s]Epoch 17 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.18it/s]Epoch 17 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.31it/s]Epoch 17 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.42it/s]Epoch 17 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.48it/s]Epoch 17 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.49it/s]Epoch 17 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.41it/s]Epoch 17 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.42it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.47it/s]Epoch 17 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.53it/s]Epoch 17 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.55it/s]Epoch 17 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.53it/s]Epoch 17 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:03<00:02, 16.55it/s]Epoch 17 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.57it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.52it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.48it/s]Epoch 17 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.45it/s]Epoch 17 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.48it/s]Epoch 17 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.46it/s]Epoch 17 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.46it/s]Epoch 17 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.46it/s]Epoch 17 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.47it/s]Epoch 17 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.48it/s]Epoch 17 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.47it/s]Epoch 17 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.45it/s]Epoch 17 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.48it/s]Epoch 17 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.46it/s]Epoch 17 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.47it/s]Epoch 17 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.46it/s]Epoch 17 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.45it/s][2025-05-30 15:20:11,768][__main__][INFO] - Train Epoch: 17 [100/101 (99%)]	Loss: 1.207568
                                                                   Epoch 17 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 17 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.87it/s]Epoch 17 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.75it/s]Epoch 17 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.67it/s]Epoch 17 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.71it/s]Epoch 17 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.82it/s]Epoch 17 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.89it/s]Epoch 17 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.96it/s]Epoch 17 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.93it/s]Epoch 17 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.94it/s]Epoch 17 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.99it/s]Epoch 17 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.99it/s]Epoch 17 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.99it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:20:13,198][__main__][INFO] - Epoch 17: Val Loss: 0.8493, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.43209603841536615, 'f1_weighted': 0.5968751381740816, 'precision_macro': 0.45193312434691746, 'recall_macro': 0.44429892141756555}
Epoch 18 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:20:13,269][__main__][INFO] - Train Epoch: 18 [0/101 (0%)]	Loss: 0.461538
Epoch 18 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.19it/s]Epoch 18 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 16.10it/s]Epoch 18 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.38it/s]Epoch 18 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.51it/s]Epoch 18 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.55it/s]Epoch 18 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.54it/s]Epoch 18 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.51it/s]Epoch 18 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.48it/s]Epoch 18 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.49it/s]Epoch 18 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.48it/s]Epoch 18 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.43it/s]Epoch 18 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.44it/s]Epoch 18 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.42it/s]Epoch 18 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.43it/s]Epoch 18 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.42it/s]Epoch 18 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.44it/s]Epoch 18 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.44it/s]Epoch 18 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.45it/s]Epoch 18 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.46it/s]Epoch 18 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.46it/s]Epoch 18 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.40it/s]Epoch 18 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.43it/s]Epoch 18 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.40it/s]Epoch 18 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.42it/s]Epoch 18 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.44it/s]Epoch 18 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.44it/s]Epoch 18 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.45it/s]Epoch 18 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.45it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.39it/s]Epoch 18 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.43it/s]Epoch 18 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.42it/s]Epoch 18 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.44it/s]Epoch 18 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.42it/s]Epoch 18 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.43it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.40it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.43it/s]Epoch 18 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.42it/s]Epoch 18 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.47it/s]Epoch 18 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.47it/s]Epoch 18 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.45it/s]Epoch 18 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.43it/s]Epoch 18 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.08it/s]Epoch 18 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.23it/s]Epoch 18 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.33it/s]Epoch 18 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.39it/s]Epoch 18 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.41it/s]Epoch 18 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.48it/s]Epoch 18 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.50it/s]Epoch 18 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.49it/s]Epoch 18 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.50it/s][2025-05-30 15:20:19,339][__main__][INFO] - Train Epoch: 18 [100/101 (99%)]	Loss: 1.459194
                                                                   Epoch 18 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 18 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.98it/s]Epoch 18 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.45it/s]Epoch 18 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.50it/s]Epoch 18 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.69it/s]Epoch 18 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.82it/s]Epoch 18 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.92it/s]Epoch 18 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.95it/s]Epoch 18 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.97it/s]Epoch 18 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.98it/s]Epoch 18 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.04it/s]Epoch 18 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.03it/s]Epoch 18 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.02it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:20:20,772][__main__][INFO] - Epoch 18: Val Loss: 1.1463, Accuracy: 0.4455, Metrics: {'accuracy': 0.44554455445544555, 'f1_macro': 0.25, 'f1_weighted': 0.4211221122112211, 'precision_macro': 0.2775345622119816, 'recall_macro': 0.3476694915254237}
Epoch 19 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:20:20,835][__main__][INFO] - Train Epoch: 19 [0/101 (0%)]	Loss: 0.877824
Epoch 19 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.83it/s]Epoch 19 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.27it/s]Epoch 19 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.44it/s]Epoch 19 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.58it/s]Epoch 19 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.61it/s]Epoch 19 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.63it/s]Epoch 19 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.62it/s]Epoch 19 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.59it/s]Epoch 19 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.34it/s]Epoch 19 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.42it/s]Epoch 19 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.49it/s]Epoch 19 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.51it/s]Epoch 19 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.51it/s]Epoch 19 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.54it/s]Epoch 19 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.51it/s]Epoch 19 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.48it/s]Epoch 19 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.45it/s]Epoch 19 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.46it/s]Epoch 19 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.42it/s]Epoch 19 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.42it/s]Epoch 19 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.44it/s]Epoch 19 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.46it/s]Epoch 19 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.47it/s]Epoch 19 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.44it/s]Epoch 19 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.40it/s]Epoch 19 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.43it/s]Epoch 19 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.43it/s]Epoch 19 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.36it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.40it/s]Epoch 19 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.43it/s]Epoch 19 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.43it/s]Epoch 19 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.46it/s]Epoch 19 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.46it/s]Epoch 19 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.44it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.51it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.48it/s]Epoch 19 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.46it/s]Epoch 19 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.41it/s]Epoch 19 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.41it/s]Epoch 19 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.45it/s]Epoch 19 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.48it/s]Epoch 19 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.48it/s]Epoch 19 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.49it/s]Epoch 19 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.48it/s]Epoch 19 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.42it/s]Epoch 19 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.38it/s]Epoch 19 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.40it/s]Epoch 19 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.42it/s]Epoch 19 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.46it/s]Epoch 19 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.45it/s][2025-05-30 15:20:26,901][__main__][INFO] - Train Epoch: 19 [100/101 (99%)]	Loss: 0.665088
                                                                   Epoch 19 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 19 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.10it/s]Epoch 19 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.47it/s]Epoch 19 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.48it/s]Epoch 19 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.70it/s]Epoch 19 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.79it/s]Epoch 19 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.87it/s]Epoch 19 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.90it/s]Epoch 19 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.96it/s]Epoch 19 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.99it/s]Epoch 19 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.06it/s]Epoch 19 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.06it/s]Epoch 19 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.05it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:20:28,335][__main__][INFO] - Epoch 19: Val Loss: 0.9188, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4354609929078014, 'f1_weighted': 0.6095920230320904, 'precision_macro': 0.5404471544715447, 'recall_macro': 0.41993451463790443}
Epoch 20 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:20:28,399][__main__][INFO] - Train Epoch: 20 [0/101 (0%)]	Loss: 1.161206
Epoch 20 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.64it/s]Epoch 20 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 16.17it/s]Epoch 20 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.35it/s]Epoch 20 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.47it/s]Epoch 20 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.56it/s]Epoch 20 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.60it/s]Epoch 20 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.61it/s]Epoch 20 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.64it/s]Epoch 20 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:04, 16.63it/s]Epoch 20 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.32it/s]Epoch 20 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.38it/s]Epoch 20 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.44it/s]Epoch 20 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.46it/s]Epoch 20 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.48it/s]Epoch 20 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.52it/s]Epoch 20 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.55it/s]Epoch 20 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.56it/s]Epoch 20 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.54it/s]Epoch 20 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.48it/s]Epoch 20 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.48it/s]Epoch 20 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.52it/s]Epoch 20 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.49it/s]Epoch 20 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.48it/s]Epoch 20 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.40it/s]Epoch 20 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.41it/s]Epoch 20 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.46it/s]Epoch 20 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.48it/s]Epoch 20 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.46it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.46it/s]Epoch 20 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.42it/s]Epoch 20 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.45it/s]Epoch 20 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.45it/s]Epoch 20 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.46it/s]Epoch 20 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.46it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.45it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.41it/s]Epoch 20 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.44it/s]Epoch 20 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.45it/s]Epoch 20 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.45it/s]Epoch 20 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.45it/s]Epoch 20 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:04<00:01, 16.46it/s]Epoch 20 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.44it/s]Epoch 20 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.43it/s]Epoch 20 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.41it/s]Epoch 20 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.41it/s]Epoch 20 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.40it/s]Epoch 20 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.41it/s]Epoch 20 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.43it/s]Epoch 20 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.41it/s]Epoch 20 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.41it/s][2025-05-30 15:20:34,466][__main__][INFO] - Train Epoch: 20 [100/101 (99%)]	Loss: 1.460731
                                                                   Epoch 20 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 20 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.76it/s]Epoch 20 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.67it/s]Epoch 20 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.55it/s]Epoch 20 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.68it/s]Epoch 20 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.74it/s]Epoch 20 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.83it/s]Epoch 20 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.84it/s]Epoch 20 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.93it/s]Epoch 20 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.95it/s]Epoch 20 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.96it/s]Epoch 20 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.95it/s]Epoch 20 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.97it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:20:35,901][__main__][INFO] - Epoch 20: Val Loss: 1.1569, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.22677322677322678, 'f1_weighted': 0.4567709518204568, 'precision_macro': 0.27763157894736845, 'recall_macro': 0.2684899845916795}
Epoch 21 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:20:35,963][__main__][INFO] - Train Epoch: 21 [0/101 (0%)]	Loss: 1.072362
Epoch 21 [Train]:   2%|‚ñè         | 2/101 [00:00<00:05, 16.79it/s]Epoch 21 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.79it/s]Epoch 21 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.70it/s]Epoch 21 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.63it/s]Epoch 21 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.68it/s]Epoch 21 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.66it/s]Epoch 21 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.61it/s]Epoch 21 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.56it/s]Epoch 21 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.46it/s]Epoch 21 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 14.72it/s]Epoch 21 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.23it/s]Epoch 21 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.62it/s]Epoch 21 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.91it/s]Epoch 21 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.13it/s]Epoch 21 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.26it/s]Epoch 21 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 16.34it/s]Epoch 21 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 16.40it/s]Epoch 21 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:03, 16.42it/s]Epoch 21 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 16.38it/s]Epoch 21 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.39it/s]Epoch 21 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.40it/s]Epoch 21 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.43it/s]Epoch 21 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 16.47it/s]Epoch 21 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 16.47it/s]Epoch 21 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.42it/s]Epoch 21 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:02, 16.42it/s]Epoch 21 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.44it/s]Epoch 21 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.47it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.50it/s]Epoch 21 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.50it/s]Epoch 21 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.48it/s]Epoch 21 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.49it/s]Epoch 21 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.48it/s]Epoch 21 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 16.48it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.45it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.03it/s]Epoch 21 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.04it/s]Epoch 21 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.22it/s]Epoch 21 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.31it/s]Epoch 21 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.41it/s]Epoch 21 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 16.47it/s]Epoch 21 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.48it/s]Epoch 21 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.47it/s]Epoch 21 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.50it/s]Epoch 21 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.53it/s]Epoch 21 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.48it/s]Epoch 21 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.48it/s]Epoch 21 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.53it/s]Epoch 21 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.56it/s]Epoch 21 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.55it/s][2025-05-30 15:20:42,067][__main__][INFO] - Train Epoch: 21 [100/101 (99%)]	Loss: 1.022681
                                                                   Epoch 21 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 21 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.06it/s]Epoch 21 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.49it/s]Epoch 21 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.52it/s]Epoch 21 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.61it/s]Epoch 21 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.79it/s]Epoch 21 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.89it/s]Epoch 21 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.92it/s]Epoch 21 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.96it/s]Epoch 21 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 18.00it/s]Epoch 21 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 18.00it/s]Epoch 21 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 18.03it/s]Epoch 21 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 18.04it/s]                                                               [2025-05-30 15:20:43,501][__main__][INFO] - Epoch 21: Val Loss: 1.1967, Accuracy: 0.2970, Metrics: {'accuracy': 0.297029702970297, 'f1_macro': 0.3560649110353873, 'f1_weighted': 0.2858967081120183, 'precision_macro': 0.42736928104575167, 'recall_macro': 0.48276194144838214}
Epoch 22 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:20:43,566][__main__][INFO] - Train Epoch: 22 [0/101 (0%)]	Loss: 1.378589
Epoch 22 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 16.28it/s]Epoch 22 [Train]:   4%|‚ñç         | 4/101 [00:00<00:05, 16.58it/s]Epoch 22 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 16.61it/s]Epoch 22 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 16.64it/s]Epoch 22 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 16.67it/s]Epoch 22 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 16.60it/s]Epoch 22 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 16.59it/s]Epoch 22 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:00<00:05, 16.58it/s]Epoch 22 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 16.56it/s]Epoch 22 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:04, 16.57it/s]Epoch 22 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 16.57it/s]Epoch 22 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 16.54it/s]Epoch 22 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 16.51it/s]Epoch 22 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 16.51it/s]Epoch 22 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 16.40it/s]Epoch 22 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:01<00:04, 15.49it/s]Epoch 22 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.36it/s]Epoch 22 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.69it/s]Epoch 22 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 15.90it/s]Epoch 22 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 16.03it/s]Epoch 22 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 16.07it/s]Epoch 22 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 16.01it/s]Epoch 22 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.76it/s]Epoch 22 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:02<00:03, 15.96it/s]Epoch 22 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 16.12it/s]Epoch 22 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 16.23it/s]Epoch 22 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:02, 16.32it/s]Epoch 22 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 16.41it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 16.40it/s]Epoch 22 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 16.46it/s]Epoch 22 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 16.48it/s]Epoch 22 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:03<00:02, 16.53it/s]Epoch 22 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 16.56it/s]Epoch 22 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:01, 16.57it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 16.57it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 16.59it/s]Epoch 22 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 16.62it/s]Epoch 22 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 16.63it/s]Epoch 22 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 16.59it/s]Epoch 22 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:04<00:01, 16.54it/s]Epoch 22 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 16.54it/s]Epoch 22 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 16.50it/s]Epoch 22 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 16.47it/s]Epoch 22 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 16.46it/s]Epoch 22 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 16.34it/s]Epoch 22 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 16.40it/s]Epoch 22 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:05<00:00, 16.43it/s]Epoch 22 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:05<00:00, 16.47it/s]Epoch 22 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:05<00:00, 16.47it/s]Epoch 22 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 16.45it/s][2025-05-30 15:20:49,666][__main__][INFO] - Train Epoch: 22 [100/101 (99%)]	Loss: 1.028178
                                                                   Epoch 22 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 22 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.66it/s]Epoch 22 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.64it/s]Epoch 22 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.56it/s]Epoch 22 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.62it/s]Epoch 22 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.72it/s]Epoch 22 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.85it/s]Epoch 22 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.87it/s]Epoch 22 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.92it/s]Epoch 22 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.90it/s]Epoch 22 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.97it/s]Epoch 22 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.97it/s]Epoch 22 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.92it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:20:51,103][__main__][INFO] - Epoch 22: Val Loss: 0.9266, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.33887254901960784, 'f1_weighted': 0.539147738303242, 'precision_macro': 0.32067669172932334, 'recall_macro': 0.4046417565485362}
[2025-05-30 15:20:51,106][__main__][INFO] - Early stopping triggered after 22 epochs
[2025-05-30 15:20:51,106][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7327
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f48d9dc0>
<numpy.flatiter object at 0x7f3702f00e40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702f0a4c0>
<numpy.flatiter object at 0x7f3702f0a4c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f0a4c0>
<numpy.flatiter object at 0x7f3702f0a4c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702f0a4c0>
<numpy.flatiter object at 0x7f3702f0a4c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f0a4c0>
<numpy.flatiter object at 0x7f3702f0a4c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:                 Train Loss ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
wandb:        Validation Accuracy ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñá‚ñÜ‚ñÅ‚ñÜ
wandb:            Validation Loss ‚ñà‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñá‚ñÉ‚ñá‚ñà‚ñÉ
wandb:        Validation accuracy ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÉ‚ñá‚ñÜ‚ñÅ‚ñÜ
wandb:        Validation f1_macro ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñÖ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÑ
wandb:     Validation f1_weighted ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñá‚ñÑ‚ñÅ‚ñÖ
wandb: Validation precision_macro ‚ñÅ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñÑ
wandb:    Validation recall_macro ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÜ‚ñÑ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.73267
wandb:                 Train Loss 1.02818
wandb:        Validation Accuracy 0.62376
wandb:            Validation Loss 0.92662
wandb:        Validation accuracy 0.62376
wandb:        Validation f1_macro 0.33887
wandb:     Validation f1_weighted 0.53915
wandb: Validation precision_macro 0.32068
wandb:    Validation recall_macro 0.40464
wandb: 
wandb: üöÄ View run still-sweep-6 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/8xcy0suj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_151752-8xcy0suj/logs
wandb: Agent Starting Run: cldq2ki2 with config:
wandb: 	Fdropout_rate: 0.38953994560324745
wandb: 	Fnum_heads: 1
wandb: 	Fnum_layers: 8
wandb: 	Mdropout_rate: 0.14633852030959107
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.02984740522832229
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_152055-cldq2ki2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/cldq2ki2
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:00,075][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.451716
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.40it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:04,766][__main__][INFO] - Epoch 0: Val Loss: 28.9640, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703179450>
<numpy.flatiter object at 0x7f3703179450>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370310fc10>
<numpy.flatiter object at 0x7f370310fc10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370310fc10>
<numpy.flatiter object at 0x7f370310fc10>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370310fc10>
<numpy.flatiter object at 0x7f370310fc10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370310fc10>
<numpy.flatiter object at 0x7f370310fc10>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:21:04,831][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:21:04,928][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:21:04,964][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:05,654][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 23.867556
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:10,348][__main__][INFO] - Epoch 1: Val Loss: 9.8727, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:11,049][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 7.399343
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:15,749][__main__][INFO] - Epoch 2: Val Loss: 13.3124, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:16,440][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 13.823077
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:21,151][__main__][INFO] - Epoch 3: Val Loss: 7.3862, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:21,850][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 5.467165
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:26,562][__main__][INFO] - Epoch 4: Val Loss: 4.7452, Accuracy: 0.1386, Metrics: {'accuracy': 0.13861386138613863, 'f1_macro': 0.07473544973544974, 'f1_weighted': 0.07781968673057782, 'precision_macro': 0.21585051546391754, 'recall_macro': 0.2627118644067797}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:27,255][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 4.256131
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:31,980][__main__][INFO] - Epoch 5: Val Loss: 1.7795, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.34874172185430463, 'f1_weighted': 0.532109369877385, 'precision_macro': 0.4923913043478261, 'recall_macro': 0.34720724191063174}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030d7cb0>
<numpy.flatiter object at 0x7f37030d7cb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3812527080>
<numpy.flatiter object at 0x7f3812527080>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812527080>
<numpy.flatiter object at 0x7f3812527080>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3812527680>
<numpy.flatiter object at 0x7f3812527680>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812527680>
<numpy.flatiter object at 0x7f3812527680>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:21:32,039][__main__][INFO] - Saved best model at epoch 5 with accuracy: 0.6238
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:21:32,137][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:32,857][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 1.442164
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:37,573][__main__][INFO] - Epoch 6: Val Loss: 2.1918, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:38,266][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 2.735879
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:42,990][__main__][INFO] - Epoch 7: Val Loss: 1.9333, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:43,695][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 1.286628
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:48,423][__main__][INFO] - Epoch 8: Val Loss: 1.2901, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.2443609022556391, 'f1_weighted': 0.4882379215365146, 'precision_macro': 0.24966397849462366, 'recall_macro': 0.28326271186440677}
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:49,129][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 0.876829
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:53,869][__main__][INFO] - Epoch 9: Val Loss: 1.1118, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2687348912167607, 'f1_weighted': 0.5143648127907069, 'precision_macro': 0.25307881773399016, 'recall_macro': 0.3040254237288136}
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:21:54,575][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 0.804725
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:21:59,329][__main__][INFO] - Epoch 10: Val Loss: 1.4629, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.21032258064516127, 'f1_weighted': 0.4605557329926541, 'precision_macro': 0.20364583333333336, 'recall_macro': 0.2625}
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:00,026][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 0.728165
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:04,795][__main__][INFO] - Epoch 11: Val Loss: 1.0811, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.26686826686826687, 'f1_weighted': 0.5192115885185192, 'precision_macro': 0.24317226890756305, 'recall_macro': 0.3040254237288136}
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:05,502][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 0.770736
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:10,246][__main__][INFO] - Epoch 12: Val Loss: 0.9294, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.4045638489208633, 'f1_weighted': 0.5870254291616211, 'precision_macro': 0.41805555555555557, 'recall_macro': 0.413424499229584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702428680>
<numpy.flatiter object at 0x7f3702428680>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37024f1710>
<numpy.flatiter object at 0x7f37024f1710>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37024f1710>
<numpy.flatiter object at 0x7f37024f1710>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37024f1d10>
<numpy.flatiter object at 0x7f37024f1d10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37024f1d10>
<numpy.flatiter object at 0x7f37024f1d10>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:22:10,314][__main__][INFO] - Saved best model at epoch 12 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:22:10,417][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:11,155][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 0.730329
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:15,898][__main__][INFO] - Epoch 13: Val Loss: 0.9113, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.36509384775808135, 'f1_weighted': 0.5900071237572142, 'precision_macro': 0.543123543123543, 'recall_macro': 0.3850154083204931}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f4409e60>
<numpy.flatiter object at 0x7f36f4409e60>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f4421500>
<numpy.flatiter object at 0x7f36f4421500>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4421500>
<numpy.flatiter object at 0x7f36f4421500>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f4421b00>
<numpy.flatiter object at 0x7f36f4421b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4421b00>
<numpy.flatiter object at 0x7f36f4421b00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:22:15,964][__main__][INFO] - Saved best model at epoch 13 with accuracy: 0.6634
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:22:16,066][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:16,793][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 0.707604
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:21,547][__main__][INFO] - Epoch 14: Val Loss: 0.9777, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.45607315389924086, 'f1_weighted': 0.6251289725245817, 'precision_macro': 0.4891199517781797, 'recall_macro': 0.450924499229584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f4412e80>
<numpy.flatiter object at 0x7f36f4413f00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f4461b40>
<numpy.flatiter object at 0x7f36f4461b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4461b40>
<numpy.flatiter object at 0x7f36f4461b40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f4461b40>
<numpy.flatiter object at 0x7f36f4461b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4461b40>
<numpy.flatiter object at 0x7f36f4461b40>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:22:21,610][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:22:21,703][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:22,704][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 0.666300
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:05,  1.04it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:04,  1.24it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:03,  1.32it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:03<00:02,  1.37it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.39it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.41it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.82it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:27,461][__main__][INFO] - Epoch 15: Val Loss: 0.9470, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.34074074074074073, 'f1_weighted': 0.5902456912357902, 'precision_macro': 0.3042105263157895, 'recall_macro': 0.38728813559322034}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:28,158][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 0.655666
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:32,914][__main__][INFO] - Epoch 16: Val Loss: 0.9566, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.431651267472163, 'f1_weighted': 0.6106853755738048, 'precision_macro': 0.43, 'recall_macro': 0.4424499229583976}
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:33,619][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.817243
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:38,393][__main__][INFO] - Epoch 17: Val Loss: 0.8502, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.4659180235822571, 'f1_weighted': 0.6371945897565613, 'precision_macro': 0.5610661268556005, 'recall_macro': 0.4531972265023113}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f37487f0710>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f37487f0710>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f37487f0710>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f37487f0710>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f37487f0710>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:22:38,453][__main__][INFO] - Saved best model at epoch 17 with accuracy: 0.6931
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:22:38,559][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:39,287][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.542577
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:44,045][__main__][INFO] - Epoch 18: Val Loss: 0.9447, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.44852092352092354, 'f1_weighted': 0.6201863043447202, 'precision_macro': 0.4891127391127391, 'recall_macro': 0.4426617873651772}
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:44,746][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.729945
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:22:49,505][__main__][INFO] - Epoch 19: Val Loss: 1.3719, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.3377551020408163, 'f1_weighted': 0.5340472822792484, 'precision_macro': 0.4647727272727273, 'recall_macro': 0.338944530046225}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:50,206][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.853202
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:22:54,966][__main__][INFO] - Epoch 20: Val Loss: 1.1042, Accuracy: 0.3564, Metrics: {'accuracy': 0.3564356435643564, 'f1_macro': 0.31920878185246, 'f1_weighted': 0.33529992298627787, 'precision_macro': 0.5603356835340363, 'recall_macro': 0.5121147919876734}
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:22:55,671][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 1.040249
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:00,428][__main__][INFO] - Epoch 21: Val Loss: 1.0631, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.3923216276477146, 'f1_weighted': 0.5967195381745534, 'precision_macro': 0.5397151898734177, 'recall_macro': 0.39524268104776583}
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:01,127][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 0.646974
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:05,888][__main__][INFO] - Epoch 22: Val Loss: 0.8880, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5192279942279943, 'f1_weighted': 0.6563899247067564, 'precision_macro': 0.5797720797720798, 'recall_macro': 0.5006163328197226}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486eddc0>
<numpy.flatiter object at 0x7f3748710d00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748da4d40>
<numpy.flatiter object at 0x7f3748721650>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37487967d0>
<numpy.flatiter object at 0x7f36f48c6f00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f7da40>
<numpy.flatiter object at 0x7f374930c280>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748dab5c0>
<numpy.flatiter object at 0x7f37033761c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:23:05,948][__main__][INFO] - Saved best model at epoch 22 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:23:06,043][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:06,770][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.668937
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:11,537][__main__][INFO] - Epoch 23: Val Loss: 0.8802, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5136574074074074, 'f1_weighted': 0.6715163182984966, 'precision_macro': 0.5842105263157895, 'recall_macro': 0.5009244992295839}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38117ad290>
<numpy.flatiter object at 0x7f38117ad290>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37033972d0>
<numpy.flatiter object at 0x7f37033972d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37033972d0>
<numpy.flatiter object at 0x7f37033972d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811804a00>
<numpy.flatiter object at 0x7f3748dbf820>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811804a00>
<numpy.flatiter object at 0x7f3748dbf820>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:23:11,604][__main__][INFO] - Saved best model at epoch 23 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:23:11,701][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:12,439][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.654994
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:17,209][__main__][INFO] - Epoch 24: Val Loss: 0.7586, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5800958853590432, 'f1_weighted': 0.704794841741168, 'precision_macro': 0.6106811145510835, 'recall_macro': 0.5691063174114022}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748fb9b00>
<numpy.flatiter object at 0x7f3748fb9b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3810041480>
<numpy.flatiter object at 0x7f37033972d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5d1eb50>
<numpy.flatiter object at 0x7f3810041480>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f5d1eb50>
<numpy.flatiter object at 0x7f3810041480>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5d1eb50>
<numpy.flatiter object at 0x7f3810041480>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:23:17,276][__main__][INFO] - Saved best model at epoch 24 with accuracy: 0.7525
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:23:17,379][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:18,109][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.623491
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:22,882][__main__][INFO] - Epoch 25: Val Loss: 0.7587, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5880252100840336, 'f1_weighted': 0.7035610283717447, 'precision_macro': 0.6151515151515151, 'recall_macro': 0.5793335901386749}
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:23,589][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.482071
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:23:28,353][__main__][INFO] - Epoch 26: Val Loss: 1.0172, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.4749688442870261, 'f1_weighted': 0.5846042396447437, 'precision_macro': 0.6456699751861043, 'recall_macro': 0.575288906009245}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:29,051][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.983350
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:23:33,817][__main__][INFO] - Epoch 27: Val Loss: 0.8107, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5924988055422837, 'f1_weighted': 0.6785229406839394, 'precision_macro': 0.7240506329113925, 'recall_macro': 0.5705508474576271}
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:34,516][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.460774
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:23:39,290][__main__][INFO] - Epoch 28: Val Loss: 0.7129, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.6438232499208109, 'f1_weighted': 0.7065650119018869, 'precision_macro': 0.6875, 'recall_macro': 0.6386171032357474}
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:39,998][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.661548
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:44,757][__main__][INFO] - Epoch 29: Val Loss: 0.6991, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.592391304347826, 'f1_weighted': 0.7135170038743004, 'precision_macro': 0.584189497716895, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37487c5d70>
<numpy.flatiter object at 0x7f37487c5d70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f4667b40>
<numpy.flatiter object at 0x7f376040d5c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f92000>
<numpy.flatiter object at 0x7f36f4667b40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f376040d5c0>
<numpy.flatiter object at 0x7f3811f92000>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4667b40>
<numpy.flatiter object at 0x7f376040d5c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:23:44,822][__main__][INFO] - Saved best model at epoch 29 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:23:44,917][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:45,645][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 0.435175
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:23:50,418][__main__][INFO] - Epoch 30: Val Loss: 0.6769, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.7331135215086897, 'f1_weighted': 0.7698925938446182, 'precision_macro': 0.753968253968254, 'recall_macro': 0.7152734976887519}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703143070>
<numpy.flatiter object at 0x7f3703143070>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748649e50>
<numpy.flatiter object at 0x7f3748649e50>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748649e50>
<numpy.flatiter object at 0x7f3748649e50>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374878a6a0>
<numpy.flatiter object at 0x7f374878a6a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374878a6a0>
<numpy.flatiter object at 0x7f374878a6a0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:23:50,481][__main__][INFO] - Saved best model at epoch 30 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:23:50,582][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:23:50,614][__main__][INFO] - Saved model at epoch 30
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:51,314][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.632108
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:23:56,085][__main__][INFO] - Epoch 31: Val Loss: 0.6552, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6242972295603875, 'f1_weighted': 0.734796584718419, 'precision_macro': 0.6303656597774245, 'recall_macro': 0.6270608628659476}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f617a740>
<numpy.flatiter object at 0x7f36f617a740>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748649e50>
<numpy.flatiter object at 0x7f3748649e50>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748649e50>
<numpy.flatiter object at 0x7f3748649e50>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374878a6a0>
<numpy.flatiter object at 0x7f374878a6a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374878a6a0>
<numpy.flatiter object at 0x7f374878a6a0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:23:56,146][__main__][INFO] - Saved best model at epoch 31 with accuracy: 0.7822
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:23:56,245][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:23:56,984][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.473420
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 15:24:01,736][__main__][INFO] - Epoch 32: Val Loss: 0.7057, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.6664700544464609, 'f1_weighted': 0.7082693931825126, 'precision_macro': 0.6859516214779373, 'recall_macro': 0.6628852080123266}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:02,447][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.616697
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:24:07,204][__main__][INFO] - Epoch 33: Val Loss: 0.7102, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5688037087290819, 'f1_weighted': 0.6990228873633633, 'precision_macro': 0.5712820512820513, 'recall_macro': 0.5895608628659477}
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:07,907][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.633066
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 15:24:12,655][__main__][INFO] - Epoch 34: Val Loss: 0.7220, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6550407925407925, 'f1_weighted': 0.7341907267649841, 'precision_macro': 0.7189869989165764, 'recall_macro': 0.6492681047765794}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:13,360][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.440445
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:24:18,114][__main__][INFO] - Epoch 35: Val Loss: 0.6882, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6682234432234433, 'f1_weighted': 0.7482500997352484, 'precision_macro': 0.7633561643835616, 'recall_macro': 0.6557781201848998}
Epoch 36 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:18,825][__main__][INFO] - Train Epoch: 36 [0/7 (0%)]	Loss: 0.430712
Epoch 36 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 36 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:24:23,590][__main__][INFO] - Epoch 36: Val Loss: 0.7804, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6242972295603875, 'f1_weighted': 0.734796584718419, 'precision_macro': 0.6303656597774245, 'recall_macro': 0.6270608628659476}
Epoch 37 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:24,300][__main__][INFO] - Train Epoch: 37 [0/7 (0%)]	Loss: 0.490192
Epoch 37 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 37 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:24:29,050][__main__][INFO] - Epoch 37: Val Loss: 0.9460, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5457778076905819, 'f1_weighted': 0.6706480312858315, 'precision_macro': 0.5879294755877035, 'recall_macro': 0.5316063174114022}
Epoch 38 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:29,747][__main__][INFO] - Train Epoch: 38 [0/7 (0%)]	Loss: 0.564130
Epoch 38 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 38 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:24:34,498][__main__][INFO] - Epoch 38: Val Loss: 0.7462, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.600866977225673, 'f1_weighted': 0.7100526822868622, 'precision_macro': 0.6387130801687764, 'recall_macro': 0.5937981510015409}
Epoch 39 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:35,194][__main__][INFO] - Train Epoch: 39 [0/7 (0%)]	Loss: 0.481209
Epoch 39 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 39 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 15:24:39,945][__main__][INFO] - Epoch 39: Val Loss: 0.6823, Accuracy: 0.7921, Metrics: {'accuracy': 0.7920792079207921, 'f1_macro': 0.6789407581392314, 'f1_weighted': 0.7591954145502631, 'precision_macro': 0.7690972222222222, 'recall_macro': 0.6682781201848998}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f376004ec70>
<numpy.flatiter object at 0x7f376004ec70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748673c80>
<numpy.flatiter object at 0x7f3748673c80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748673c80>
<numpy.flatiter object at 0x7f3748673c80>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748674280>
<numpy.flatiter object at 0x7f3748674280>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748674280>
<numpy.flatiter object at 0x7f3748674280>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:24:40,009][__main__][INFO] - Saved best model at epoch 39 with accuracy: 0.7921
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:24:40,119][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 40 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:40,859][__main__][INFO] - Train Epoch: 40 [0/7 (0%)]	Loss: 0.402706
Epoch 40 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 40 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:24:45,624][__main__][INFO] - Epoch 40: Val Loss: 0.6784, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6935063746322327, 'f1_weighted': 0.7510268223291764, 'precision_macro': 0.7160984848484848, 'recall_macro': 0.6842835130970725}
Epoch 41 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:24:46,321][__main__][INFO] - Train Epoch: 41 [0/7 (0%)]	Loss: 0.564043
Epoch 41 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 41 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 15:24:51,073][__main__][INFO] - Epoch 41: Val Loss: 0.6718, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6653645833333333, 'f1_weighted': 0.742832095709571, 'precision_macro': 0.7380816170861937, 'recall_macro': 0.6370762711864407}
[2025-05-30 15:24:51,074][__main__][INFO] - Early stopping triggered after 41 epochs
[2025-05-30 15:24:51,075][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7921
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f376004a310>
<numpy.flatiter object at 0x7f376004a310>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370337abe0>
<numpy.flatiter object at 0x7f370337abe0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370337abe0>
<numpy.flatiter object at 0x7f370337abe0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370337b1e0>
<numpy.flatiter object at 0x7f370337b1e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370337b1e0>
<numpy.flatiter object at 0x7f370337b1e0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:            Validation Loss ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:        Validation f1_macro ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:     Validation f1_weighted ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb: Validation precision_macro ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñà‚ñà
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.79208
wandb:                 Train Loss 0.56404
wandb:        Validation Accuracy 0.76238
wandb:            Validation Loss 0.67177
wandb:        Validation accuracy 0.76238
wandb:        Validation f1_macro 0.66536
wandb:     Validation f1_weighted 0.74283
wandb: Validation precision_macro 0.73808
wandb:    Validation recall_macro 0.63708
wandb: 
wandb: üöÄ View run jolly-sweep-7 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/cldq2ki2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 13 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_152055-cldq2ki2/logs
wandb: Agent Starting Run: fvk76sdb with config:
wandb: 	Fdropout_rate: 0.2096956746243114
wandb: 	Fnum_heads: 4
wandb: 	Fnum_layers: 3
wandb: 	Mdropout_rate: 0.1022087673970178
wandb: 	Mnum_layers: 1
wandb: 	batch_size: 8
wandb: 	learning_rate: 0.024885962248272827
wandb: 	pretrained_model_name: dmis-lab/biobert-base-cased-v1.1
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_152455-fvk76sdb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/fvk76sdb
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:00,081][__main__][INFO] - Train Epoch: 0 [0/51 (0%)]	Loss: 1.532405
Epoch 0 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.19it/s]Epoch 0 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  8.78it/s]Epoch 0 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.17it/s]Epoch 0 [Train]:   8%|‚ñä         | 4/51 [00:00<00:05,  9.15it/s]Epoch 0 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.30it/s]Epoch 0 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.40it/s]Epoch 0 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.48it/s]Epoch 0 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.49it/s]Epoch 0 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.53it/s]Epoch 0 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.57it/s]Epoch 0 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.39it/s]Epoch 0 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.40it/s]Epoch 0 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.51it/s]Epoch 0 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.59it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.57it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.59it/s]Epoch 0 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.62it/s]Epoch 0 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.66it/s]Epoch 0 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:02<00:03,  9.65it/s]Epoch 0 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.64it/s]Epoch 0 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.65it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.69it/s]Epoch 0 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.72it/s]Epoch 0 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.73it/s]Epoch 0 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.75it/s]Epoch 0 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.73it/s]Epoch 0 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.72it/s]Epoch 0 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.74it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.75it/s]Epoch 0 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.75it/s]Epoch 0 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.76it/s]Epoch 0 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.78it/s]Epoch 0 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.76it/s]Epoch 0 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.75it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.75it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.68it/s]Epoch 0 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.69it/s]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.70it/s]Epoch 0 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.72it/s]Epoch 0 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.71it/s]Epoch 0 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.73it/s]Epoch 0 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.73it/s]Epoch 0 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.72it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.62it/s]Epoch 0 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.61it/s]Epoch 0 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.66it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.71it/s]Epoch 0 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.74it/s]Epoch 0 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.77it/s]Epoch 0 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.77it/s]                                                                Epoch 0 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 0 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.35it/s]Epoch 0 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.33it/s]Epoch 0 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.40it/s]Epoch 0 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.43it/s]Epoch 0 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.46it/s]Epoch 0 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.47it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:06,441][__main__][INFO] - Epoch 0: Val Loss: 1.4011, Accuracy: 0.5149, Metrics: {'accuracy': 0.5148514851485149, 'f1_macro': 0.2023721275018532, 'f1_weighted': 0.4322233557677488, 'precision_macro': 0.178380187416332, 'recall_macro': 0.236864406779661}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38121ec190>
<numpy.flatiter object at 0x7f38121ec190>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748791330>
<numpy.flatiter object at 0x7f3748791330>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748791330>
<numpy.flatiter object at 0x7f3748791330>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748791330>
<numpy.flatiter object at 0x7f3748791330>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748791330>
<numpy.flatiter object at 0x7f3748791330>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:25:06,509][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5149
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:25:06,603][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:25:06,636][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:06,738][__main__][INFO] - Train Epoch: 1 [0/51 (0%)]	Loss: 0.804464
Epoch 1 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.94it/s]Epoch 1 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.47it/s]Epoch 1 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.60it/s]Epoch 1 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.65it/s]Epoch 1 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.70it/s]Epoch 1 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.73it/s]Epoch 1 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.75it/s]Epoch 1 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.76it/s]Epoch 1 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.74it/s]Epoch 1 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.73it/s]Epoch 1 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.74it/s]Epoch 1 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.74it/s]Epoch 1 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.74it/s]Epoch 1 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.73it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.71it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.67it/s]Epoch 1 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.68it/s]Epoch 1 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 1 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.72it/s]Epoch 1 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.73it/s]Epoch 1 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.72it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.70it/s]Epoch 1 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.67it/s]Epoch 1 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.68it/s]Epoch 1 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.70it/s]Epoch 1 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.69it/s]Epoch 1 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.69it/s]Epoch 1 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.68it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.69it/s]Epoch 1 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.71it/s]Epoch 1 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.72it/s]Epoch 1 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.73it/s]Epoch 1 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.74it/s]Epoch 1 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.74it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.73it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.73it/s]Epoch 1 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.75it/s]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.75it/s]Epoch 1 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.73it/s]Epoch 1 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.73it/s]Epoch 1 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.64it/s]Epoch 1 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.63it/s]Epoch 1 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.66it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.68it/s]Epoch 1 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.70it/s]Epoch 1 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.70it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.71it/s]Epoch 1 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.71it/s]Epoch 1 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.70it/s]Epoch 1 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.72it/s]                                                                Epoch 1 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 1 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.45it/s]Epoch 1 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.36it/s]Epoch 1 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.44it/s]Epoch 1 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.46it/s]Epoch 1 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.46it/s]Epoch 1 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.48it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:13,062][__main__][INFO] - Epoch 1: Val Loss: 1.9981, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.21032258064516127, 'f1_weighted': 0.4605557329926541, 'precision_macro': 0.20364583333333336, 'recall_macro': 0.2625}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811ef31e0>
<numpy.flatiter object at 0x7f3811ef31e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811ef31e0>
<numpy.flatiter object at 0x7f3811ef31e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811ef31e0>
<numpy.flatiter object at 0x7f3811ef31e0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811ef31e0>
<numpy.flatiter object at 0x7f3811ef31e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811ef31e0>
<numpy.flatiter object at 0x7f3811ef31e0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:25:13,139][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:25:13,248][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:13,382][__main__][INFO] - Train Epoch: 2 [0/51 (0%)]	Loss: 2.280020
Epoch 2 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.92it/s]Epoch 2 [Train]:   4%|‚ñç         | 2/51 [00:00<00:04,  9.85it/s]Epoch 2 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.80it/s]Epoch 2 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.78it/s]Epoch 2 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.77it/s]Epoch 2 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.75it/s]Epoch 2 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.74it/s]Epoch 2 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.74it/s]Epoch 2 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.73it/s]Epoch 2 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.72it/s]Epoch 2 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.71it/s]Epoch 2 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.72it/s]Epoch 2 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.72it/s]Epoch 2 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.73it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.72it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.73it/s]Epoch 2 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.68it/s]Epoch 2 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 2 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.69it/s]Epoch 2 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.71it/s]Epoch 2 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.71it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.69it/s]Epoch 2 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.66it/s]Epoch 2 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.67it/s]Epoch 2 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.68it/s]Epoch 2 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.64it/s]Epoch 2 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.68it/s]Epoch 2 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.71it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.73it/s]Epoch 2 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.74it/s]Epoch 2 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.74it/s]Epoch 2 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.65it/s]Epoch 2 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.67it/s]Epoch 2 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.69it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.71it/s]Epoch 2 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.69it/s]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.71it/s]Epoch 2 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.73it/s]Epoch 2 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.74it/s]Epoch 2 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.77it/s]Epoch 2 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.80it/s]Epoch 2 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.78it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.77it/s]Epoch 2 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.78it/s]Epoch 2 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.75it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.74it/s]Epoch 2 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.69it/s]Epoch 2 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.69it/s]Epoch 2 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.67it/s]                                                                Epoch 2 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 2 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.41it/s]Epoch 2 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.05it/s]Epoch 2 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.21it/s]Epoch 2 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.32it/s]Epoch 2 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.38it/s]Epoch 2 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:19,716][__main__][INFO] - Epoch 2: Val Loss: 0.9498, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.4976890756302521, 'f1_weighted': 0.6457359181296282, 'precision_macro': 0.5687830687830688, 'recall_macro': 0.4778890600924499}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030cfb40>
<numpy.flatiter object at 0x7f37030cfb40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381178edf0>
<numpy.flatiter object at 0x7f3702f3fb30>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748ff91b0>
<numpy.flatiter object at 0x7f381222eb70>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811795bb0>
<numpy.flatiter object at 0x7f38122aceb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381178edf0>
<numpy.flatiter object at 0x7f3702f3fb30>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:25:19,776][__main__][INFO] - Saved best model at epoch 2 with accuracy: 0.7030
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:25:19,880][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 3 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:20,022][__main__][INFO] - Train Epoch: 3 [0/51 (0%)]	Loss: 0.297798
Epoch 3 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.63it/s]Epoch 3 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.40it/s]Epoch 3 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.59it/s]Epoch 3 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.70it/s]Epoch 3 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.77it/s]Epoch 3 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.81it/s]Epoch 3 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.83it/s]Epoch 3 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.81it/s]Epoch 3 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.81it/s]Epoch 3 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.84it/s]Epoch 3 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.87it/s]Epoch 3 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.87it/s]Epoch 3 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.89it/s]Epoch 3 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.87it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.85it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.81it/s]Epoch 3 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.79it/s]Epoch 3 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.78it/s]Epoch 3 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.79it/s]Epoch 3 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.79it/s]Epoch 3 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.78it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.73it/s]Epoch 3 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.68it/s]Epoch 3 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.66it/s]Epoch 3 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.66it/s]Epoch 3 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.66it/s]Epoch 3 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.66it/s]Epoch 3 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.67it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.69it/s]Epoch 3 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.72it/s]Epoch 3 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.72it/s]Epoch 3 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.74it/s]Epoch 3 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.71it/s]Epoch 3 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.71it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.68it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.67it/s]Epoch 3 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.67it/s]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.68it/s]Epoch 3 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.69it/s]Epoch 3 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.70it/s]Epoch 3 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.71it/s]Epoch 3 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.74it/s]Epoch 3 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.75it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.72it/s]Epoch 3 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.72it/s]Epoch 3 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.71it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.71it/s]Epoch 3 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.70it/s]Epoch 3 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.51it/s]Epoch 3 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.59it/s]                                                                Epoch 3 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 3 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.43it/s]Epoch 3 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.43it/s]Epoch 3 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.47it/s]Epoch 3 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.48it/s]Epoch 3 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.50it/s]Epoch 3 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.48it/s]                                                              [2025-05-30 15:25:26,334][__main__][INFO] - Epoch 3: Val Loss: 0.9429, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.4330404816388798, 'f1_weighted': 0.5981556344585096, 'precision_macro': 0.6225198412698413, 'recall_macro': 0.4628852080123266}
Epoch 4 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:26,438][__main__][INFO] - Train Epoch: 4 [0/51 (0%)]	Loss: 0.666534
Epoch 4 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.87it/s]Epoch 4 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.46it/s]Epoch 4 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.58it/s]Epoch 4 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.61it/s]Epoch 4 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.63it/s]Epoch 4 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.64it/s]Epoch 4 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.63it/s]Epoch 4 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.68it/s]Epoch 4 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.71it/s]Epoch 4 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.73it/s]Epoch 4 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.72it/s]Epoch 4 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.72it/s]Epoch 4 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.72it/s]Epoch 4 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.73it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.74it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.73it/s]Epoch 4 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.73it/s]Epoch 4 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.72it/s]Epoch 4 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.68it/s]Epoch 4 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.67it/s]Epoch 4 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.66it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.68it/s]Epoch 4 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.70it/s]Epoch 4 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.69it/s]Epoch 4 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.72it/s]Epoch 4 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.73it/s]Epoch 4 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.74it/s]Epoch 4 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.75it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.75it/s]Epoch 4 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.71it/s]Epoch 4 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.70it/s]Epoch 4 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.66it/s]Epoch 4 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.66it/s]Epoch 4 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.68it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.70it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.71it/s]Epoch 4 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.73it/s]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.75it/s]Epoch 4 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.76it/s]Epoch 4 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.77it/s]Epoch 4 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.76it/s]Epoch 4 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.76it/s]Epoch 4 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.74it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.72it/s]Epoch 4 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.67it/s]Epoch 4 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.64it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.67it/s]Epoch 4 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.69it/s]Epoch 4 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.71it/s]Epoch 4 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.73it/s]                                                                Epoch 4 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 4 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.20it/s]Epoch 4 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.28it/s]Epoch 4 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.37it/s]Epoch 4 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.43it/s]Epoch 4 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.45it/s]Epoch 4 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.47it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:32,768][__main__][INFO] - Epoch 4: Val Loss: 0.9571, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.38022388059701495, 'f1_weighted': 0.6032954041672824, 'precision_macro': 0.5533333333333333, 'recall_macro': 0.4057781201848998}
Epoch 5 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:32,881][__main__][INFO] - Train Epoch: 5 [0/51 (0%)]	Loss: 0.544013
Epoch 5 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.13it/s]Epoch 5 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.43it/s]Epoch 5 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.54it/s]Epoch 5 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.63it/s]Epoch 5 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.68it/s]Epoch 5 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.68it/s]Epoch 5 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.71it/s]Epoch 5 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.72it/s]Epoch 5 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.74it/s]Epoch 5 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.74it/s]Epoch 5 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.75it/s]Epoch 5 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.72it/s]Epoch 5 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.69it/s]Epoch 5 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.68it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.64it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.64it/s]Epoch 5 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.66it/s]Epoch 5 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.67it/s]Epoch 5 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.68it/s]Epoch 5 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.66it/s]Epoch 5 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.67it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.67it/s]Epoch 5 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.69it/s]Epoch 5 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.65it/s]Epoch 5 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.64it/s]Epoch 5 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.67it/s]Epoch 5 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.66it/s]Epoch 5 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.68it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.70it/s]Epoch 5 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.71it/s]Epoch 5 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.72it/s]Epoch 5 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.72it/s]Epoch 5 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.71it/s]Epoch 5 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.71it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.71it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.67it/s]Epoch 5 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.65it/s]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.66it/s]Epoch 5 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.69it/s]Epoch 5 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.70it/s]Epoch 5 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.70it/s]Epoch 5 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.73it/s]Epoch 5 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.72it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.73it/s]Epoch 5 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.71it/s]Epoch 5 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.72it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.72it/s]Epoch 5 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.66it/s]Epoch 5 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.66it/s]Epoch 5 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.67it/s]                                                                Epoch 5 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 5 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.32it/s]Epoch 5 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.35it/s]Epoch 5 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.41it/s]Epoch 5 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.43it/s]Epoch 5 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.33it/s]Epoch 5 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.36it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:39,221][__main__][INFO] - Epoch 5: Val Loss: 0.8379, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5459423205902079, 'f1_weighted': 0.6575625369377984, 'precision_macro': 0.6091867469879518, 'recall_macro': 0.5437981510015408}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63c4b00>
<numpy.flatiter object at 0x7f36f63c4b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703131580>
<numpy.flatiter object at 0x7f3703131580>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703131580>
<numpy.flatiter object at 0x7f3703131580>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703131b80>
<numpy.flatiter object at 0x7f3703131b80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703131b80>
<numpy.flatiter object at 0x7f3703131b80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:25:39,285][__main__][INFO] - Saved best model at epoch 5 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:25:39,395][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 6 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:39,530][__main__][INFO] - Train Epoch: 6 [0/51 (0%)]	Loss: 0.744891
Epoch 6 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.90it/s]Epoch 6 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.78it/s]Epoch 6 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.65it/s]Epoch 6 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.72it/s]Epoch 6 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.76it/s]Epoch 6 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.77it/s]Epoch 6 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.79it/s]Epoch 6 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.80it/s]Epoch 6 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.83it/s]Epoch 6 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.84it/s]Epoch 6 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.84it/s]Epoch 6 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.84it/s]Epoch 6 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.86it/s]Epoch 6 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.87it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.86it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.83it/s]Epoch 6 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.82it/s]Epoch 6 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.81it/s]Epoch 6 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.80it/s]Epoch 6 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.80it/s]Epoch 6 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.77it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.76it/s]Epoch 6 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.75it/s]Epoch 6 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.76it/s]Epoch 6 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.76it/s]Epoch 6 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.75it/s]Epoch 6 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.64it/s]Epoch 6 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.64it/s]Epoch 6 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.67it/s]Epoch 6 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.67it/s]Epoch 6 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.64it/s]Epoch 6 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.62it/s]Epoch 6 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.64it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.66it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.68it/s]Epoch 6 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.68it/s]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.67it/s]Epoch 6 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.69it/s]Epoch 6 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.72it/s]Epoch 6 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.72it/s]Epoch 6 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.71it/s]Epoch 6 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.72it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.70it/s]Epoch 6 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.72it/s]Epoch 6 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.72it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.71it/s]Epoch 6 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.70it/s]Epoch 6 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.69it/s]Epoch 6 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.69it/s]                                                                Epoch 6 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 6 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.47it/s]Epoch 6 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.35it/s]Epoch 6 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.39it/s]Epoch 6 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.40it/s]Epoch 6 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.44it/s]Epoch 6 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.45it/s]                                                              [2025-05-30 15:25:45,843][__main__][INFO] - Epoch 6: Val Loss: 0.8654, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.6438256938256939, 'f1_weighted': 0.6909133265568909, 'precision_macro': 0.6618773946360154, 'recall_macro': 0.6421224961479199}
Epoch 7 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:45,955][__main__][INFO] - Train Epoch: 7 [0/51 (0%)]	Loss: 0.478106
Epoch 7 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.18it/s]Epoch 7 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.29it/s]Epoch 7 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.49it/s]Epoch 7 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.56it/s]Epoch 7 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.59it/s]Epoch 7 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.30it/s]Epoch 7 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.40it/s]Epoch 7 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.51it/s]Epoch 7 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.53it/s]Epoch 7 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.57it/s]Epoch 7 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.59it/s]Epoch 7 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.63it/s]Epoch 7 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.58it/s]Epoch 7 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.64it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.66it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.67it/s]Epoch 7 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.70it/s]Epoch 7 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.68it/s]Epoch 7 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.68it/s]Epoch 7 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.67it/s]Epoch 7 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.66it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.68it/s]Epoch 7 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.71it/s]Epoch 7 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.72it/s]Epoch 7 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.74it/s]Epoch 7 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.73it/s]Epoch 7 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.72it/s]Epoch 7 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.71it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.73it/s]Epoch 7 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.73it/s]Epoch 7 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.73it/s]Epoch 7 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:02,  9.47it/s]Epoch 7 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.55it/s]Epoch 7 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.60it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.64it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.68it/s]Epoch 7 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.65it/s]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.66it/s]Epoch 7 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.65it/s]Epoch 7 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.66it/s]Epoch 7 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.64it/s]Epoch 7 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.66it/s]Epoch 7 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.66it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.70it/s]Epoch 7 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.71it/s]Epoch 7 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.72it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.72it/s]Epoch 7 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.71it/s]Epoch 7 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.70it/s]Epoch 7 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.72it/s]                                                                Epoch 7 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 7 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.33it/s]Epoch 7 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.34it/s]Epoch 7 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.42it/s]Epoch 7 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.41it/s]Epoch 7 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.43it/s]Epoch 7 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.44it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:52,311][__main__][INFO] - Epoch 7: Val Loss: 0.8823, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.4862859712230216, 'f1_weighted': 0.6461731604815159, 'precision_macro': 0.56875, 'recall_macro': 0.4676617873651772}
Epoch 8 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:52,422][__main__][INFO] - Train Epoch: 8 [0/51 (0%)]	Loss: 1.154526
Epoch 8 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.47it/s]Epoch 8 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.67it/s]Epoch 8 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.74it/s]Epoch 8 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.80it/s]Epoch 8 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.74it/s]Epoch 8 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.71it/s]Epoch 8 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.73it/s]Epoch 8 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.73it/s]Epoch 8 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.71it/s]Epoch 8 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.72it/s]Epoch 8 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.70it/s]Epoch 8 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.70it/s]Epoch 8 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.69it/s]Epoch 8 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.66it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.70it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.71it/s]Epoch 8 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.71it/s]Epoch 8 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.72it/s]Epoch 8 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.72it/s]Epoch 8 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.73it/s]Epoch 8 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.72it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.70it/s]Epoch 8 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.69it/s]Epoch 8 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.70it/s]Epoch 8 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.68it/s]Epoch 8 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.67it/s]Epoch 8 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.68it/s]Epoch 8 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.69it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.72it/s]Epoch 8 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.72it/s]Epoch 8 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.72it/s]Epoch 8 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.74it/s]Epoch 8 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.72it/s]Epoch 8 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.70it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.67it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.66it/s]Epoch 8 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.48it/s]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.55it/s]Epoch 8 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.53it/s]Epoch 8 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.57it/s]Epoch 8 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.60it/s]Epoch 8 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.60it/s]Epoch 8 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.61it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.64it/s]Epoch 8 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.66it/s]Epoch 8 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.68it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.69it/s]Epoch 8 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.70it/s]Epoch 8 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.73it/s]Epoch 8 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.70it/s]                                                                Epoch 8 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 8 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.35it/s]Epoch 8 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.18it/s]Epoch 8 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.30it/s]Epoch 8 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.35it/s]Epoch 8 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.38it/s]Epoch 8 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.40it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:25:58,768][__main__][INFO] - Epoch 8: Val Loss: 0.9417, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5609125528421199, 'f1_weighted': 0.6716187183124559, 'precision_macro': 0.6182249322493225, 'recall_macro': 0.5562981510015408}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702684bc0>
<numpy.flatiter object at 0x7f3702684bc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63d1510>
<numpy.flatiter object at 0x7f36f63d1510>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63d1510>
<numpy.flatiter object at 0x7f36f63d1510>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63d1b10>
<numpy.flatiter object at 0x7f36f63d1b10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63d1b10>
<numpy.flatiter object at 0x7f36f63d1b10>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:25:58,834][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:25:58,936][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:25:59,070][__main__][INFO] - Train Epoch: 9 [0/51 (0%)]	Loss: 0.758530
Epoch 9 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.82it/s]Epoch 9 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.77it/s]Epoch 9 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.74it/s]Epoch 9 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.75it/s]Epoch 9 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.76it/s]Epoch 9 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.72it/s]Epoch 9 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.74it/s]Epoch 9 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.72it/s]Epoch 9 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.75it/s]Epoch 9 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.73it/s]Epoch 9 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.61it/s]Epoch 9 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.61it/s]Epoch 9 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.61it/s]Epoch 9 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.64it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.62it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.66it/s]Epoch 9 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.68it/s]Epoch 9 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 9 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.70it/s]Epoch 9 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.69it/s]Epoch 9 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.67it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.68it/s]Epoch 9 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.65it/s]Epoch 9 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.64it/s]Epoch 9 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.66it/s]Epoch 9 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.46it/s]Epoch 9 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.54it/s]Epoch 9 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.57it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.59it/s]Epoch 9 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.61it/s]Epoch 9 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.64it/s]Epoch 9 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.67it/s]Epoch 9 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.69it/s]Epoch 9 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.69it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.72it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.72it/s]Epoch 9 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.73it/s]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.70it/s]Epoch 9 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.70it/s]Epoch 9 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.69it/s]Epoch 9 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.30it/s]Epoch 9 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:01,  7.25it/s]Epoch 9 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:01,  6.32it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:01,  5.87it/s]Epoch 9 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:05<00:01,  5.58it/s]Epoch 9 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:05<00:00,  5.36it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:05<00:00,  5.21it/s]Epoch 9 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:05<00:00,  5.17it/s]Epoch 9 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  5.14it/s]Epoch 9 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:06<00:00,  5.05it/s]                                                                Epoch 9 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 9 [Val]:   8%|‚ñä         | 1/13 [00:00<00:02,  5.13it/s]Epoch 9 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:02,  5.14it/s]Epoch 9 [Val]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:01,  5.19it/s]Epoch 9 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:01,  5.23it/s]Epoch 9 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:00<00:01,  5.19it/s]Epoch 9 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:01<00:01,  5.23it/s]Epoch 9 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:01<00:01,  5.25it/s]Epoch 9 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:01<00:00,  5.21it/s]Epoch 9 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:01<00:00,  5.16it/s]Epoch 9 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:01<00:00,  5.21it/s]Epoch 9 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:02<00:00,  5.18it/s]Epoch 9 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:02<00:00,  5.16it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:02<00:00,  5.76it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:26:07,586][__main__][INFO] - Epoch 9: Val Loss: 0.7301, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5237418092464506, 'f1_weighted': 0.6818946501493979, 'precision_macro': 0.5914285714285714, 'recall_macro': 0.513424499229584}
Epoch 10 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:07,792][__main__][INFO] - Train Epoch: 10 [0/51 (0%)]	Loss: 0.579109
Epoch 10 [Train]:   2%|‚ñè         | 1/51 [00:00<00:10,  4.91it/s]Epoch 10 [Train]:   4%|‚ñç         | 2/51 [00:00<00:10,  4.82it/s]Epoch 10 [Train]:   6%|‚ñå         | 3/51 [00:00<00:09,  4.86it/s]Epoch 10 [Train]:   8%|‚ñä         | 4/51 [00:00<00:09,  4.94it/s]Epoch 10 [Train]:  10%|‚ñâ         | 5/51 [00:01<00:09,  4.99it/s]Epoch 10 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:01<00:09,  4.95it/s]Epoch 10 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:01<00:08,  4.99it/s]Epoch 10 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:01<00:08,  5.01it/s]Epoch 10 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:01<00:08,  4.98it/s]Epoch 10 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:02<00:08,  4.96it/s]Epoch 10 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:02<00:08,  4.99it/s]Epoch 10 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:02<00:07,  5.00it/s]Epoch 10 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:02<00:07,  4.97it/s]Epoch 10 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:02<00:06,  5.77it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:02<00:05,  6.59it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:02<00:04,  7.32it/s]Epoch 10 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:03<00:04,  7.93it/s]Epoch 10 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:03<00:03,  8.42it/s]Epoch 10 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:03<00:03,  8.82it/s]Epoch 10 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:03<00:03,  9.12it/s]Epoch 10 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:03<00:03,  9.34it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:03<00:03,  9.48it/s]Epoch 10 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:03<00:02,  9.59it/s]Epoch 10 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:03<00:02,  9.68it/s]Epoch 10 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:03<00:02,  9.72it/s]Epoch 10 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:03<00:02,  9.74it/s]Epoch 10 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:04<00:02,  9.78it/s]Epoch 10 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:04<00:02,  9.77it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:04<00:02,  9.78it/s]Epoch 10 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:04<00:02,  9.80it/s]Epoch 10 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:04<00:02,  9.76it/s]Epoch 10 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:04<00:01,  9.80it/s]Epoch 10 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:04<00:01,  9.80it/s]Epoch 10 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:04<00:01,  9.81it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:04<00:01,  9.81it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:04<00:01,  9.82it/s]Epoch 10 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:05<00:01,  9.81it/s]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:05<00:01,  9.81it/s]Epoch 10 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:05<00:01,  9.78it/s]Epoch 10 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:05<00:01,  9.77it/s]Epoch 10 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:05<00:01,  9.78it/s]Epoch 10 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:05<00:00,  9.78it/s]Epoch 10 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:05<00:00,  9.79it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:05<00:00,  9.79it/s]Epoch 10 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:05<00:00,  9.80it/s]Epoch 10 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:05<00:00,  9.81it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:06<00:00,  9.77it/s]Epoch 10 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:06<00:00,  9.79it/s]Epoch 10 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:06<00:00,  9.77it/s]Epoch 10 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:06<00:00,  9.80it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 10 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.51it/s]Epoch 10 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.44it/s]Epoch 10 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.44it/s]Epoch 10 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.46it/s]Epoch 10 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.48it/s]Epoch 10 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.47it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:26:15,256][__main__][INFO] - Epoch 10: Val Loss: 0.7466, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5514964255422271, 'f1_weighted': 0.6799699599185655, 'precision_macro': 0.5817550505050505, 'recall_macro': 0.5461671802773498}
Epoch 11 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:15,367][__main__][INFO] - Train Epoch: 11 [0/51 (0%)]	Loss: 0.505569
Epoch 11 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.30it/s]Epoch 11 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.23it/s]Epoch 11 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.43it/s]Epoch 11 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.51it/s]Epoch 11 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.58it/s]Epoch 11 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.62it/s]Epoch 11 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.69it/s]Epoch 11 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.68it/s]Epoch 11 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.69it/s]Epoch 11 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.70it/s]Epoch 11 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.72it/s]Epoch 11 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.73it/s]Epoch 11 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.69it/s]Epoch 11 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.62it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.62it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.63it/s]Epoch 11 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.66it/s]Epoch 11 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.66it/s]Epoch 11 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.68it/s]Epoch 11 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.69it/s]Epoch 11 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.68it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.67it/s]Epoch 11 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.66it/s]Epoch 11 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.63it/s]Epoch 11 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.63it/s]Epoch 11 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.64it/s]Epoch 11 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.65it/s]Epoch 11 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.66it/s]Epoch 11 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.66it/s]Epoch 11 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.65it/s]Epoch 11 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.60it/s]Epoch 11 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.54it/s]Epoch 11 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.53it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.51it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.57it/s]Epoch 11 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.60it/s]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.63it/s]Epoch 11 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.63it/s]Epoch 11 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.64it/s]Epoch 11 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.65it/s]Epoch 11 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.66it/s]Epoch 11 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.67it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.69it/s]Epoch 11 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.69it/s]Epoch 11 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.71it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.70it/s]Epoch 11 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.72it/s]Epoch 11 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.69it/s]Epoch 11 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.67it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 11 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.32it/s]Epoch 11 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.31it/s]Epoch 11 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.39it/s]Epoch 11 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.39it/s]Epoch 11 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.42it/s]Epoch 11 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                               [2025-05-30 15:26:21,728][__main__][INFO] - Epoch 11: Val Loss: 0.7195, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5667076167076168, 'f1_weighted': 0.6935217846108935, 'precision_macro': 0.5836243173068314, 'recall_macro': 0.5606317411402157}
Epoch 12 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:21,833][__main__][INFO] - Train Epoch: 12 [0/51 (0%)]	Loss: 0.215653
Epoch 12 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.81it/s]Epoch 12 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.77it/s]Epoch 12 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.79it/s]Epoch 12 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.80it/s]Epoch 12 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.80it/s]Epoch 12 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.81it/s]Epoch 12 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.78it/s]Epoch 12 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.77it/s]Epoch 12 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.76it/s]Epoch 12 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.74it/s]Epoch 12 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.71it/s]Epoch 12 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.71it/s]Epoch 12 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.71it/s]Epoch 12 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.70it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.70it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.66it/s]Epoch 12 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.69it/s]Epoch 12 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 12 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.72it/s]Epoch 12 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.72it/s]Epoch 12 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.71it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.70it/s]Epoch 12 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.67it/s]Epoch 12 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.66it/s]Epoch 12 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.65it/s]Epoch 12 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.68it/s]Epoch 12 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.69it/s]Epoch 12 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.68it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.68it/s]Epoch 12 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.69it/s]Epoch 12 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.65it/s]Epoch 12 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.65it/s]Epoch 12 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.67it/s]Epoch 12 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.66it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.64it/s]Epoch 12 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.67it/s]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.67it/s]Epoch 12 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.70it/s]Epoch 12 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.68it/s]Epoch 12 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.67it/s]Epoch 12 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.68it/s]Epoch 12 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.68it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.67it/s]Epoch 12 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.65it/s]Epoch 12 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.64it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.64it/s]Epoch 12 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.65it/s]Epoch 12 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.63it/s]Epoch 12 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.66it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 12 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.35it/s]Epoch 12 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.32it/s]Epoch 12 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.40it/s]Epoch 12 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.43it/s]Epoch 12 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.41it/s]Epoch 12 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.43it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:26:28,171][__main__][INFO] - Epoch 12: Val Loss: 0.8817, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.38295807453416153, 'f1_weighted': 0.5610279195621426, 'precision_macro': 0.5462628089210367, 'recall_macro': 0.4770608628659476}
Epoch 13 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:28,284][__main__][INFO] - Train Epoch: 13 [0/51 (0%)]	Loss: 0.339983
Epoch 13 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.10it/s]Epoch 13 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.49it/s]Epoch 13 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.59it/s]Epoch 13 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.65it/s]Epoch 13 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.69it/s]Epoch 13 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.72it/s]Epoch 13 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.73it/s]Epoch 13 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.73it/s]Epoch 13 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.61it/s]Epoch 13 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.62it/s]Epoch 13 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.64it/s]Epoch 13 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.65it/s]Epoch 13 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.63it/s]Epoch 13 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.67it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.69it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.72it/s]Epoch 13 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.72it/s]Epoch 13 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 13 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.69it/s]Epoch 13 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.67it/s]Epoch 13 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.66it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.67it/s]Epoch 13 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.68it/s]Epoch 13 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.69it/s]Epoch 13 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.70it/s]Epoch 13 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.71it/s]Epoch 13 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.72it/s]Epoch 13 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.66it/s]Epoch 13 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.61it/s]Epoch 13 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.62it/s]Epoch 13 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.62it/s]Epoch 13 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.64it/s]Epoch 13 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.70it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.70it/s]Epoch 13 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.68it/s]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.65it/s]Epoch 13 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.63it/s]Epoch 13 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.63it/s]Epoch 13 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.62it/s]Epoch 13 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.65it/s]Epoch 13 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.66it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.68it/s]Epoch 13 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.68it/s]Epoch 13 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.65it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.65it/s]Epoch 13 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.64it/s]Epoch 13 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.60it/s]Epoch 13 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.61it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 13 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.33it/s]Epoch 13 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.30it/s]Epoch 13 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.36it/s]Epoch 13 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.37it/s]Epoch 13 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.40it/s]Epoch 13 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.39it/s]                                                               [2025-05-30 15:26:34,638][__main__][INFO] - Epoch 13: Val Loss: 0.7025, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.633957033957034, 'f1_weighted': 0.7300192805143301, 'precision_macro': 0.7398267526188558, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486173c0>
<numpy.flatiter object at 0x7f37486173c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37492d8650>
<numpy.flatiter object at 0x7f37492d8650>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492d8650>
<numpy.flatiter object at 0x7f37492d8650>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37492d8650>
<numpy.flatiter object at 0x7f37492d8650>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492d8650>
<numpy.flatiter object at 0x7f37492d8650>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:26:34,711][__main__][INFO] - Saved best model at epoch 13 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:26:34,812][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 14 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:34,946][__main__][INFO] - Train Epoch: 14 [0/51 (0%)]	Loss: 1.114537
Epoch 14 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.86it/s]Epoch 14 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.76it/s]Epoch 14 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.68it/s]Epoch 14 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.67it/s]Epoch 14 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.66it/s]Epoch 14 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.69it/s]Epoch 14 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.72it/s]Epoch 14 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.71it/s]Epoch 14 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.68it/s]Epoch 14 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.69it/s]Epoch 14 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.64it/s]Epoch 14 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.65it/s]Epoch 14 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.63it/s]Epoch 14 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.64it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.66it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.69it/s]Epoch 14 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.68it/s]Epoch 14 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.68it/s]Epoch 14 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.69it/s]Epoch 14 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.68it/s]Epoch 14 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.69it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.67it/s]Epoch 14 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.66it/s]Epoch 14 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.65it/s]Epoch 14 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.66it/s]Epoch 14 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.65it/s]Epoch 14 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.67it/s]Epoch 14 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.69it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.69it/s]Epoch 14 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.68it/s]Epoch 14 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.66it/s]Epoch 14 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.62it/s]Epoch 14 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.61it/s]Epoch 14 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.65it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.68it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.70it/s]Epoch 14 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.72it/s]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.73it/s]Epoch 14 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.74it/s]Epoch 14 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.75it/s]Epoch 14 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.74it/s]Epoch 14 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.73it/s]Epoch 14 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.70it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.66it/s]Epoch 14 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.66it/s]Epoch 14 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.66it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.67it/s]Epoch 14 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.68it/s]Epoch 14 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.69it/s]Epoch 14 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.67it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 14 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.36it/s]Epoch 14 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.30it/s]Epoch 14 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.36it/s]Epoch 14 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.37it/s]Epoch 14 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.43it/s]Epoch 14 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.44it/s]                                                               [2025-05-30 15:26:41,291][__main__][INFO] - Epoch 14: Val Loss: 0.7507, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5749785542875137, 'f1_weighted': 0.6928375136928415, 'precision_macro': 0.610498366013072, 'recall_macro': 0.5563944530046225}
Epoch 15 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:41,405][__main__][INFO] - Train Epoch: 15 [0/51 (0%)]	Loss: 0.596879
Epoch 15 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.23it/s]Epoch 15 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.56it/s]Epoch 15 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.66it/s]Epoch 15 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.51it/s]Epoch 15 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.58it/s]Epoch 15 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.66it/s]Epoch 15 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.71it/s]Epoch 15 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.73it/s]Epoch 15 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.72it/s]Epoch 15 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.75it/s]Epoch 15 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.76it/s]Epoch 15 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.77it/s]Epoch 15 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.77it/s]Epoch 15 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.77it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.83it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.83it/s]Epoch 15 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.81it/s]Epoch 15 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.81it/s]Epoch 15 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.83it/s]Epoch 15 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.83it/s]Epoch 15 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.84it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.80it/s]Epoch 15 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.82it/s]Epoch 15 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.81it/s]Epoch 15 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.80it/s]Epoch 15 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.77it/s]Epoch 15 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.75it/s]Epoch 15 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.71it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.70it/s]Epoch 15 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.66it/s]Epoch 15 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.64it/s]Epoch 15 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.65it/s]Epoch 15 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.66it/s]Epoch 15 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.68it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.67it/s]Epoch 15 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.67it/s]Epoch 15 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.64it/s]Epoch 15 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.39it/s]Epoch 15 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.49it/s]Epoch 15 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.54it/s]Epoch 15 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.56it/s]Epoch 15 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.57it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.55it/s]Epoch 15 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.60it/s]Epoch 15 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.58it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.61it/s]Epoch 15 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.65it/s]Epoch 15 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.67it/s]Epoch 15 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.70it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 15 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.21it/s]Epoch 15 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.21it/s]Epoch 15 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.34it/s]Epoch 15 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.39it/s]Epoch 15 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.43it/s]Epoch 15 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                               [2025-05-30 15:26:47,741][__main__][INFO] - Epoch 15: Val Loss: 0.7569, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.673015873015873, 'f1_weighted': 0.7448687725915448, 'precision_macro': 0.714863184079602, 'recall_macro': 0.6430662557781203}
Epoch 16 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:47,854][__main__][INFO] - Train Epoch: 16 [0/51 (0%)]	Loss: 0.906965
Epoch 16 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.36it/s]Epoch 16 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.58it/s]Epoch 16 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.64it/s]Epoch 16 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.66it/s]Epoch 16 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.68it/s]Epoch 16 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.65it/s]Epoch 16 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.65it/s]Epoch 16 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.66it/s]Epoch 16 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.66it/s]Epoch 16 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.68it/s]Epoch 16 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.68it/s]Epoch 16 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.68it/s]Epoch 16 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.70it/s]Epoch 16 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.70it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.69it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.69it/s]Epoch 16 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.66it/s]Epoch 16 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.66it/s]Epoch 16 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.63it/s]Epoch 16 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.67it/s]Epoch 16 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.70it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.70it/s]Epoch 16 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.71it/s]Epoch 16 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.72it/s]Epoch 16 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.72it/s]Epoch 16 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.72it/s]Epoch 16 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.71it/s]Epoch 16 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.67it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.66it/s]Epoch 16 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.65it/s]Epoch 16 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.64it/s]Epoch 16 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.66it/s]Epoch 16 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.67it/s]Epoch 16 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.68it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.66it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.66it/s]Epoch 16 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.66it/s]Epoch 16 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.62it/s]Epoch 16 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.60it/s]Epoch 16 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.61it/s]Epoch 16 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.63it/s]Epoch 16 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.65it/s]Epoch 16 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.64it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.64it/s]Epoch 16 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.65it/s]Epoch 16 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.65it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.60it/s]Epoch 16 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.62it/s]Epoch 16 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.64it/s]Epoch 16 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.67it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 16 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.39it/s]Epoch 16 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.37it/s]Epoch 16 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.41it/s]Epoch 16 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.43it/s]Epoch 16 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.44it/s]Epoch 16 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.43it/s]                                                               [2025-05-30 15:26:54,201][__main__][INFO] - Epoch 16: Val Loss: 0.7709, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6152159244264508, 'f1_weighted': 0.7203337742681151, 'precision_macro': 0.7300228310502282, 'recall_macro': 0.5875963020030817}
Epoch 17 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:26:54,315][__main__][INFO] - Train Epoch: 17 [0/51 (0%)]	Loss: 0.380763
Epoch 17 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.25it/s]Epoch 17 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.47it/s]Epoch 17 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.52it/s]Epoch 17 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.58it/s]Epoch 17 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.64it/s]Epoch 17 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.68it/s]Epoch 17 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.71it/s]Epoch 17 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.72it/s]Epoch 17 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.74it/s]Epoch 17 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.76it/s]Epoch 17 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.76it/s]Epoch 17 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.75it/s]Epoch 17 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.73it/s]Epoch 17 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.70it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.70it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.68it/s]Epoch 17 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.69it/s]Epoch 17 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.65it/s]Epoch 17 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.63it/s]Epoch 17 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.66it/s]Epoch 17 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.67it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.67it/s]Epoch 17 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.67it/s]Epoch 17 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.66it/s]Epoch 17 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.65it/s]Epoch 17 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.62it/s]Epoch 17 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.64it/s]Epoch 17 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.68it/s]Epoch 17 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.70it/s]Epoch 17 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.70it/s]Epoch 17 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.70it/s]Epoch 17 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.65it/s]Epoch 17 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.64it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.63it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.65it/s]Epoch 17 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.65it/s]Epoch 17 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.68it/s]Epoch 17 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.69it/s]Epoch 17 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.69it/s]Epoch 17 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.72it/s]Epoch 17 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.73it/s]Epoch 17 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.72it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.70it/s]Epoch 17 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.69it/s]Epoch 17 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.66it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.64it/s]Epoch 17 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.67it/s]Epoch 17 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.67it/s]Epoch 17 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.70it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 17 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.34it/s]Epoch 17 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.36it/s]Epoch 17 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.38it/s]Epoch 17 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.41it/s]Epoch 17 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.37it/s]Epoch 17 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.40it/s]                                                               [2025-05-30 15:27:00,658][__main__][INFO] - Epoch 17: Val Loss: 0.7483, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5995408523663763, 'f1_weighted': 0.7014502957241805, 'precision_macro': 0.6340326340326341, 'recall_macro': 0.5997881355932204}
Epoch 18 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:27:00,762][__main__][INFO] - Train Epoch: 18 [0/51 (0%)]	Loss: 0.140425
Epoch 18 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.85it/s]Epoch 18 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.51it/s]Epoch 18 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.58it/s]Epoch 18 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.61it/s]Epoch 18 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.26it/s]Epoch 18 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.37it/s]Epoch 18 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.46it/s]Epoch 18 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.53it/s]Epoch 18 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.59it/s]Epoch 18 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.58it/s]Epoch 18 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.60it/s]Epoch 18 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.63it/s]Epoch 18 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.63it/s]Epoch 18 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.64it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.64it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.57it/s]Epoch 18 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.61it/s]Epoch 18 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.64it/s]Epoch 18 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.66it/s]Epoch 18 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.66it/s]Epoch 18 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.68it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.68it/s]Epoch 18 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.68it/s]Epoch 18 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.68it/s]Epoch 18 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.65it/s]Epoch 18 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.64it/s]Epoch 18 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.66it/s]Epoch 18 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.68it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.68it/s]Epoch 18 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.69it/s]Epoch 18 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.65it/s]Epoch 18 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.67it/s]Epoch 18 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.71it/s]Epoch 18 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.71it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.67it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.68it/s]Epoch 18 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.65it/s]Epoch 18 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.65it/s]Epoch 18 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.67it/s]Epoch 18 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.68it/s]Epoch 18 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.67it/s]Epoch 18 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.68it/s]Epoch 18 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.69it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.68it/s]Epoch 18 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.64it/s]Epoch 18 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.63it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.63it/s]Epoch 18 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.58it/s]Epoch 18 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.61it/s]Epoch 18 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.60it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 18 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.33it/s]Epoch 18 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.27it/s]Epoch 18 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.34it/s]Epoch 18 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.36it/s]Epoch 18 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.38it/s]Epoch 18 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.41it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:27:07,139][__main__][INFO] - Epoch 18: Val Loss: 0.8448, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.47971222040370975, 'f1_weighted': 0.6222445485137712, 'precision_macro': 0.5476626016260162, 'recall_macro': 0.5332627118644068}
Epoch 19 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:27:07,250][__main__][INFO] - Train Epoch: 19 [0/51 (0%)]	Loss: 0.733269
Epoch 19 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.35it/s]Epoch 19 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.58it/s]Epoch 19 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.65it/s]Epoch 19 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.68it/s]Epoch 19 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.71it/s]Epoch 19 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.73it/s]Epoch 19 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.72it/s]Epoch 19 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.73it/s]Epoch 19 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.71it/s]Epoch 19 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.69it/s]Epoch 19 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.68it/s]Epoch 19 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.66it/s]Epoch 19 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.69it/s]Epoch 19 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.70it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.71it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.71it/s]Epoch 19 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.70it/s]Epoch 19 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.70it/s]Epoch 19 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.71it/s]Epoch 19 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.69it/s]Epoch 19 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.70it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.66it/s]Epoch 19 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.66it/s]Epoch 19 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.66it/s]Epoch 19 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.64it/s]Epoch 19 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.66it/s]Epoch 19 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.40it/s]Epoch 19 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.47it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.54it/s]Epoch 19 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.55it/s]Epoch 19 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.61it/s]Epoch 19 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.63it/s]Epoch 19 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.65it/s]Epoch 19 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.63it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.58it/s]Epoch 19 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.57it/s]Epoch 19 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.60it/s]Epoch 19 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.61it/s]Epoch 19 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.67it/s]Epoch 19 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.67it/s]Epoch 19 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.67it/s]Epoch 19 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.67it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.65it/s]Epoch 19 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.62it/s]Epoch 19 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.63it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.64it/s]Epoch 19 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.65it/s]Epoch 19 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.65it/s]Epoch 19 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.67it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 19 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.30it/s]Epoch 19 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.29it/s]Epoch 19 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.37it/s]Epoch 19 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.40it/s]Epoch 19 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.41it/s]Epoch 19 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:27:13,609][__main__][INFO] - Epoch 19: Val Loss: 0.7505, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.5961173860427592, 'f1_weighted': 0.7147168891959789, 'precision_macro': 0.6131372549019608, 'recall_macro': 0.5918335901386749}
Epoch 20 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:27:13,718][__main__][INFO] - Train Epoch: 20 [0/51 (0%)]	Loss: 0.960476
Epoch 20 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.57it/s]Epoch 20 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.62it/s]Epoch 20 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.45it/s]Epoch 20 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.55it/s]Epoch 20 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.60it/s]Epoch 20 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.61it/s]Epoch 20 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.60it/s]Epoch 20 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.63it/s]Epoch 20 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.66it/s]Epoch 20 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.66it/s]Epoch 20 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.67it/s]Epoch 20 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.67it/s]Epoch 20 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.67it/s]Epoch 20 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.68it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.68it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.65it/s]Epoch 20 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.65it/s]Epoch 20 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.64it/s]Epoch 20 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.65it/s]Epoch 20 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.66it/s]Epoch 20 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.68it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.69it/s]Epoch 20 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.68it/s]Epoch 20 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.67it/s]Epoch 20 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.66it/s]Epoch 20 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.62it/s]Epoch 20 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.61it/s]Epoch 20 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.62it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.62it/s]Epoch 20 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.60it/s]Epoch 20 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.62it/s]Epoch 20 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.63it/s]Epoch 20 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.62it/s]Epoch 20 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.63it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.60it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.63it/s]Epoch 20 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.64it/s]Epoch 20 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.67it/s]Epoch 20 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.68it/s]Epoch 20 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.69it/s]Epoch 20 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.70it/s]Epoch 20 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.69it/s]Epoch 20 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.66it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.65it/s]Epoch 20 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.63it/s]Epoch 20 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.62it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.62it/s]Epoch 20 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.63it/s]Epoch 20 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.65it/s]Epoch 20 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.63it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 20 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.33it/s]Epoch 20 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.30it/s]Epoch 20 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.38it/s]Epoch 20 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.38it/s]Epoch 20 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.41it/s]Epoch 20 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:27:20,083][__main__][INFO] - Epoch 20: Val Loss: 1.0464, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.48708220415537484, 'f1_weighted': 0.6586349691879756, 'precision_macro': 0.5770676691729323, 'recall_macro': 0.4781972265023112}
Epoch 21 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:27:20,188][__main__][INFO] - Train Epoch: 21 [0/51 (0%)]	Loss: 0.617690
Epoch 21 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.78it/s]Epoch 21 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.78it/s]Epoch 21 [Train]:   6%|‚ñå         | 3/51 [00:00<00:04,  9.74it/s]Epoch 21 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.74it/s]Epoch 21 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.75it/s]Epoch 21 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.78it/s]Epoch 21 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.80it/s]Epoch 21 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.81it/s]Epoch 21 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.82it/s]Epoch 21 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.79it/s]Epoch 21 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.77it/s]Epoch 21 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.66it/s]Epoch 21 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:04,  9.37it/s]Epoch 21 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.47it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.52it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.57it/s]Epoch 21 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.59it/s]Epoch 21 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.61it/s]Epoch 21 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.62it/s]Epoch 21 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.62it/s]Epoch 21 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.63it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:03,  9.60it/s]Epoch 21 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.63it/s]Epoch 21 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.64it/s]Epoch 21 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.64it/s]Epoch 21 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.64it/s]Epoch 21 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.63it/s]Epoch 21 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.65it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.62it/s]Epoch 21 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.66it/s]Epoch 21 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.68it/s]Epoch 21 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.66it/s]Epoch 21 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.65it/s]Epoch 21 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.65it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.66it/s]Epoch 21 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.64it/s]Epoch 21 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.65it/s]Epoch 21 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.67it/s]Epoch 21 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.68it/s]Epoch 21 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.69it/s]Epoch 21 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.70it/s]Epoch 21 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.69it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.70it/s]Epoch 21 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.68it/s]Epoch 21 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.66it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.63it/s]Epoch 21 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.64it/s]Epoch 21 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.64it/s]Epoch 21 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.65it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 21 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.37it/s]Epoch 21 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.31it/s]Epoch 21 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.33it/s]Epoch 21 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.38it/s]Epoch 21 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.21it/s]Epoch 21 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.24it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:27:26,560][__main__][INFO] - Epoch 21: Val Loss: 0.7595, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.546588693957115, 'f1_weighted': 0.683986644278463, 'precision_macro': 0.5869883040935673, 'recall_macro': 0.5338790446841294}
Epoch 22 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:27:26,664][__main__][INFO] - Train Epoch: 22 [0/51 (0%)]	Loss: 0.533630
Epoch 22 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.91it/s]Epoch 22 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.50it/s]Epoch 22 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.59it/s]Epoch 22 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.61it/s]Epoch 22 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.66it/s]Epoch 22 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.70it/s]Epoch 22 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.73it/s]Epoch 22 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.75it/s]Epoch 22 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.73it/s]Epoch 22 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.77it/s]Epoch 22 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.79it/s]Epoch 22 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:03,  9.77it/s]Epoch 22 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.78it/s]Epoch 22 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.80it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.81it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.80it/s]Epoch 22 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.82it/s]Epoch 22 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.83it/s]Epoch 22 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.83it/s]Epoch 22 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.85it/s]Epoch 22 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.81it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.80it/s]Epoch 22 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.76it/s]Epoch 22 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.75it/s]Epoch 22 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.74it/s]Epoch 22 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.72it/s]Epoch 22 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.70it/s]Epoch 22 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.68it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:02<00:02,  9.68it/s]Epoch 22 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.69it/s]Epoch 22 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.68it/s]Epoch 22 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.70it/s]Epoch 22 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.66it/s]Epoch 22 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.66it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.65it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.63it/s]Epoch 22 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.63it/s]Epoch 22 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.65it/s]Epoch 22 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.66it/s]Epoch 22 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.66it/s]Epoch 22 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.67it/s]Epoch 22 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.67it/s]Epoch 22 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.68it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.66it/s]Epoch 22 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.61it/s]Epoch 22 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.61it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.62it/s]Epoch 22 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.65it/s]Epoch 22 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.66it/s]Epoch 22 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.65it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 22 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.29it/s]Epoch 22 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.29it/s]Epoch 22 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.36it/s]Epoch 22 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.38it/s]Epoch 22 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.41it/s]Epoch 22 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.42it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:27:32,997][__main__][INFO] - Epoch 22: Val Loss: 0.7360, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6016830294530154, 'f1_weighted': 0.7064557788177135, 'precision_macro': 0.6349252013808976, 'recall_macro': 0.6040254237288136}
Epoch 23 [Train]:   0%|          | 0/51 [00:00<?, ?it/s][2025-05-30 15:27:33,109][__main__][INFO] - Train Epoch: 23 [0/51 (0%)]	Loss: 0.296129
Epoch 23 [Train]:   2%|‚ñè         | 1/51 [00:00<00:05,  9.42it/s]Epoch 23 [Train]:   4%|‚ñç         | 2/51 [00:00<00:05,  9.33it/s]Epoch 23 [Train]:   6%|‚ñå         | 3/51 [00:00<00:05,  9.49it/s]Epoch 23 [Train]:   8%|‚ñä         | 4/51 [00:00<00:04,  9.56it/s]Epoch 23 [Train]:  10%|‚ñâ         | 5/51 [00:00<00:04,  9.60it/s]Epoch 23 [Train]:  12%|‚ñà‚ñè        | 6/51 [00:00<00:04,  9.63it/s]Epoch 23 [Train]:  14%|‚ñà‚ñé        | 7/51 [00:00<00:04,  9.65it/s]Epoch 23 [Train]:  16%|‚ñà‚ñå        | 8/51 [00:00<00:04,  9.67it/s]Epoch 23 [Train]:  18%|‚ñà‚ñä        | 9/51 [00:00<00:04,  9.69it/s]Epoch 23 [Train]:  20%|‚ñà‚ñâ        | 10/51 [00:01<00:04,  9.69it/s]Epoch 23 [Train]:  22%|‚ñà‚ñà‚ñè       | 11/51 [00:01<00:04,  9.69it/s]Epoch 23 [Train]:  24%|‚ñà‚ñà‚ñé       | 12/51 [00:01<00:04,  9.71it/s]Epoch 23 [Train]:  25%|‚ñà‚ñà‚ñå       | 13/51 [00:01<00:03,  9.71it/s]Epoch 23 [Train]:  27%|‚ñà‚ñà‚ñã       | 14/51 [00:01<00:03,  9.71it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñâ       | 15/51 [00:01<00:03,  9.67it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà‚ñè      | 16/51 [00:01<00:03,  9.66it/s]Epoch 23 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 17/51 [00:01<00:03,  9.65it/s]Epoch 23 [Train]:  35%|‚ñà‚ñà‚ñà‚ñå      | 18/51 [00:01<00:03,  9.64it/s]Epoch 23 [Train]:  37%|‚ñà‚ñà‚ñà‚ñã      | 19/51 [00:01<00:03,  9.66it/s]Epoch 23 [Train]:  39%|‚ñà‚ñà‚ñà‚ñâ      | 20/51 [00:02<00:03,  9.65it/s]Epoch 23 [Train]:  41%|‚ñà‚ñà‚ñà‚ñà      | 21/51 [00:02<00:03,  9.65it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 22/51 [00:02<00:02,  9.68it/s]Epoch 23 [Train]:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/51 [00:02<00:02,  9.61it/s]Epoch 23 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 24/51 [00:02<00:02,  9.61it/s]Epoch 23 [Train]:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 25/51 [00:02<00:02,  9.61it/s]Epoch 23 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 26/51 [00:02<00:02,  9.61it/s]Epoch 23 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 27/51 [00:02<00:02,  9.63it/s]Epoch 23 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 28/51 [00:02<00:02,  9.66it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 29/51 [00:03<00:02,  9.66it/s]Epoch 23 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 30/51 [00:03<00:02,  9.67it/s]Epoch 23 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 31/51 [00:03<00:02,  9.68it/s]Epoch 23 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 32/51 [00:03<00:01,  9.68it/s]Epoch 23 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 33/51 [00:03<00:01,  9.69it/s]Epoch 23 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 34/51 [00:03<00:01,  9.68it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 35/51 [00:03<00:01,  9.64it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 36/51 [00:03<00:01,  9.65it/s]Epoch 23 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 37/51 [00:03<00:01,  9.66it/s]Epoch 23 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 38/51 [00:03<00:01,  9.59it/s]Epoch 23 [Train]:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 39/51 [00:04<00:01,  9.60it/s]Epoch 23 [Train]:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 40/51 [00:04<00:01,  9.62it/s]Epoch 23 [Train]:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 41/51 [00:04<00:01,  9.66it/s]Epoch 23 [Train]:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 42/51 [00:04<00:00,  9.67it/s]Epoch 23 [Train]:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 43/51 [00:04<00:00,  9.67it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 44/51 [00:04<00:00,  9.66it/s]Epoch 23 [Train]:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 45/51 [00:04<00:00,  9.65it/s]Epoch 23 [Train]:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 46/51 [00:04<00:00,  9.65it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 47/51 [00:04<00:00,  9.66it/s]Epoch 23 [Train]:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 48/51 [00:04<00:00,  9.66it/s]Epoch 23 [Train]:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 49/51 [00:05<00:00,  9.70it/s]Epoch 23 [Train]:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 50/51 [00:05<00:00,  9.69it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/13 [00:00<?, ?it/s]Epoch 23 [Val]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:01, 10.26it/s]Epoch 23 [Val]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:00<00:00, 10.28it/s]Epoch 23 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:00<00:00, 10.34it/s]Epoch 23 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:00<00:00, 10.38it/s]Epoch 23 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:00<00:00, 10.42it/s]Epoch 23 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:01<00:00, 10.44it/s]                                                               [2025-05-30 15:27:39,467][__main__][INFO] - Epoch 23: Val Loss: 0.7585, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6055493063367079, 'f1_weighted': 0.7049044611997758, 'precision_macro': 0.5965909090909091, 'recall_macro': 0.6183744221879816}
[2025-05-30 15:27:39,468][__main__][INFO] - Early stopping triggered after 23 epochs
[2025-05-30 15:27:39,469][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7624
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370312b4c0>
<numpy.flatiter object at 0x7f370312b4c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37492ff3d0>
<numpy.flatiter object at 0x7f37492ff3d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492ff3d0>
<numpy.flatiter object at 0x7f37492ff3d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37492ff9d0>
<numpy.flatiter object at 0x7f37492ff9d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492ff9d0>
<numpy.flatiter object at 0x7f37492ff9d0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà
wandb:                 Train Loss ‚ñÜ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ
wandb:        Validation Accuracy ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá
wandb:            Validation Loss ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñá
wandb:     Validation f1_weighted ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.76238
wandb:                 Train Loss 0.29613
wandb:        Validation Accuracy 0.74257
wandb:            Validation Loss 0.7585
wandb:        Validation accuracy 0.74257
wandb:        Validation f1_macro 0.60555
wandb:     Validation f1_weighted 0.7049
wandb: Validation precision_macro 0.59659
wandb:    Validation recall_macro 0.61837
wandb: 
wandb: üöÄ View run icy-sweep-8 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/fvk76sdb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_152455-fvk76sdb/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 1p6fh40j with config:
wandb: 	Fdropout_rate: 0.3112211670395192
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 5
wandb: 	Mdropout_rate: 0.302025161907234
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 4
wandb: 	learning_rate: 0.0453456397122867
wandb: 	pretrained_model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_152752-1p6fh40j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/1p6fh40j
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:27:56,026][__main__][INFO] - Train Epoch: 0 [0/101 (0%)]	Loss: 2.048912
Epoch 0 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 14.46it/s]Epoch 0 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 14.98it/s]Epoch 0 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.41it/s]Epoch 0 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.53it/s]Epoch 0 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.53it/s]Epoch 0 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.40it/s]Epoch 0 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.40it/s]Epoch 0 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.39it/s]Epoch 0 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.43it/s]Epoch 0 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.48it/s]Epoch 0 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.47it/s]Epoch 0 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.54it/s]Epoch 0 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.56it/s]Epoch 0 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.53it/s]Epoch 0 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.54it/s]Epoch 0 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.52it/s]Epoch 0 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.48it/s]Epoch 0 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.48it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.43it/s]Epoch 0 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.46it/s]Epoch 0 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.47it/s]Epoch 0 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.40it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.43it/s]Epoch 0 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.45it/s]Epoch 0 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.46it/s]Epoch 0 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.47it/s]Epoch 0 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.50it/s]Epoch 0 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.45it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.44it/s]Epoch 0 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.40it/s]Epoch 0 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.43it/s]Epoch 0 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.41it/s]Epoch 0 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.43it/s]Epoch 0 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.47it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.47it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.46it/s]Epoch 0 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.50it/s]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.48it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.42it/s]Epoch 0 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.45it/s]Epoch 0 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.48it/s]Epoch 0 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.51it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.52it/s]Epoch 0 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.50it/s]Epoch 0 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.53it/s]Epoch 0 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.52it/s]Epoch 0 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.54it/s]Epoch 0 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.56it/s]Epoch 0 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.53it/s]Epoch 0 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.48it/s][2025-05-30 15:28:02,478][__main__][INFO] - Train Epoch: 0 [100/101 (99%)]	Loss: 1.488593
                                                                  Epoch 0 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 0 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.05it/s]Epoch 0 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.17it/s]Epoch 0 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.09it/s]Epoch 0 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.11it/s]Epoch 0 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.28it/s]Epoch 0 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.31it/s]Epoch 0 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.40it/s]Epoch 0 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.32it/s]Epoch 0 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.41it/s]Epoch 0 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.44it/s]Epoch 0 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.52it/s]Epoch 0 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.52it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:28:03,954][__main__][INFO] - Epoch 0: Val Loss: 1.1095, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37487b4420>
<numpy.flatiter object at 0x7f37487b4420>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38116c2600>
<numpy.flatiter object at 0x7f38116c2600>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38116c2600>
<numpy.flatiter object at 0x7f38116c2600>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38116c2c00>
<numpy.flatiter object at 0x7f38116c2c00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38116c2c00>
<numpy.flatiter object at 0x7f38116c2c00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:28:04,018][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:28:04,114][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:28:04,146][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:04,212][__main__][INFO] - Train Epoch: 1 [0/101 (0%)]	Loss: 1.213653
Epoch 1 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.60it/s]Epoch 1 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.60it/s]Epoch 1 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.62it/s]Epoch 1 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.58it/s]Epoch 1 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.59it/s]Epoch 1 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.65it/s]Epoch 1 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.63it/s]Epoch 1 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.54it/s]Epoch 1 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.56it/s]Epoch 1 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.54it/s]Epoch 1 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.54it/s]Epoch 1 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.52it/s]Epoch 1 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.52it/s]Epoch 1 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.49it/s]Epoch 1 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.55it/s]Epoch 1 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.53it/s]Epoch 1 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.53it/s]Epoch 1 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.51it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.52it/s]Epoch 1 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.56it/s]Epoch 1 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.55it/s]Epoch 1 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.51it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.49it/s]Epoch 1 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.53it/s]Epoch 1 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.53it/s]Epoch 1 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.51it/s]Epoch 1 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.49it/s]Epoch 1 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.50it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.53it/s]Epoch 1 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.52it/s]Epoch 1 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 15.55it/s]Epoch 1 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.55it/s]Epoch 1 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.54it/s]Epoch 1 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.42it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.41it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.40it/s]Epoch 1 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.41it/s]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.41it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.42it/s]Epoch 1 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.36it/s]Epoch 1 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.38it/s]Epoch 1 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.40it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.40it/s]Epoch 1 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.44it/s]Epoch 1 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.40it/s]Epoch 1 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.42it/s]Epoch 1 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.45it/s]Epoch 1 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.43it/s]Epoch 1 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.46it/s]Epoch 1 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.44it/s][2025-05-30 15:28:10,658][__main__][INFO] - Train Epoch: 1 [100/101 (99%)]	Loss: 0.749523
                                                                  Epoch 1 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 1 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.67it/s]Epoch 1 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.90it/s]Epoch 1 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.85it/s]Epoch 1 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.76it/s]Epoch 1 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 16.86it/s]Epoch 1 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 16.96it/s]Epoch 1 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 16.98it/s]Epoch 1 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.08it/s]Epoch 1 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.16it/s]Epoch 1 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.21it/s]Epoch 1 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.25it/s]Epoch 1 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.31it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:28:12,158][__main__][INFO] - Epoch 1: Val Loss: 1.0037, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:12,233][__main__][INFO] - Train Epoch: 2 [0/101 (0%)]	Loss: 1.193883
Epoch 2 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 14.76it/s]Epoch 2 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.21it/s]Epoch 2 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.39it/s]Epoch 2 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.51it/s]Epoch 2 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.52it/s]Epoch 2 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.42it/s]Epoch 2 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.42it/s]Epoch 2 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.43it/s]Epoch 2 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.43it/s]Epoch 2 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.45it/s]Epoch 2 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.46it/s]Epoch 2 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.48it/s]Epoch 2 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.31it/s]Epoch 2 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.31it/s]Epoch 2 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.37it/s]Epoch 2 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.42it/s]Epoch 2 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.47it/s]Epoch 2 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.49it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.52it/s]Epoch 2 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.57it/s]Epoch 2 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.55it/s]Epoch 2 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.50it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.49it/s]Epoch 2 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.49it/s]Epoch 2 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.50it/s]Epoch 2 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.42it/s]Epoch 2 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.41it/s]Epoch 2 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.47it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.39it/s]Epoch 2 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.39it/s]Epoch 2 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.39it/s]Epoch 2 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.43it/s]Epoch 2 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.41it/s]Epoch 2 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.44it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.47it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.48it/s]Epoch 2 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.51it/s]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.55it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.19it/s]Epoch 2 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.31it/s]Epoch 2 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.36it/s]Epoch 2 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.43it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.48it/s]Epoch 2 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.47it/s]Epoch 2 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.44it/s]Epoch 2 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.46it/s]Epoch 2 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.46it/s]Epoch 2 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.47it/s]Epoch 2 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.46it/s]Epoch 2 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.43it/s][2025-05-30 15:28:18,695][__main__][INFO] - Train Epoch: 2 [100/101 (99%)]	Loss: 1.047143
                                                                  Epoch 2 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 2 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.13it/s]Epoch 2 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.18it/s]Epoch 2 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.90it/s]Epoch 2 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.00it/s]Epoch 2 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.18it/s]Epoch 2 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.29it/s]Epoch 2 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.33it/s]Epoch 2 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.41it/s]Epoch 2 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.44it/s]Epoch 2 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.49it/s]Epoch 2 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.52it/s]Epoch 2 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.51it/s]                                                              [2025-05-30 15:28:20,173][__main__][INFO] - Epoch 2: Val Loss: 1.2162, Accuracy: 0.2871, Metrics: {'accuracy': 0.2871287128712871, 'f1_macro': 0.2487762237762238, 'f1_weighted': 0.3096517344042097, 'precision_macro': 0.287748171368861, 'recall_macro': 0.31604391371340523}
Epoch 3 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:20,238][__main__][INFO] - Train Epoch: 3 [0/101 (0%)]	Loss: 1.276374
Epoch 3 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.75it/s]Epoch 3 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.96it/s]Epoch 3 [Train]:   6%|‚ñå         | 6/101 [00:00<00:05, 15.92it/s]Epoch 3 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.99it/s]Epoch 3 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.96it/s]Epoch 3 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.92it/s]Epoch 3 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.96it/s]Epoch 3 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.97it/s]Epoch 3 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.94it/s]Epoch 3 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.89it/s]Epoch 3 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 15.89it/s]Epoch 3 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.92it/s]Epoch 3 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.95it/s]Epoch 3 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.98it/s]Epoch 3 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.94it/s]Epoch 3 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.89it/s]Epoch 3 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.91it/s]Epoch 3 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.91it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:03, 15.88it/s]Epoch 3 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.82it/s]Epoch 3 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.71it/s]Epoch 3 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.68it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.63it/s]Epoch 3 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.56it/s]Epoch 3 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.52it/s]Epoch 3 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.46it/s]Epoch 3 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.45it/s]Epoch 3 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.41it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.39it/s]Epoch 3 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.43it/s]Epoch 3 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 15.46it/s]Epoch 3 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.50it/s]Epoch 3 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.50it/s]Epoch 3 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.49it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.46it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.48it/s]Epoch 3 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.43it/s]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.40it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 15.46it/s]Epoch 3 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.49it/s]Epoch 3 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.47it/s]Epoch 3 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.42it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.45it/s]Epoch 3 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.40it/s]Epoch 3 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.39it/s]Epoch 3 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.37it/s]Epoch 3 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.40it/s]Epoch 3 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.38it/s]Epoch 3 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.38it/s]Epoch 3 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.35it/s][2025-05-30 15:28:26,649][__main__][INFO] - Train Epoch: 3 [100/101 (99%)]	Loss: 0.387153
                                                                  Epoch 3 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 3 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.04it/s]Epoch 3 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.12it/s]Epoch 3 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.01it/s]Epoch 3 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.01it/s]Epoch 3 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.19it/s]Epoch 3 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.32it/s]Epoch 3 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.34it/s]Epoch 3 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.39it/s]Epoch 3 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.41it/s]Epoch 3 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.39it/s]Epoch 3 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.47it/s]Epoch 3 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.45it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:28:28,129][__main__][INFO] - Epoch 3: Val Loss: 1.1252, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:28,202][__main__][INFO] - Train Epoch: 4 [0/101 (0%)]	Loss: 0.851065
Epoch 4 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.18it/s]Epoch 4 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.40it/s]Epoch 4 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.50it/s]Epoch 4 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.45it/s]Epoch 4 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.54it/s]Epoch 4 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.62it/s]Epoch 4 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.60it/s]Epoch 4 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.55it/s]Epoch 4 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.47it/s]Epoch 4 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.38it/s]Epoch 4 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.36it/s]Epoch 4 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.25it/s]Epoch 4 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.33it/s]Epoch 4 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.35it/s]Epoch 4 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.35it/s]Epoch 4 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.34it/s]Epoch 4 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 14.78it/s]Epoch 4 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 14.99it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.11it/s]Epoch 4 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:04, 15.17it/s]Epoch 4 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.24it/s]Epoch 4 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.30it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:03<00:03, 15.36it/s]Epoch 4 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.35it/s]Epoch 4 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.20it/s]Epoch 4 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.27it/s]Epoch 4 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.36it/s]Epoch 4 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.35it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.42it/s]Epoch 4 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.41it/s]Epoch 4 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.45it/s]Epoch 4 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.45it/s]Epoch 4 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.49it/s]Epoch 4 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.50it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:01, 15.50it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.47it/s]Epoch 4 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.46it/s]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.48it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.45it/s]Epoch 4 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.38it/s]Epoch 4 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.41it/s]Epoch 4 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.44it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.10it/s]Epoch 4 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.22it/s]Epoch 4 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.33it/s]Epoch 4 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.31it/s]Epoch 4 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.33it/s]Epoch 4 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.30it/s]Epoch 4 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.16it/s]Epoch 4 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.21it/s][2025-05-30 15:28:34,709][__main__][INFO] - Train Epoch: 4 [100/101 (99%)]	Loss: 1.833618
                                                                  Epoch 4 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 4 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.99it/s]Epoch 4 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.92it/s]Epoch 4 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.90it/s]Epoch 4 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.94it/s]Epoch 4 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.13it/s]Epoch 4 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.23it/s]Epoch 4 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.27it/s]Epoch 4 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.35it/s]Epoch 4 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.35it/s]Epoch 4 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.37it/s]Epoch 4 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.41it/s]Epoch 4 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.38it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:28:36,195][__main__][INFO] - Epoch 4: Val Loss: 0.9244, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2974654377880184, 'f1_weighted': 0.49139024501528494, 'precision_macro': 0.40364583333333337, 'recall_macro': 0.3181818181818182}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38125aa800>
<numpy.flatiter object at 0x7f38125aa800>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703175560>
<numpy.flatiter object at 0x7f3703175560>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703175560>
<numpy.flatiter object at 0x7f3703175560>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703175b60>
<numpy.flatiter object at 0x7f3703175b60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703175b60>
<numpy.flatiter object at 0x7f3703175b60>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:28:36,260][__main__][INFO] - Saved best model at epoch 4 with accuracy: 0.6139
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:28:36,360][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 5 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:36,457][__main__][INFO] - Train Epoch: 5 [0/101 (0%)]	Loss: 0.977702
Epoch 5 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.15it/s]Epoch 5 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.32it/s]Epoch 5 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.34it/s]Epoch 5 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.40it/s]Epoch 5 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.36it/s]Epoch 5 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.37it/s]Epoch 5 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.39it/s]Epoch 5 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.39it/s]Epoch 5 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.45it/s]Epoch 5 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.44it/s]Epoch 5 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.43it/s]Epoch 5 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.40it/s]Epoch 5 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.43it/s]Epoch 5 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.40it/s]Epoch 5 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.41it/s]Epoch 5 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.42it/s]Epoch 5 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.42it/s]Epoch 5 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.41it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.35it/s]Epoch 5 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.35it/s]Epoch 5 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.40it/s]Epoch 5 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.38it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.29it/s]Epoch 5 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.32it/s]Epoch 5 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.32it/s]Epoch 5 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.35it/s]Epoch 5 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.34it/s]Epoch 5 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.33it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.33it/s]Epoch 5 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.29it/s]Epoch 5 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.32it/s]Epoch 5 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.34it/s]Epoch 5 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.36it/s]Epoch 5 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.35it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.39it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.41it/s]Epoch 5 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.43it/s]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.45it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.43it/s]Epoch 5 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.43it/s]Epoch 5 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.45it/s]Epoch 5 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.45it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.48it/s]Epoch 5 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.49it/s]Epoch 5 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.45it/s]Epoch 5 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.37it/s]Epoch 5 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.41it/s]Epoch 5 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.41it/s]Epoch 5 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.41it/s]Epoch 5 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.44it/s][2025-05-30 15:28:42,945][__main__][INFO] - Train Epoch: 5 [100/101 (99%)]	Loss: 0.265550
                                                                  Epoch 5 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 5 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.15it/s]Epoch 5 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.05it/s]Epoch 5 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.92it/s]Epoch 5 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.01it/s]Epoch 5 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.11it/s]Epoch 5 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.16it/s]Epoch 5 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.21it/s]Epoch 5 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.34it/s]Epoch 5 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.35it/s]Epoch 5 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.38it/s]Epoch 5 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.44it/s]Epoch 5 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.42it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:28:44,429][__main__][INFO] - Epoch 5: Val Loss: 0.9183, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.35794183445190153, 'f1_weighted': 0.5195472567390967, 'precision_macro': 0.3333333333333333, 'recall_macro': 0.40061633281972264}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37491ecec0>
<numpy.flatiter object at 0x7f37491ecec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37035f69e0>
<numpy.flatiter object at 0x7f37035f69e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035f69e0>
<numpy.flatiter object at 0x7f37035f69e0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3810138d70>
<numpy.flatiter object at 0x7f3810138d70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3810138d70>
<numpy.flatiter object at 0x7f3810138d70>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:28:44,497][__main__][INFO] - Saved best model at epoch 5 with accuracy: 0.6337
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:28:44,600][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 6 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:44,697][__main__][INFO] - Train Epoch: 6 [0/101 (0%)]	Loss: 0.951920
Epoch 6 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.62it/s]Epoch 6 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.58it/s]Epoch 6 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.47it/s]Epoch 6 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.48it/s]Epoch 6 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.62it/s]Epoch 6 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.63it/s]Epoch 6 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.61it/s]Epoch 6 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.52it/s]Epoch 6 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.49it/s]Epoch 6 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.29it/s]Epoch 6 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.36it/s]Epoch 6 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.37it/s]Epoch 6 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.32it/s]Epoch 6 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.35it/s]Epoch 6 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.36it/s]Epoch 6 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.34it/s]Epoch 6 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.29it/s]Epoch 6 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.36it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.18it/s]Epoch 6 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:04, 15.24it/s]Epoch 6 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.28it/s]Epoch 6 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.34it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.42it/s]Epoch 6 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.42it/s]Epoch 6 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.46it/s]Epoch 6 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.42it/s]Epoch 6 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.40it/s]Epoch 6 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.38it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.40it/s]Epoch 6 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.39it/s]Epoch 6 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.42it/s]Epoch 6 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.40it/s]Epoch 6 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.38it/s]Epoch 6 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.41it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.43it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.38it/s]Epoch 6 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.37it/s]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.39it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.35it/s]Epoch 6 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.36it/s]Epoch 6 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.33it/s]Epoch 6 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.36it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.36it/s]Epoch 6 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.26it/s]Epoch 6 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.33it/s]Epoch 6 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.33it/s]Epoch 6 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.36it/s]Epoch 6 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.34it/s]Epoch 6 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 14.88it/s]Epoch 6 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.08it/s][2025-05-30 15:28:51,200][__main__][INFO] - Train Epoch: 6 [100/101 (99%)]	Loss: 1.779819
                                                                  Epoch 6 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 6 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.75it/s]Epoch 6 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.16it/s]Epoch 6 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.47it/s]Epoch 6 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.66it/s]Epoch 6 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 16.77it/s]Epoch 6 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 16.90it/s]Epoch 6 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.03it/s]Epoch 6 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.13it/s]Epoch 6 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.14it/s]Epoch 6 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.15it/s]Epoch 6 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.21it/s]Epoch 6 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.25it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:28:52,708][__main__][INFO] - Epoch 6: Val Loss: 1.3253, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.35740365111561867, 'f1_weighted': 0.5289337858735164, 'precision_macro': 0.3989018087855297, 'recall_macro': 0.363424499229584}
Epoch 7 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:28:52,781][__main__][INFO] - Train Epoch: 7 [0/101 (0%)]	Loss: 2.021734
Epoch 7 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.31it/s]Epoch 7 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.64it/s]Epoch 7 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.64it/s]Epoch 7 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.67it/s]Epoch 7 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.75it/s]Epoch 7 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.74it/s]Epoch 7 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.75it/s]Epoch 7 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.48it/s]Epoch 7 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.45it/s]Epoch 7 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.52it/s]Epoch 7 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.55it/s]Epoch 7 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.52it/s]Epoch 7 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.49it/s]Epoch 7 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.46it/s]Epoch 7 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.42it/s]Epoch 7 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.37it/s]Epoch 7 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.38it/s]Epoch 7 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.38it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.34it/s]Epoch 7 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.33it/s]Epoch 7 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.37it/s]Epoch 7 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.30it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.30it/s]Epoch 7 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.33it/s]Epoch 7 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 14.91it/s]Epoch 7 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 14.89it/s]Epoch 7 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 14.98it/s]Epoch 7 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.09it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.17it/s]Epoch 7 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.28it/s]Epoch 7 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.37it/s]Epoch 7 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.41it/s]Epoch 7 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.43it/s]Epoch 7 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.43it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.36it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.36it/s]Epoch 7 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.38it/s]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.26it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.32it/s]Epoch 7 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.36it/s]Epoch 7 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.38it/s]Epoch 7 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.38it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.39it/s]Epoch 7 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.42it/s]Epoch 7 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.46it/s]Epoch 7 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.45it/s]Epoch 7 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.39it/s]Epoch 7 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.42it/s]Epoch 7 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.44it/s]Epoch 7 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.45it/s][2025-05-30 15:28:59,268][__main__][INFO] - Train Epoch: 7 [100/101 (99%)]	Loss: 0.438704
                                                                  Epoch 7 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 7 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.07it/s]Epoch 7 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.04it/s]Epoch 7 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.98it/s]Epoch 7 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.02it/s]Epoch 7 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.09it/s]Epoch 7 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.20it/s]Epoch 7 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.24it/s]Epoch 7 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.29it/s]Epoch 7 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.35it/s]Epoch 7 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.36it/s]Epoch 7 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.41it/s]Epoch 7 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.40it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:00,755][__main__][INFO] - Epoch 7: Val Loss: 1.0822, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.33859194725688724, 'f1_weighted': 0.5152151664424743, 'precision_macro': 0.28237179487179487, 'recall_macro': 0.4291217257318952}
Epoch 8 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:00,821][__main__][INFO] - Train Epoch: 8 [0/101 (0%)]	Loss: 1.049042
Epoch 8 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.66it/s]Epoch 8 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.69it/s]Epoch 8 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.74it/s]Epoch 8 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.80it/s]Epoch 8 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.83it/s]Epoch 8 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.84it/s]Epoch 8 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.84it/s]Epoch 8 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.87it/s]Epoch 8 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.87it/s]Epoch 8 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.84it/s]Epoch 8 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:04, 15.87it/s]Epoch 8 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.89it/s]Epoch 8 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.93it/s]Epoch 8 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.90it/s]Epoch 8 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.77it/s]Epoch 8 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.70it/s]Epoch 8 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.66it/s]Epoch 8 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.69it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.69it/s]Epoch 8 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.74it/s]Epoch 8 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.75it/s]Epoch 8 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.74it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.72it/s]Epoch 8 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.71it/s]Epoch 8 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.62it/s]Epoch 8 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.58it/s]Epoch 8 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.52it/s]Epoch 8 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.47it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.49it/s]Epoch 8 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.47it/s]Epoch 8 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:03<00:02, 15.50it/s]Epoch 8 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.52it/s]Epoch 8 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.49it/s]Epoch 8 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.45it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.45it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.41it/s]Epoch 8 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.40it/s]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.39it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:04<00:01, 15.42it/s]Epoch 8 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.46it/s]Epoch 8 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.34it/s]Epoch 8 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.37it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.38it/s]Epoch 8 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.43it/s]Epoch 8 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.44it/s]Epoch 8 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.37it/s]Epoch 8 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.40it/s]Epoch 8 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.41it/s]Epoch 8 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.42it/s]Epoch 8 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.43it/s][2025-05-30 15:29:07,227][__main__][INFO] - Train Epoch: 8 [100/101 (99%)]	Loss: 1.735377
                                                                  Epoch 8 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 8 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.04it/s]Epoch 8 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.12it/s]Epoch 8 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 17.02it/s]Epoch 8 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.02it/s]Epoch 8 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.17it/s]Epoch 8 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.29it/s]Epoch 8 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.34it/s]Epoch 8 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.33it/s]Epoch 8 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.33it/s]Epoch 8 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.39it/s]Epoch 8 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.41it/s]Epoch 8 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.38it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:08,711][__main__][INFO] - Epoch 8: Val Loss: 0.9496, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18670886075949367, 'f1_weighted': 0.43627020929941096, 'precision_macro': 0.14898989898989898, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:08,784][__main__][INFO] - Train Epoch: 9 [0/101 (0%)]	Loss: 1.715028
Epoch 9 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.07it/s]Epoch 9 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.36it/s]Epoch 9 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.46it/s]Epoch 9 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.48it/s]Epoch 9 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.39it/s]Epoch 9 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.24it/s]Epoch 9 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.35it/s]Epoch 9 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.36it/s]Epoch 9 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.37it/s]Epoch 9 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.40it/s]Epoch 9 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.40it/s]Epoch 9 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.38it/s]Epoch 9 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.42it/s]Epoch 9 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.46it/s]Epoch 9 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.42it/s]Epoch 9 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.43it/s]Epoch 9 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.39it/s]Epoch 9 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.38it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.39it/s]Epoch 9 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.41it/s]Epoch 9 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.39it/s]Epoch 9 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.35it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.36it/s]Epoch 9 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.35it/s]Epoch 9 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.36it/s]Epoch 9 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.42it/s]Epoch 9 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.43it/s]Epoch 9 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.47it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.47it/s]Epoch 9 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.47it/s]Epoch 9 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.46it/s]Epoch 9 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.39it/s]Epoch 9 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.42it/s]Epoch 9 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.43it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.37it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.37it/s]Epoch 9 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.38it/s]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.38it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.40it/s]Epoch 9 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.36it/s]Epoch 9 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.39it/s]Epoch 9 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.33it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.31it/s]Epoch 9 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.28it/s]Epoch 9 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.31it/s]Epoch 9 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.33it/s]Epoch 9 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.32it/s]Epoch 9 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.33it/s]Epoch 9 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.35it/s]Epoch 9 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.38it/s][2025-05-30 15:29:15,273][__main__][INFO] - Train Epoch: 9 [100/101 (99%)]	Loss: 0.255232
                                                                  Epoch 9 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 9 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.85it/s]Epoch 9 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.90it/s]Epoch 9 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.82it/s]Epoch 9 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.78it/s]Epoch 9 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 16.71it/s]Epoch 9 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 16.78it/s]Epoch 9 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 16.88it/s]Epoch 9 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 16.96it/s]Epoch 9 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.11it/s]Epoch 9 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.21it/s]Epoch 9 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.25it/s]Epoch 9 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.29it/s]                                                              /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:16,776][__main__][INFO] - Epoch 9: Val Loss: 1.0361, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.24679802955665023, 'f1_weighted': 0.48841632931766077, 'precision_macro': 0.22655038759689922, 'recall_macro': 0.2830508474576271}
Epoch 10 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:16,851][__main__][INFO] - Train Epoch: 10 [0/101 (0%)]	Loss: 0.550819
Epoch 10 [Train]:   2%|‚ñè         | 2/101 [00:00<00:07, 13.83it/s]Epoch 10 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 14.63it/s]Epoch 10 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.03it/s]Epoch 10 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.19it/s]Epoch 10 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.27it/s]Epoch 10 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.29it/s]Epoch 10 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.36it/s]Epoch 10 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.33it/s]Epoch 10 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.29it/s]Epoch 10 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.30it/s]Epoch 10 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.36it/s]Epoch 10 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.39it/s]Epoch 10 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.40it/s]Epoch 10 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.39it/s]Epoch 10 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.19it/s]Epoch 10 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.20it/s]Epoch 10 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.30it/s]Epoch 10 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.33it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.35it/s]Epoch 10 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.37it/s]Epoch 10 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.39it/s]Epoch 10 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.43it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:03<00:03, 15.42it/s]Epoch 10 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.42it/s]Epoch 10 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.12it/s]Epoch 10 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.22it/s]Epoch 10 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.21it/s]Epoch 10 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.25it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.31it/s]Epoch 10 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.35it/s]Epoch 10 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.36it/s]Epoch 10 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.33it/s]Epoch 10 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.22it/s]Epoch 10 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 14.98it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.13it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.18it/s]Epoch 10 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.27it/s]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.31it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.30it/s]Epoch 10 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.28it/s]Epoch 10 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.30it/s]Epoch 10 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.33it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.33it/s]Epoch 10 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.35it/s]Epoch 10 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.34it/s]Epoch 10 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:06<00:00, 15.36it/s]Epoch 10 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.36it/s]Epoch 10 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.39it/s]Epoch 10 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.36it/s]Epoch 10 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.32it/s][2025-05-30 15:29:23,376][__main__][INFO] - Train Epoch: 10 [100/101 (99%)]	Loss: 1.089173
                                                                   Epoch 10 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 10 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.21it/s]Epoch 10 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.65it/s]Epoch 10 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.66it/s]Epoch 10 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.72it/s]Epoch 10 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 16.96it/s]Epoch 10 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.10it/s]Epoch 10 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.11it/s]Epoch 10 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.10it/s]Epoch 10 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.21it/s]Epoch 10 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.24it/s]Epoch 10 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.28it/s]Epoch 10 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.28it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:24,875][__main__][INFO] - Epoch 10: Val Loss: 1.0086, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 11 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:24,943][__main__][INFO] - Train Epoch: 11 [0/101 (0%)]	Loss: 0.543626
Epoch 11 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.42it/s]Epoch 11 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.52it/s]Epoch 11 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.54it/s]Epoch 11 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.52it/s]Epoch 11 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.54it/s]Epoch 11 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.56it/s]Epoch 11 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.54it/s]Epoch 11 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.57it/s]Epoch 11 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.46it/s]Epoch 11 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.42it/s]Epoch 11 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.41it/s]Epoch 11 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.44it/s]Epoch 11 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.44it/s]Epoch 11 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.44it/s]Epoch 11 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.43it/s]Epoch 11 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.43it/s]Epoch 11 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.39it/s]Epoch 11 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.33it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.24it/s]Epoch 11 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.28it/s]Epoch 11 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.32it/s]Epoch 11 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.08it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.13it/s]Epoch 11 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.20it/s]Epoch 11 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.24it/s]Epoch 11 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.31it/s]Epoch 11 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.36it/s]Epoch 11 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.36it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.41it/s]Epoch 11 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.45it/s]Epoch 11 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.40it/s]Epoch 11 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.39it/s]Epoch 11 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.33it/s]Epoch 11 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.33it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.34it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.36it/s]Epoch 11 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.39it/s]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.39it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.39it/s]Epoch 11 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.39it/s]Epoch 11 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.42it/s]Epoch 11 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.44it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.45it/s]Epoch 11 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.45it/s]Epoch 11 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.41it/s]Epoch 11 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.42it/s]Epoch 11 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.41it/s]Epoch 11 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.38it/s]Epoch 11 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.08it/s]Epoch 11 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.16it/s][2025-05-30 15:29:31,443][__main__][INFO] - Train Epoch: 11 [100/101 (99%)]	Loss: 0.667723
                                                                   Epoch 11 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 11 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.88it/s]Epoch 11 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.91it/s]Epoch 11 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.87it/s]Epoch 11 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.96it/s]Epoch 11 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.09it/s]Epoch 11 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.15it/s]Epoch 11 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.23it/s]Epoch 11 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.27it/s]Epoch 11 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.24it/s]Epoch 11 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.27it/s]Epoch 11 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.33it/s]Epoch 11 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.31it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:32,935][__main__][INFO] - Epoch 11: Val Loss: 1.0242, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:33,001][__main__][INFO] - Train Epoch: 12 [0/101 (0%)]	Loss: 1.239944
Epoch 12 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.32it/s]Epoch 12 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.22it/s]Epoch 12 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.41it/s]Epoch 12 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.43it/s]Epoch 12 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.47it/s]Epoch 12 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.51it/s]Epoch 12 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.47it/s]Epoch 12 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.50it/s]Epoch 12 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.46it/s]Epoch 12 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.09it/s]Epoch 12 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.21it/s]Epoch 12 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.27it/s]Epoch 12 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.24it/s]Epoch 12 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.25it/s]Epoch 12 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.25it/s]Epoch 12 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.32it/s]Epoch 12 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.37it/s]Epoch 12 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.37it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.14it/s]Epoch 12 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:04, 15.23it/s]Epoch 12 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.32it/s]Epoch 12 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.34it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.40it/s]Epoch 12 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.43it/s]Epoch 12 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.44it/s]Epoch 12 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.39it/s]Epoch 12 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.41it/s]Epoch 12 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.45it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.42it/s]Epoch 12 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.35it/s]Epoch 12 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.36it/s]Epoch 12 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.32it/s]Epoch 12 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.31it/s]Epoch 12 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.30it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.28it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.26it/s]Epoch 12 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.24it/s]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.28it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.29it/s]Epoch 12 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.23it/s]Epoch 12 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.24it/s]Epoch 12 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.24it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.28it/s]Epoch 12 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.28it/s]Epoch 12 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.32it/s]Epoch 12 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:06<00:00, 15.34it/s]Epoch 12 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.34it/s]Epoch 12 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.31it/s]Epoch 12 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.30it/s]Epoch 12 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.34it/s][2025-05-30 15:29:39,518][__main__][INFO] - Train Epoch: 12 [100/101 (99%)]	Loss: 0.973950
                                                                   Epoch 12 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 12 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 17.12it/s]Epoch 12 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 17.03it/s]Epoch 12 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.93it/s]Epoch 12 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.00it/s]Epoch 12 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.06it/s]Epoch 12 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.17it/s]Epoch 12 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.23it/s]Epoch 12 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.29it/s]Epoch 12 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.31it/s]Epoch 12 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.29it/s]Epoch 12 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.35it/s]Epoch 12 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.37it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:41,007][__main__][INFO] - Epoch 12: Val Loss: 1.3554, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 13 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:41,074][__main__][INFO] - Train Epoch: 13 [0/101 (0%)]	Loss: 0.916641
Epoch 13 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.75it/s]Epoch 13 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.79it/s]Epoch 13 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.80it/s]Epoch 13 [Train]:   8%|‚ñä         | 8/101 [00:00<00:05, 15.82it/s]Epoch 13 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.77it/s]Epoch 13 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.77it/s]Epoch 13 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.74it/s]Epoch 13 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.61it/s]Epoch 13 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.63it/s]Epoch 13 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.59it/s]Epoch 13 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.54it/s]Epoch 13 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:04, 15.51it/s]Epoch 13 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.49it/s]Epoch 13 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.48it/s]Epoch 13 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.43it/s]Epoch 13 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.41it/s]Epoch 13 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.37it/s]Epoch 13 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.37it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.36it/s]Epoch 13 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.29it/s]Epoch 13 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.29it/s]Epoch 13 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.34it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.29it/s]Epoch 13 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.32it/s]Epoch 13 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.32it/s]Epoch 13 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.32it/s]Epoch 13 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.34it/s]Epoch 13 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.32it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.34it/s]Epoch 13 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.35it/s]Epoch 13 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.37it/s]Epoch 13 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.35it/s]Epoch 13 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.35it/s]Epoch 13 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.36it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.36it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.37it/s]Epoch 13 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.40it/s]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.37it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.37it/s]Epoch 13 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.38it/s]Epoch 13 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.39it/s]Epoch 13 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.37it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.36it/s]Epoch 13 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.38it/s]Epoch 13 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.37it/s]Epoch 13 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.39it/s]Epoch 13 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.40it/s]Epoch 13 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.34it/s]Epoch 13 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.34it/s]Epoch 13 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.37it/s][2025-05-30 15:29:47,549][__main__][INFO] - Train Epoch: 13 [100/101 (99%)]	Loss: 1.185905
                                                                   Epoch 13 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 13 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.86it/s]Epoch 13 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.98it/s]Epoch 13 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.80it/s]Epoch 13 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 17.00it/s]Epoch 13 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.13it/s]Epoch 13 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.21it/s]Epoch 13 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.27it/s]Epoch 13 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.30it/s]Epoch 13 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.32it/s]Epoch 13 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.33it/s]Epoch 13 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.36it/s]Epoch 13 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.41it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:49,037][__main__][INFO] - Epoch 13: Val Loss: 0.9507, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.2636319376825706, 'f1_weighted': 0.4697812527114445, 'precision_macro': 0.398989898989899, 'recall_macro': 0.29545454545454547}
Epoch 14 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:49,104][__main__][INFO] - Train Epoch: 14 [0/101 (0%)]	Loss: 0.805067
Epoch 14 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 14.87it/s]Epoch 14 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.22it/s]Epoch 14 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.30it/s]Epoch 14 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.35it/s]Epoch 14 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.44it/s]Epoch 14 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.47it/s]Epoch 14 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.39it/s]Epoch 14 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.40it/s]Epoch 14 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.42it/s]Epoch 14 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.37it/s]Epoch 14 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.38it/s]Epoch 14 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.35it/s]Epoch 14 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.38it/s]Epoch 14 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.43it/s]Epoch 14 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.44it/s]Epoch 14 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.43it/s]Epoch 14 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.44it/s]Epoch 14 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.39it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.39it/s]Epoch 14 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.42it/s]Epoch 14 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.35it/s]Epoch 14 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.41it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.40it/s]Epoch 14 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.42it/s]Epoch 14 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.42it/s]Epoch 14 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.40it/s]Epoch 14 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.38it/s]Epoch 14 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.38it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.37it/s]Epoch 14 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.38it/s]Epoch 14 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.35it/s]Epoch 14 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.38it/s]Epoch 14 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.37it/s]Epoch 14 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.41it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.38it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.31it/s]Epoch 14 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.31it/s]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.29it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.31it/s]Epoch 14 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.29it/s]Epoch 14 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.33it/s]Epoch 14 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.25it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.32it/s]Epoch 14 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.35it/s]Epoch 14 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.38it/s]Epoch 14 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.39it/s]Epoch 14 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.38it/s]Epoch 14 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.36it/s]Epoch 14 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.34it/s]Epoch 14 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.40it/s][2025-05-30 15:29:55,599][__main__][INFO] - Train Epoch: 14 [100/101 (99%)]	Loss: 1.785928
                                                                   Epoch 14 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 14 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.67it/s]Epoch 14 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.97it/s]Epoch 14 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.92it/s]Epoch 14 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.92it/s]Epoch 14 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 17.02it/s]Epoch 14 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.19it/s]Epoch 14 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.21it/s]Epoch 14 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.27it/s]Epoch 14 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.31it/s]Epoch 14 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.36it/s]Epoch 14 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.36it/s]Epoch 14 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.40it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:29:57,089][__main__][INFO] - Epoch 14: Val Loss: 1.2045, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2950409463148317, 'f1_weighted': 0.48572509662249214, 'precision_macro': 0.4005102040816326, 'recall_macro': 0.3181818181818182}
Epoch 15 [Train]:   0%|          | 0/101 [00:00<?, ?it/s][2025-05-30 15:29:57,155][__main__][INFO] - Train Epoch: 15 [0/101 (0%)]	Loss: 1.078428
Epoch 15 [Train]:   2%|‚ñè         | 2/101 [00:00<00:06, 15.65it/s]Epoch 15 [Train]:   4%|‚ñç         | 4/101 [00:00<00:06, 15.50it/s]Epoch 15 [Train]:   6%|‚ñå         | 6/101 [00:00<00:06, 15.48it/s]Epoch 15 [Train]:   8%|‚ñä         | 8/101 [00:00<00:06, 15.46it/s]Epoch 15 [Train]:  10%|‚ñâ         | 10/101 [00:00<00:05, 15.52it/s]Epoch 15 [Train]:  12%|‚ñà‚ñè        | 12/101 [00:00<00:05, 15.27it/s]Epoch 15 [Train]:  14%|‚ñà‚ñç        | 14/101 [00:00<00:05, 15.35it/s]Epoch 15 [Train]:  16%|‚ñà‚ñå        | 16/101 [00:01<00:05, 15.30it/s]Epoch 15 [Train]:  18%|‚ñà‚ñä        | 18/101 [00:01<00:05, 15.36it/s]Epoch 15 [Train]:  20%|‚ñà‚ñâ        | 20/101 [00:01<00:05, 15.35it/s]Epoch 15 [Train]:  22%|‚ñà‚ñà‚ñè       | 22/101 [00:01<00:05, 15.31it/s]Epoch 15 [Train]:  24%|‚ñà‚ñà‚ñç       | 24/101 [00:01<00:05, 15.18it/s]Epoch 15 [Train]:  26%|‚ñà‚ñà‚ñå       | 26/101 [00:01<00:04, 15.20it/s]Epoch 15 [Train]:  28%|‚ñà‚ñà‚ñä       | 28/101 [00:01<00:04, 15.24it/s]Epoch 15 [Train]:  30%|‚ñà‚ñà‚ñâ       | 30/101 [00:01<00:04, 15.28it/s]Epoch 15 [Train]:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/101 [00:02<00:04, 15.34it/s]Epoch 15 [Train]:  34%|‚ñà‚ñà‚ñà‚ñé      | 34/101 [00:02<00:04, 15.35it/s]Epoch 15 [Train]:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/101 [00:02<00:04, 15.35it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/101 [00:02<00:04, 15.40it/s]Epoch 15 [Train]:  40%|‚ñà‚ñà‚ñà‚ñâ      | 40/101 [00:02<00:03, 15.43it/s]Epoch 15 [Train]:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/101 [00:02<00:03, 15.44it/s]Epoch 15 [Train]:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/101 [00:02<00:03, 15.40it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/101 [00:02<00:03, 15.42it/s]Epoch 15 [Train]:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/101 [00:03<00:03, 15.42it/s]Epoch 15 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 50/101 [00:03<00:03, 15.36it/s]Epoch 15 [Train]:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/101 [00:03<00:03, 15.34it/s]Epoch 15 [Train]:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 54/101 [00:03<00:03, 15.30it/s]Epoch 15 [Train]:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/101 [00:03<00:02, 15.33it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/101 [00:03<00:02, 15.35it/s]Epoch 15 [Train]:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 60/101 [00:03<00:02, 15.04it/s]Epoch 15 [Train]:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/101 [00:04<00:02, 15.12it/s]Epoch 15 [Train]:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 64/101 [00:04<00:02, 15.17it/s]Epoch 15 [Train]:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/101 [00:04<00:02, 15.22it/s]Epoch 15 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 68/101 [00:04<00:02, 15.26it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 70/101 [00:04<00:02, 15.31it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/101 [00:04<00:01, 15.35it/s]Epoch 15 [Train]:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 74/101 [00:04<00:01, 15.43it/s]Epoch 15 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/101 [00:04<00:01, 15.41it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 78/101 [00:05<00:01, 15.44it/s]Epoch 15 [Train]:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 80/101 [00:05<00:01, 15.41it/s]Epoch 15 [Train]:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 82/101 [00:05<00:01, 15.42it/s]Epoch 15 [Train]:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 84/101 [00:05<00:01, 15.46it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/101 [00:05<00:00, 15.40it/s]Epoch 15 [Train]:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 88/101 [00:05<00:00, 15.44it/s]Epoch 15 [Train]:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 90/101 [00:05<00:00, 15.42it/s]Epoch 15 [Train]:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 92/101 [00:05<00:00, 15.43it/s]Epoch 15 [Train]:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 94/101 [00:06<00:00, 15.45it/s]Epoch 15 [Train]:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/101 [00:06<00:00, 15.32it/s]Epoch 15 [Train]:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 98/101 [00:06<00:00, 15.35it/s]Epoch 15 [Train]:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 100/101 [00:06<00:00, 15.35it/s][2025-05-30 15:30:03,662][__main__][INFO] - Train Epoch: 15 [100/101 (99%)]	Loss: 1.733038
                                                                   Epoch 15 [Val]:   0%|          | 0/26 [00:00<?, ?it/s]Epoch 15 [Val]:   8%|‚ñä         | 2/26 [00:00<00:01, 16.38it/s]Epoch 15 [Val]:  15%|‚ñà‚ñå        | 4/26 [00:00<00:01, 16.74it/s]Epoch 15 [Val]:  23%|‚ñà‚ñà‚ñé       | 6/26 [00:00<00:01, 16.74it/s]Epoch 15 [Val]:  31%|‚ñà‚ñà‚ñà       | 8/26 [00:00<00:01, 16.79it/s]Epoch 15 [Val]:  38%|‚ñà‚ñà‚ñà‚ñä      | 10/26 [00:00<00:00, 16.91it/s]Epoch 15 [Val]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 12/26 [00:00<00:00, 17.09it/s]Epoch 15 [Val]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 14/26 [00:00<00:00, 17.10it/s]Epoch 15 [Val]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 16/26 [00:00<00:00, 17.19it/s]Epoch 15 [Val]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 18/26 [00:01<00:00, 17.22it/s]Epoch 15 [Val]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20/26 [00:01<00:00, 17.23it/s]Epoch 15 [Val]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 22/26 [00:01<00:00, 17.26it/s]Epoch 15 [Val]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 24/26 [00:01<00:00, 17.22it/s]                                                               /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:05,165][__main__][INFO] - Epoch 15: Val Loss: 1.1518, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
[2025-05-30 15:30:05,166][__main__][INFO] - Early stopping triggered after 15 epochs
[2025-05-30 15:30:05,167][__main__][INFO] - Saving best confusion matrix with accuracy: 0.6337
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37035fd6c0>
<numpy.flatiter object at 0x7f37035fd6c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63ef450>
<numpy.flatiter object at 0x7f36f63ef450>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63ef450>
<numpy.flatiter object at 0x7f36f63ef450>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63efa50>
<numpy.flatiter object at 0x7f36f63efa50>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63efa50>
<numpy.flatiter object at 0x7f36f63efa50>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÖ‚ñà
wandb:                 Train Loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÇ‚ñÑ‚ñá‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñÑ‚ñá
wandb:        Validation Accuracy ‚ñá‚ñá‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñà‚ñà‚ñá
wandb:            Validation Loss ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÜ‚ñÖ
wandb:        Validation accuracy ‚ñá‚ñá‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñà‚ñà‚ñá
wandb:        Validation f1_macro ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÑ
wandb:     Validation f1_weighted ‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñá‚ñá‚ñá
wandb: Validation precision_macro ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñà‚ñá‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñà‚ñÉ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÅ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.63366
wandb:                 Train Loss 1.73304
wandb:        Validation Accuracy 0.58416
wandb:            Validation Loss 1.15184
wandb:        Validation accuracy 0.58416
wandb:        Validation f1_macro 0.18438
wandb:     Validation f1_weighted 0.43082
wandb: Validation precision_macro 0.14604
wandb:    Validation recall_macro 0.25
wandb: 
wandb: üöÄ View run fiery-sweep-9 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/1p6fh40j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_152752-1p6fh40j/logs
wandb: Agent Starting Run: 6r0s40y2 with config:
wandb: 	Fdropout_rate: 0.3779843249706254
wandb: 	Fnum_heads: 1
wandb: 	Fnum_layers: 7
wandb: 	Mdropout_rate: 0.13808221167282925
wandb: 	Mnum_layers: 4
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.032073118512954336
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_153009-6r0s40y2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/6r0s40y2
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:15,379][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.547649
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.03it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:20,060][__main__][INFO] - Epoch 0: Val Loss: 34.4781, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703084850>
<numpy.flatiter object at 0x7f3703084850>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703084850>
<numpy.flatiter object at 0x7f3703084850>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703084850>
<numpy.flatiter object at 0x7f3703084850>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703084850>
<numpy.flatiter object at 0x7f3703084850>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703084850>
<numpy.flatiter object at 0x7f3703084850>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:30:20,124][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:30:20,223][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:30:20,255][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:20,945][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 32.400307
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:25,625][__main__][INFO] - Epoch 1: Val Loss: 33.0523, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:26,322][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 19.722389
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:31,017][__main__][INFO] - Epoch 2: Val Loss: 6.2429, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:31,713][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 6.088589
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:36,408][__main__][INFO] - Epoch 3: Val Loss: 4.8292, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:37,097][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 4.561600
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:41,800][__main__][INFO] - Epoch 4: Val Loss: 3.0496, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:42,500][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 2.031688
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:47,213][__main__][INFO] - Epoch 5: Val Loss: 2.9213, Accuracy: 0.5248, Metrics: {'accuracy': 0.5247524752475248, 'f1_macro': 0.19736842105263158, 'f1_weighted': 0.4111516414799375, 'precision_macro': 0.17103494623655913, 'recall_macro': 0.2430662557781202}
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:47,912][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 1.524749
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:52,639][__main__][INFO] - Epoch 6: Val Loss: 2.0907, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:53,339][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 0.862530
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:30:58,058][__main__][INFO] - Epoch 7: Val Loss: 2.2057, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:30:58,756][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 0.889308
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:03,489][__main__][INFO] - Epoch 8: Val Loss: 2.0578, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:04,186][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 0.695996
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:08,932][__main__][INFO] - Epoch 9: Val Loss: 2.1219, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:09,631][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 0.798374
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:14,381][__main__][INFO] - Epoch 10: Val Loss: 1.7386, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
[2025-05-30 15:31:14,383][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:15,089][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 0.852827
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.28it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.67it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:20,101][__main__][INFO] - Epoch 11: Val Loss: 3.4689, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:20,807][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 1.115892
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:25,566][__main__][INFO] - Epoch 12: Val Loss: 2.8062, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2679802955665025, 'f1_weighted': 0.51584646149344, 'precision_macro': 0.24903100775193798, 'recall_macro': 0.3040254237288136}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f38119fe200>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:31:25,629][__main__][INFO] - Saved best model at epoch 12 with accuracy: 0.6139
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:31:25,734][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:26,463][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 2.352073
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:31,211][__main__][INFO] - Epoch 13: Val Loss: 2.7764, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:31,922][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 1.130019
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.41it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:36,686][__main__][INFO] - Epoch 14: Val Loss: 1.7096, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:37,393][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 0.847246
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:42,149][__main__][INFO] - Epoch 15: Val Loss: 1.2678, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.23032258064516128, 'f1_weighted': 0.47639731715107, 'precision_macro': 0.25364583333333335, 'recall_macro': 0.275}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:42,856][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 0.828942
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:47,612][__main__][INFO] - Epoch 16: Val Loss: 1.2420, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.25788497217068646, 'f1_weighted': 0.5089733463142233, 'precision_macro': 0.2416958041958042, 'recall_macro': 0.2957627118644068}
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:48,312][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.796123
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:53,081][__main__][INFO] - Epoch 17: Val Loss: 1.3657, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.22979323308270677, 'f1_weighted': 0.4817799449117844, 'precision_macro': 0.2211021505376344, 'recall_macro': 0.275}
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:53,785][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.864101
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:31:58,543][__main__][INFO] - Epoch 18: Val Loss: 1.2510, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18789808917197454, 'f1_weighted': 0.43904900044144546, 'precision_macro': 0.15051020408163265, 'recall_macro': 0.25}
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:31:59,252][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.605986
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:04,014][__main__][INFO] - Epoch 19: Val Loss: 1.5270, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2113289760348584, 'f1_weighted': 0.4651955391617593, 'precision_macro': 0.19262917933130697, 'recall_macro': 0.2625}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:04,712][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.582842
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:09,477][__main__][INFO] - Epoch 20: Val Loss: 1.1949, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.2629725722757598, 'f1_weighted': 0.5128551402212126, 'precision_macro': 0.23811914323962516, 'recall_macro': 0.2997881355932204}
[2025-05-30 15:32:09,478][__main__][INFO] - Saved model at epoch 20
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:10,183][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 0.677314
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:14,947][__main__][INFO] - Epoch 21: Val Loss: 0.9637, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3879790385053543, 'f1_weighted': 0.5834685724211519, 'precision_macro': 0.4267199017199017, 'recall_macro': 0.4523690292758089}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119fe200>
<numpy.flatiter object at 0x7f38119fe200>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486a0010>
<numpy.flatiter object at 0x7f37486a0010>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:32:15,006][__main__][INFO] - Saved best model at epoch 21 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:32:15,106][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:15,834][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 1.388484
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:20,586][__main__][INFO] - Epoch 22: Val Loss: 1.4835, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.25788497217068646, 'f1_weighted': 0.5089733463142233, 'precision_macro': 0.2416958041958042, 'recall_macro': 0.2957627118644068}
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:21,293][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.696253
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.42it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:26,082][__main__][INFO] - Epoch 23: Val Loss: 1.2456, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2755046372067649, 'f1_weighted': 0.5249415285227377, 'precision_macro': 0.2496790757381258, 'recall_macro': 0.31228813559322033}
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:26,791][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.651787
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:31,562][__main__][INFO] - Epoch 24: Val Loss: 1.3564, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.2534722222222222, 'f1_weighted': 0.5064631463146314, 'precision_macro': 0.2301470588235294, 'recall_macro': 0.29152542372881357}
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:32,269][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.592269
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:37,032][__main__][INFO] - Epoch 25: Val Loss: 1.0353, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.33141025641025645, 'f1_weighted': 0.5565625793348566, 'precision_macro': 0.5149447693307343, 'recall_macro': 0.34751540832049305}
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:37,729][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.520366
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:42,485][__main__][INFO] - Epoch 26: Val Loss: 1.0535, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.35432131495228, 'f1_weighted': 0.5791869218735236, 'precision_macro': 0.5343580470162749, 'recall_macro': 0.37251540832049307}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:43,194][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.671775
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:47,949][__main__][INFO] - Epoch 27: Val Loss: 1.3835, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2796515937731653, 'f1_weighted': 0.5315048183839881, 'precision_macro': 0.25502008032128515, 'recall_macro': 0.31652542372881354}
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:48,658][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.455895
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:53,419][__main__][INFO] - Epoch 28: Val Loss: 0.9609, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.42386536805141456, 'f1_weighted': 0.6286688537667124, 'precision_macro': 0.5646453089244852, 'recall_macro': 0.4327426810477658}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63c6bb0>
<numpy.flatiter object at 0x7f3702f14480>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38121fb200>
<numpy.flatiter object at 0x7f374862b140>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374876a240>
<numpy.flatiter object at 0x7f37486a2b80>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f375e6f96e0>
<numpy.flatiter object at 0x7f37492441d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811792910>
<numpy.flatiter object at 0x7f38122db860>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:32:53,483][__main__][INFO] - Saved best model at epoch 28 with accuracy: 0.6931
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:32:53,587][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:54,322][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.619298
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:32:59,079][__main__][INFO] - Epoch 29: Val Loss: 1.2402, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2673611111111111, 'f1_weighted': 0.5174642464246424, 'precision_macro': 0.2457720588235294, 'recall_macro': 0.3040254237288136}
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:32:59,787][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 0.394238
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:04,548][__main__][INFO] - Epoch 30: Val Loss: 1.0835, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.3754559963520292, 'f1_weighted': 0.6005359085840184, 'precision_macro': 0.5513833992094862, 'recall_macro': 0.39751540832049304}
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:05,246][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.466087
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:33:10,010][__main__][INFO] - Epoch 31: Val Loss: 0.9232, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5532304226038242, 'f1_weighted': 0.6794344944176551, 'precision_macro': 0.830379746835443, 'recall_macro': 0.5131163328197226}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37492c0b80>
<numpy.flatiter object at 0x7f3749248660>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811804a00>
<numpy.flatiter object at 0x7f36f63c6bb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492441d0>
<numpy.flatiter object at 0x7f3748650850>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702f14480>
<numpy.flatiter object at 0x7f38119fee10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374867ff00>
<numpy.flatiter object at 0x7f37487c1e80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:33:10,076][__main__][INFO] - Saved best model at epoch 31 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:33:10,180][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:10,912][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.528975
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:15,672][__main__][INFO] - Epoch 32: Val Loss: 1.1495, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.31919559537140724, 'f1_weighted': 0.5446967429105734, 'precision_macro': 0.5040650406504066, 'recall_macro': 0.33501540832049304}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:16,375][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.456528
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:21,142][__main__][INFO] - Epoch 33: Val Loss: 0.9565, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.40325385847906764, 'f1_weighted': 0.6076662335438294, 'precision_macro': 0.5485347985347986, 'recall_macro': 0.40774268104776584}
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:21,849][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.446976
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:26,620][__main__][INFO] - Epoch 34: Val Loss: 1.2048, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.31041181041181043, 'f1_weighted': 0.5388500388500389, 'precision_macro': 0.49776785714285715, 'recall_macro': 0.3267526964560863}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:27,329][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.490423
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:32,088][__main__][INFO] - Epoch 35: Val Loss: 1.0516, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3809260284080428, 'f1_weighted': 0.5854387320303696, 'precision_macro': 0.5302631578947368, 'recall_macro': 0.3827426810477658}
Epoch 36 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:32,785][__main__][INFO] - Train Epoch: 36 [0/7 (0%)]	Loss: 0.493890
Epoch 36 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 36 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:37,541][__main__][INFO] - Epoch 36: Val Loss: 1.1796, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.40173745173745173, 'f1_weighted': 0.588929240414389, 'precision_macro': 0.5257806826434277, 'recall_macro': 0.3929699537750385}
Epoch 37 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:38,248][__main__][INFO] - Train Epoch: 37 [0/7 (0%)]	Loss: 0.593769
Epoch 37 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 37 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:43,019][__main__][INFO] - Epoch 37: Val Loss: 1.0550, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.44717155154744825, 'f1_weighted': 0.6340022606482825, 'precision_macro': 0.5627705627705628, 'recall_macro': 0.4429699537750385}
Epoch 38 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:43,725][__main__][INFO] - Train Epoch: 38 [0/7 (0%)]	Loss: 0.593304
Epoch 38 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 38 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:33:48,487][__main__][INFO] - Epoch 38: Val Loss: 1.0135, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4099522740033689, 'f1_weighted': 0.6186089692630128, 'precision_macro': 0.5576923076923077, 'recall_macro': 0.41197996918335905}
Epoch 39 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:49,185][__main__][INFO] - Train Epoch: 39 [0/7 (0%)]	Loss: 0.550091
Epoch 39 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 39 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:33:53,959][__main__][INFO] - Epoch 39: Val Loss: 0.9192, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5749857914180164, 'f1_weighted': 0.6902599467107836, 'precision_macro': 0.8410940325497287, 'recall_macro': 0.5358436055469954}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3753c781c0>
<numpy.flatiter object at 0x7f36f46a31d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63dd960>
<numpy.flatiter object at 0x7f36f5d27d60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702683b20>
<numpy.flatiter object at 0x7f374872ba60>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f4c510>
<numpy.flatiter object at 0x7f3702f1b870>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63dfa80>
<numpy.flatiter object at 0x7f3702660640>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:33:54,024][__main__][INFO] - Saved best model at epoch 39 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:33:54,126][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 40 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:33:54,860][__main__][INFO] - Train Epoch: 40 [0/7 (0%)]	Loss: 0.542372
Epoch 40 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 40 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:33:59,634][__main__][INFO] - Epoch 40: Val Loss: 1.0903, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4867760047281324, 'f1_weighted': 0.6229782552723357, 'precision_macro': 0.5457317073170732, 'recall_macro': 0.4713790446841294}
Epoch 41 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:00,332][__main__][INFO] - Train Epoch: 41 [0/7 (0%)]	Loss: 0.503224
Epoch 41 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 41 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:34:05,087][__main__][INFO] - Epoch 41: Val Loss: 0.7318, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.674066924066924, 'f1_weighted': 0.7512647017597511, 'precision_macro': 0.7170889251222878, 'recall_macro': 0.6473035439137134}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374922a5e0>
<numpy.flatiter object at 0x7f374922a5e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38117ad290>
<numpy.flatiter object at 0x7f3748716cb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38117458b0>
<numpy.flatiter object at 0x7f3811eda9f0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f89c50>
<numpy.flatiter object at 0x7f3811f363c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38117ad290>
<numpy.flatiter object at 0x7f3748716cb0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:34:05,150][__main__][INFO] - Saved best model at epoch 41 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:34:05,245][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 42 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:05,973][__main__][INFO] - Train Epoch: 42 [0/7 (0%)]	Loss: 0.632255
Epoch 42 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 42 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 42 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 42 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 42 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 42 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 42 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 42 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             [2025-05-30 15:34:10,744][__main__][INFO] - Epoch 42: Val Loss: 0.7250, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6947370890627469, 'f1_weighted': 0.7614482154118684, 'precision_macro': 0.7649799050054805, 'recall_macro': 0.6515408320493066}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f785f040>
<numpy.flatiter object at 0x7f36f785f040>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3749303110>
<numpy.flatiter object at 0x7f3749303110>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3749303110>
<numpy.flatiter object at 0x7f3749303110>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3749303110>
<numpy.flatiter object at 0x7f3749303110>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3749303110>
<numpy.flatiter object at 0x7f3749303110>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:34:10,806][__main__][INFO] - Saved best model at epoch 42 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:34:10,906][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 43 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:11,632][__main__][INFO] - Train Epoch: 43 [0/7 (0%)]	Loss: 0.551469
Epoch 43 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 43 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 43 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 43 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 43 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 43 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 43 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 43 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 43 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:34:16,389][__main__][INFO] - Epoch 43: Val Loss: 1.1757, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.49603391164189714, 'f1_weighted': 0.6256898480578198, 'precision_macro': 0.558531746031746, 'recall_macro': 0.4858436055469954}
Epoch 44 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:17,087][__main__][INFO] - Train Epoch: 44 [0/7 (0%)]	Loss: 0.587700
Epoch 44 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 44 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 44 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 44 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 44 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 44 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 44 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 44 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 44 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 44 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:34:21,843][__main__][INFO] - Epoch 44: Val Loss: 1.0582, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.350259571706684, 'f1_weighted': 0.6001760461575034, 'precision_macro': 0.31166666666666665, 'recall_macro': 0.39978813559322035}
Epoch 45 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:22,540][__main__][INFO] - Train Epoch: 45 [0/7 (0%)]	Loss: 0.627279
Epoch 45 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 45 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 45 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 45 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 45 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 45 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 45 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 45 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 45 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 45 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:34:27,297][__main__][INFO] - Epoch 45: Val Loss: 1.2204, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.47856800766283525, 'f1_weighted': 0.6154499070596714, 'precision_macro': 0.5565359477124183, 'recall_macro': 0.46311633281972264}
Epoch 46 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:28,004][__main__][INFO] - Train Epoch: 46 [0/7 (0%)]	Loss: 0.534244
Epoch 46 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 46 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 46 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 46 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 46 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 46 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 46 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 46 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 46 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 46 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:34:32,752][__main__][INFO] - Epoch 46: Val Loss: 0.8132, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.700702548225768, 'f1_weighted': 0.759806083013636, 'precision_macro': 0.7784834004024145, 'recall_macro': 0.6535053929121726}
Epoch 47 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:33,449][__main__][INFO] - Train Epoch: 47 [0/7 (0%)]	Loss: 0.604267
Epoch 47 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 47 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 47 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 47 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 47 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 47 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 47 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 47 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 47 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 47 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:34:38,206][__main__][INFO] - Epoch 47: Val Loss: 1.0115, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5270897832817337, 'f1_weighted': 0.6725929558900163, 'precision_macro': 0.5845959595959596, 'recall_macro': 0.5111517719568567}
Epoch 48 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:38,913][__main__][INFO] - Train Epoch: 48 [0/7 (0%)]	Loss: 0.605376
Epoch 48 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 48 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 48 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 48 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 48 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 48 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 48 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 48 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 48 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 48 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:34:43,674][__main__][INFO] - Epoch 48: Val Loss: 0.9094, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.5905341712490181, 'f1_weighted': 0.7154534777908269, 'precision_macro': 0.6172222222222222, 'recall_macro': 0.5816063174114021}
Epoch 49 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:44,383][__main__][INFO] - Train Epoch: 49 [0/7 (0%)]	Loss: 0.506013
Epoch 49 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 49 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 49 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 49 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 49 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 49 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 49 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 49 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 49 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 49 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:34:49,136][__main__][INFO] - Epoch 49: Val Loss: 0.7739, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6272168972048442, 'f1_weighted': 0.7332750665871843, 'precision_macro': 0.704861111111111, 'recall_macro': 0.6000963020030816}
Epoch 50 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:49,846][__main__][INFO] - Train Epoch: 50 [0/7 (0%)]	Loss: 0.512869
Epoch 50 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 50 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 50 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 50 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 50 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 50 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 50 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 50 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:34:54,610][__main__][INFO] - Epoch 50: Val Loss: 1.0951, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5112305411415864, 'f1_weighted': 0.639894604731044, 'precision_macro': 0.5716867469879519, 'recall_macro': 0.49834360554699536}
Epoch 51 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:34:55,316][__main__][INFO] - Train Epoch: 51 [0/7 (0%)]	Loss: 0.331497
Epoch 51 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 51 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 51 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 51 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 51 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 51 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 51 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 51 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 51 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 51 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:00,067][__main__][INFO] - Epoch 51: Val Loss: 1.1866, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.33696548661337394, 'f1_weighted': 0.5620504760792029, 'precision_macro': 0.52462792345854, 'recall_macro': 0.35175269645608626}
Epoch 52 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:00,764][__main__][INFO] - Train Epoch: 52 [0/7 (0%)]	Loss: 0.573691
Epoch 52 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 52 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 52 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 52 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 52 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 52 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 52 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 52 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 52 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 52 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:05,520][__main__][INFO] - Epoch 52: Val Loss: 0.8984, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5641068784493202, 'f1_weighted': 0.6907623189294297, 'precision_macro': 0.6089511754068716, 'recall_macro': 0.5483436055469955}
[2025-05-30 15:35:05,522][__main__][INFO] - Early stopping triggered after 52 epochs
[2025-05-30 15:35:05,523][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7723
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3749233b40>
<numpy.flatiter object at 0x7f3749233b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f374924a530>
<numpy.flatiter object at 0x7f374924a530>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374924a530>
<numpy.flatiter object at 0x7f374924a530>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374924ab30>
<numpy.flatiter object at 0x7f374924ab30>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374924ab30>
<numpy.flatiter object at 0x7f374924ab30>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñÜ‚ñá
wandb:            Validation Loss ‚ñà‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ
wandb:     Validation f1_weighted ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÜ‚ñá
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.77228
wandb:                 Train Loss 0.57369
wandb:        Validation Accuracy 0.74257
wandb:            Validation Loss 0.89838
wandb:        Validation accuracy 0.74257
wandb:        Validation f1_macro 0.56411
wandb:     Validation f1_weighted 0.69076
wandb: Validation precision_macro 0.60895
wandb:    Validation recall_macro 0.54834
wandb: 
wandb: üöÄ View run zany-sweep-10 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/6r0s40y2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_153009-6r0s40y2/logs
wandb: Agent Starting Run: ivur44yi with config:
wandb: 	Fdropout_rate: 0.3774131914820842
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 8
wandb: 	Mdropout_rate: 0.11958954751221763
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.03027205316986029
wandb: 	pretrained_model_name: dmis-lab/biobert-base-cased-v1.1
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_153512-ivur44yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/ivur44yi
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:17,631][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.528545
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.40it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:22,333][__main__][INFO] - Epoch 0: Val Loss: 24.3580, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f6403550>
<numpy.flatiter object at 0x7f36f6403550>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6403550>
<numpy.flatiter object at 0x7f36f6403550>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6403550>
<numpy.flatiter object at 0x7f36f6403550>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6403550>
<numpy.flatiter object at 0x7f36f6403550>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6403550>
<numpy.flatiter object at 0x7f36f6403550>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:35:22,398][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:35:22,495][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:35:22,527][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:23,217][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 19.643093
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:27,903][__main__][INFO] - Epoch 1: Val Loss: 25.3465, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:28,622][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 17.843306
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:33,327][__main__][INFO] - Epoch 2: Val Loss: 9.6811, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:34,028][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 10.440536
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:38,736][__main__][INFO] - Epoch 3: Val Loss: 5.6077, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:39,430][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 4.425651
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:02<00:05,  1.07s/it]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:03<00:04,  1.20s/it]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:04<00:03,  1.26s/it]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:06<00:02,  1.29s/it]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:07<00:01,  1.31s/it]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:07<00:00,  1.02s/it]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.29s/it]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:48,638][__main__][INFO] - Epoch 4: Val Loss: 3.1433, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:49,456][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 2.476979
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.23it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.35it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.39it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.41it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:54,188][__main__][INFO] - Epoch 5: Val Loss: 2.3101, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:35:54,892][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 1.446627
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:35:59,628][__main__][INFO] - Epoch 6: Val Loss: 2.5024, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:00,330][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 1.981128
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:05,072][__main__][INFO] - Epoch 7: Val Loss: 1.3970, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.21032258064516127, 'f1_weighted': 0.4605557329926541, 'precision_macro': 0.20364583333333336, 'recall_macro': 0.2625}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38122d6c70>
<numpy.flatiter object at 0x7f38122d6c70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370339a720>
<numpy.flatiter object at 0x7f370339a720>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370339a720>
<numpy.flatiter object at 0x7f370339a720>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370339a720>
<numpy.flatiter object at 0x7f370339a720>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370339a720>
<numpy.flatiter object at 0x7f370339a720>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:36:05,135][__main__][INFO] - Saved best model at epoch 7 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:36:05,234][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:05,960][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 0.797678
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:10,701][__main__][INFO] - Epoch 8: Val Loss: 2.6455, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:11,396][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 1.723924
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:16,138][__main__][INFO] - Epoch 9: Val Loss: 1.3926, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.25448361162646876, 'f1_weighted': 0.5010256127653582, 'precision_macro': 0.2388548951048951, 'recall_macro': 0.29152542372881357}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38116bfc40>
<numpy.flatiter object at 0x7f38116bfc40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37036072c0>
<numpy.flatiter object at 0x7f37036072c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37036072c0>
<numpy.flatiter object at 0x7f37036072c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37036078c0>
<numpy.flatiter object at 0x7f37036078c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37036078c0>
<numpy.flatiter object at 0x7f37036078c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:36:16,202][__main__][INFO] - Saved best model at epoch 9 with accuracy: 0.6040
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:36:16,308][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:17,035][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 0.889286
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:21,780][__main__][INFO] - Epoch 10: Val Loss: 1.0493, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3206586318112375, 'f1_weighted': 0.5696623982547636, 'precision_macro': 0.28818283166109254, 'recall_macro': 0.3622881355932204}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38122d0220>
<numpy.flatiter object at 0x7f38122d0220>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63d19c0>
<numpy.flatiter object at 0x7f36f63d19c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63d19c0>
<numpy.flatiter object at 0x7f36f63d19c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38117cedf0>
<numpy.flatiter object at 0x7f38117cedf0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38117cedf0>
<numpy.flatiter object at 0x7f38117cedf0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:36:21,842][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:36:21,937][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:36:21,969][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:22,664][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 0.693977
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:27,423][__main__][INFO] - Epoch 11: Val Loss: 1.2222, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2679802955665025, 'f1_weighted': 0.51584646149344, 'precision_macro': 0.24903100775193798, 'recall_macro': 0.3040254237288136}
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:28,127][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 0.692812
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:32,879][__main__][INFO] - Epoch 12: Val Loss: 0.9088, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.43652241918665274, 'f1_weighted': 0.6232461619467474, 'precision_macro': 0.5544871794871795, 'recall_macro': 0.43046995377503855}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3812275540>
<numpy.flatiter object at 0x7f3812275540>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37486b6900>
<numpy.flatiter object at 0x7f37486b6900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486b6900>
<numpy.flatiter object at 0x7f37486b6900>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37486b6f00>
<numpy.flatiter object at 0x7f37486b6f00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486b6f00>
<numpy.flatiter object at 0x7f37486b6f00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:36:32,945][__main__][INFO] - Saved best model at epoch 12 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:36:33,046][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:33,777][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 0.749983
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:38,539][__main__][INFO] - Epoch 13: Val Loss: 0.9318, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.45908748114630465, 'f1_weighted': 0.6370756985200782, 'precision_macro': 0.5133971291866029, 'recall_macro': 0.4531972265023113}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702eef990>
<numpy.flatiter object at 0x7f3702eef990>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748790860>
<numpy.flatiter object at 0x7f3748790860>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748790860>
<numpy.flatiter object at 0x7f3748790860>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748790e60>
<numpy.flatiter object at 0x7f3748790e60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748790e60>
<numpy.flatiter object at 0x7f3748790e60>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:36:38,607][__main__][INFO] - Saved best model at epoch 13 with accuracy: 0.6931
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:36:38,708][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:39,439][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 0.688391
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:44,207][__main__][INFO] - Epoch 14: Val Loss: 1.2829, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.36599099099099097, 'f1_weighted': 0.5383551868700384, 'precision_macro': 0.34073033707865163, 'recall_macro': 0.40909090909090906}
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:44,911][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 0.736489
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:36:49,674][__main__][INFO] - Epoch 15: Val Loss: 1.1303, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.33141025641025645, 'f1_weighted': 0.5565625793348566, 'precision_macro': 0.5149447693307343, 'recall_macro': 0.34751540832049305}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:50,380][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 0.572757
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:36:55,146][__main__][INFO] - Epoch 16: Val Loss: 0.8361, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.47824074074074074, 'f1_weighted': 0.6516318298496516, 'precision_macro': 0.5717105263157894, 'recall_macro': 0.46569722650231127}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3812275540>
<numpy.flatiter object at 0x7f3812275540>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702f036c0>
<numpy.flatiter object at 0x7f3702f036c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f036c0>
<numpy.flatiter object at 0x7f3702f036c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37035d8c80>
<numpy.flatiter object at 0x7f37035d8c80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035d8c80>
<numpy.flatiter object at 0x7f37035d8c80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:36:55,204][__main__][INFO] - Saved best model at epoch 16 with accuracy: 0.7030
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:36:55,298][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:36:56,026][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.634720
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:00,786][__main__][INFO] - Epoch 17: Val Loss: 0.7898, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5542607138192877, 'f1_weighted': 0.6805136714719998, 'precision_macro': 0.6533432783432783, 'recall_macro': 0.5603235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37035c50c0>
<numpy.flatiter object at 0x7f37035c50c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702cc9c80>
<numpy.flatiter object at 0x7f3702cc9c80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702cc9c80>
<numpy.flatiter object at 0x7f3702cc9c80>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702cca280>
<numpy.flatiter object at 0x7f3702cca280>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702cca280>
<numpy.flatiter object at 0x7f3702cca280>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:37:00,851][__main__][INFO] - Saved best model at epoch 17 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:37:00,953][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:01,690][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.686824
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:37:06,457][__main__][INFO] - Epoch 18: Val Loss: 1.0039, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4428802903623047, 'f1_weighted': 0.6144047887191986, 'precision_macro': 0.5426470588235294, 'recall_macro': 0.4281972265023113}
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:07,161][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.595353
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:37:11,929][__main__][INFO] - Epoch 19: Val Loss: 1.2091, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.37853881278538815, 'f1_weighted': 0.5538134635381347, 'precision_macro': 0.48879310344827587, 'recall_macro': 0.3699345146379045}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:12,637][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.683882
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             [2025-05-30 15:37:17,413][__main__][INFO] - Epoch 20: Val Loss: 0.8022, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6432861815555839, 'f1_weighted': 0.7070547656269386, 'precision_macro': 0.6508676351896692, 'recall_macro': 0.6403697996918336}
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:18,119][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 0.666898
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:37:22,879][__main__][INFO] - Epoch 21: Val Loss: 1.1674, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.40649273893954746, 'f1_weighted': 0.5959820906102768, 'precision_macro': 0.5331554878048781, 'recall_macro': 0.3972072419106317}
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:23,587][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 0.751951
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.41it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.42it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:28,366][__main__][INFO] - Epoch 22: Val Loss: 0.7290, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6277472527472527, 'f1_weighted': 0.728919595256229, 'precision_macro': 0.7258561643835616, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486e4b00>
<numpy.flatiter object at 0x7f37486e4b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370309c0c0>
<numpy.flatiter object at 0x7f370309c0c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370309c0c0>
<numpy.flatiter object at 0x7f370309c0c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370309c6c0>
<numpy.flatiter object at 0x7f370309c6c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370309c6c0>
<numpy.flatiter object at 0x7f370309c6c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:37:28,438][__main__][INFO] - Saved best model at epoch 22 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:37:28,530][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:29,261][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.599054
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:34,025][__main__][INFO] - Epoch 23: Val Loss: 0.8135, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.49839514175872657, 'f1_weighted': 0.6480824648383321, 'precision_macro': 0.638095238095238, 'recall_macro': 0.4714753466872111}
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:34,723][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.684858
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:39,488][__main__][INFO] - Epoch 24: Val Loss: 0.7653, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.46883196363000523, 'f1_weighted': 0.6583318762021332, 'precision_macro': 0.5804935370152762, 'recall_macro': 0.4679699537750385}
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:40,196][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.612288
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:44,969][__main__][INFO] - Epoch 25: Val Loss: 0.7301, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6356483018032968, 'f1_weighted': 0.7353848395128261, 'precision_macro': 0.8368055555555556, 'recall_macro': 0.6330508474576271}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f5d482f0>
<numpy.flatiter object at 0x7f36f5d482f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37486e6900>
<numpy.flatiter object at 0x7f37486e6900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486e6900>
<numpy.flatiter object at 0x7f37486e6900>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37486e6f00>
<numpy.flatiter object at 0x7f37486e6f00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486e6f00>
<numpy.flatiter object at 0x7f37486e6f00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:37:45,030][__main__][INFO] - Saved best model at epoch 25 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:37:45,129][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:45,859][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.497081
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:50,629][__main__][INFO] - Epoch 26: Val Loss: 0.7093, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6617756512493355, 'f1_weighted': 0.7214901941321952, 'precision_macro': 0.6909232247851651, 'recall_macro': 0.6448189522342065}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:51,338][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.501044
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:37:56,105][__main__][INFO] - Epoch 27: Val Loss: 0.7976, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6675861108710474, 'f1_weighted': 0.7123314526595689, 'precision_macro': 0.6766630116959064, 'recall_macro': 0.66712249614792}
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:37:56,804][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.576714
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:38:01,578][__main__][INFO] - Epoch 28: Val Loss: 0.7295, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6043859649122807, 'f1_weighted': 0.7203057147820046, 'precision_macro': 0.6189117199391172, 'recall_macro': 0.6000963020030817}
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:02,286][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.476767
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:38:07,054][__main__][INFO] - Epoch 29: Val Loss: 0.9774, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5456614509246088, 'f1_weighted': 0.6660788980747292, 'precision_macro': 0.5746904024767802, 'recall_macro': 0.5356317411402157}
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:07,761][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 0.491983
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:38:12,537][__main__][INFO] - Epoch 30: Val Loss: 0.7499, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.7255485893416928, 'f1_weighted': 0.7553772618641176, 'precision_macro': 0.7194117286222549, 'recall_macro': 0.7335516178736519}
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:13,238][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.620895
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:38:18,018][__main__][INFO] - Epoch 31: Val Loss: 0.6907, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6242972295603875, 'f1_weighted': 0.734796584718419, 'precision_macro': 0.6303656597774245, 'recall_macro': 0.6270608628659476}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030de840>
<numpy.flatiter object at 0x7f37030de840>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f374869bb90>
<numpy.flatiter object at 0x7f374869bb90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374869bb90>
<numpy.flatiter object at 0x7f374869bb90>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374869c190>
<numpy.flatiter object at 0x7f374869c190>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374869c190>
<numpy.flatiter object at 0x7f374869c190>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:38:18,084][__main__][INFO] - Saved best model at epoch 31 with accuracy: 0.7822
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:38:18,186][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:18,919][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.449114
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:38:23,687][__main__][INFO] - Epoch 32: Val Loss: 0.7304, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.7149396177030994, 'f1_weighted': 0.7341861462941999, 'precision_macro': 0.7029494190020505, 'recall_macro': 0.7475924499229585}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:24,399][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.629085
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:38:29,159][__main__][INFO] - Epoch 33: Val Loss: 0.6688, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6094451244390044, 'f1_weighted': 0.7049254497053132, 'precision_macro': 0.6607142857142857, 'recall_macro': 0.5976117103235747}
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:29,858][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.615714
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:38:34,616][__main__][INFO] - Epoch 34: Val Loss: 0.7129, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6302118171683389, 'f1_weighted': 0.7287746834884157, 'precision_macro': 0.7109741784037559, 'recall_macro': 0.6288135593220339}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:35,323][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.387086
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:38:40,085][__main__][INFO] - Epoch 35: Val Loss: 0.8908, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5566522893165229, 'f1_weighted': 0.6755799667557998, 'precision_macro': 0.5734265734265734, 'recall_macro': 0.5645608628659476}
Epoch 36 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:40,792][__main__][INFO] - Train Epoch: 36 [0/7 (0%)]	Loss: 0.503139
Epoch 36 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 36 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:38:45,558][__main__][INFO] - Epoch 36: Val Loss: 0.9275, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5800958853590432, 'f1_weighted': 0.704794841741168, 'precision_macro': 0.6106811145510835, 'recall_macro': 0.5691063174114022}
Epoch 37 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:46,266][__main__][INFO] - Train Epoch: 37 [0/7 (0%)]	Loss: 0.458510
Epoch 37 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 37 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:38:51,037][__main__][INFO] - Epoch 37: Val Loss: 0.8653, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5108138489208633, 'f1_weighted': 0.6444511717358786, 'precision_macro': 0.5430555555555555, 'recall_macro': 0.5066063174114022}
Epoch 38 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:51,746][__main__][INFO] - Train Epoch: 38 [0/7 (0%)]	Loss: 0.430195
Epoch 38 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 38 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             [2025-05-30 15:38:56,530][__main__][INFO] - Epoch 38: Val Loss: 0.6906, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5968836718836719, 'f1_weighted': 0.7019934960529018, 'precision_macro': 0.6463735061886471, 'recall_macro': 0.589348998459168}
Epoch 39 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:38:57,243][__main__][INFO] - Train Epoch: 39 [0/7 (0%)]	Loss: 0.372350
Epoch 39 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.43it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 39 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:39:02,011][__main__][INFO] - Epoch 39: Val Loss: 0.7379, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.7265947125879214, 'f1_weighted': 0.7761002634340562, 'precision_macro': 0.7618055555555555, 'recall_macro': 0.7010208012326656}
Epoch 40 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:39:02,709][__main__][INFO] - Train Epoch: 40 [0/7 (0%)]	Loss: 0.373983
Epoch 40 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 40 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:39:07,474][__main__][INFO] - Epoch 40: Val Loss: 0.7660, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5597465886939571, 'f1_weighted': 0.694408739119526, 'precision_macro': 0.6008771929824561, 'recall_macro': 0.5463790446841295}
Epoch 41 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:39:08,179][__main__][INFO] - Train Epoch: 41 [0/7 (0%)]	Loss: 0.451433
Epoch 41 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.43it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.84it/s]                                                               Epoch 41 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:39:12,958][__main__][INFO] - Epoch 41: Val Loss: 0.7207, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6498405103668261, 'f1_weighted': 0.7473084150520316, 'precision_macro': 0.8723363774733638, 'recall_macro': 0.6270608628659476}
Epoch 42 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:39:13,661][__main__][INFO] - Train Epoch: 42 [0/7 (0%)]	Loss: 0.332674
Epoch 42 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 42 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 42 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 42 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 42 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 42 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 42 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 42 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:39:18,427][__main__][INFO] - Epoch 42: Val Loss: 0.7564, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6169312169312169, 'f1_weighted': 0.713960919901514, 'precision_macro': 0.8508771929824561, 'recall_macro': 0.5895608628659477}
Epoch 43 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:39:19,140][__main__][INFO] - Train Epoch: 43 [0/7 (0%)]	Loss: 0.367478
Epoch 43 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 43 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 43 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 43 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 43 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 43 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 43 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 43 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 43 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 15:39:23,896][__main__][INFO] - Epoch 43: Val Loss: 0.6878, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6921578947368421, 'f1_weighted': 0.7456154247003648, 'precision_macro': 0.7348484848484849, 'recall_macro': 0.6615562403697998}
[2025-05-30 15:39:23,899][__main__][INFO] - Early stopping triggered after 43 epochs
[2025-05-30 15:39:23,899][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7822
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f48a8380>
<numpy.flatiter object at 0x7f36f48a8380>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702ca04f0>
<numpy.flatiter object at 0x7f3702ca04f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702ca04f0>
<numpy.flatiter object at 0x7f3702ca04f0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702ca0af0>
<numpy.flatiter object at 0x7f3702ca0af0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702ca0af0>
<numpy.flatiter object at 0x7f3702ca0af0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñá
wandb:            Validation Loss ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñà
wandb:     Validation f1_weighted ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñà‚ñá
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.78218
wandb:                 Train Loss 0.36748
wandb:        Validation Accuracy 0.75248
wandb:            Validation Loss 0.68776
wandb:        Validation accuracy 0.75248
wandb:        Validation f1_macro 0.69216
wandb:     Validation f1_weighted 0.74562
wandb: Validation precision_macro 0.73485
wandb:    Validation recall_macro 0.66156
wandb: 
wandb: üöÄ View run smart-sweep-11 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/ivur44yi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 11 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_153512-ivur44yi/logs
wandb: Agent Starting Run: x236w1h7 with config:
wandb: 	Fdropout_rate: 0.2827165537759782
wandb: 	Fnum_heads: 4
wandb: 	Fnum_layers: 5
wandb: 	Mdropout_rate: 0.1062877105931635
wandb: 	Mnum_layers: 4
wandb: 	batch_size: 32
wandb: 	learning_rate: 0.029757869458519062
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_153928-x236w1h7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/x236w1h7
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-8.8125, -7.0, 8.8125, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:39:33,958][__main__][INFO] - Train Epoch: 0 [0/13 (0%)]	Loss: 2.140086
Epoch 0 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.73it/s]Epoch 0 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 0 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 0 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 0 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 0 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 0 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 0 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:39:39,122][__main__][INFO] - Epoch 0: Val Loss: 47.5529, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63e21d0>
<numpy.flatiter object at 0x7f36f63e21d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811cb8610>
<numpy.flatiter object at 0x7f3811cb8610>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811cb8610>
<numpy.flatiter object at 0x7f3811cb8610>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811cb8610>
<numpy.flatiter object at 0x7f3811cb8610>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811cb8610>
<numpy.flatiter object at 0x7f3811cb8610>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:39:39,450][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.1980
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:39:39,568][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:39:39,609][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:39:39,963][__main__][INFO] - Train Epoch: 1 [0/13 (0%)]	Loss: 34.084976
Epoch 1 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 1 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.85it/s]Epoch 1 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 1 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 1 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 1 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 1 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 1 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:39:45,134][__main__][INFO] - Epoch 1: Val Loss: 12.0559, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:39:45,204][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:39:45,303][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:39:45,691][__main__][INFO] - Train Epoch: 2 [0/13 (0%)]	Loss: 9.821410
Epoch 2 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 2 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 2 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 2 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 2 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 2 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 2 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 2 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:39:50,863][__main__][INFO] - Epoch 2: Val Loss: 2.4254, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:39:51,227][__main__][INFO] - Train Epoch: 3 [0/13 (0%)]	Loss: 1.874121
Epoch 3 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 3 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 3 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 3 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 3 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                Epoch 3 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 3 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 3 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:39:56,416][__main__][INFO] - Epoch 3: Val Loss: 1.4031, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.23252937538651824, 'f1_weighted': 0.473128945547616, 'precision_macro': 0.2139423076923077, 'recall_macro': 0.2705508474576271}
Epoch 4 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:39:56,771][__main__][INFO] - Train Epoch: 4 [0/13 (0%)]	Loss: 1.222789
Epoch 4 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 4 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 4 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 4 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 4 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                Epoch 4 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 4 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 4 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:01,955][__main__][INFO] - Epoch 4: Val Loss: 1.1909, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:02,320][__main__][INFO] - Train Epoch: 5 [0/13 (0%)]	Loss: 1.155276
Epoch 5 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 5 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 5 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 5 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 5 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                Epoch 5 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 5 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:07,522][__main__][INFO] - Epoch 5: Val Loss: 1.3654, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:07,886][__main__][INFO] - Train Epoch: 6 [0/13 (0%)]	Loss: 1.277752
Epoch 6 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 6 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 6 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 6 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 6 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                Epoch 6 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 6 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 6 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:13,084][__main__][INFO] - Epoch 6: Val Loss: 1.0999, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18789808917197454, 'f1_weighted': 0.43904900044144546, 'precision_macro': 0.15051020408163265, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:13,450][__main__][INFO] - Train Epoch: 7 [0/13 (0%)]	Loss: 1.105917
Epoch 7 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 7 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 7 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 7 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 7 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                Epoch 7 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 7 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 7 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:18,664][__main__][INFO] - Epoch 7: Val Loss: 1.0130, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.27083333333333337, 'f1_weighted': 0.5255775577557756, 'precision_macro': 0.24871323529411765, 'recall_macro': 0.3082627118644068}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030c1bb0>
<numpy.flatiter object at 0x7f37030c1bb0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:40:18,729][__main__][INFO] - Saved best model at epoch 7 with accuracy: 0.6238
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:40:18,830][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 8 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:19,220][__main__][INFO] - Train Epoch: 8 [0/13 (0%)]	Loss: 1.063157
Epoch 8 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 8 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 8 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 8 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 8 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                Epoch 8 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 8 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 8 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                            [2025-05-30 15:40:24,419][__main__][INFO] - Epoch 8: Val Loss: 1.0547, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.3711014607185156, 'f1_weighted': 0.5316593246375565, 'precision_macro': 0.4111111111111111, 'recall_macro': 0.38212634822804314}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370312d510>
<numpy.flatiter object at 0x7f3810124650>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370269e6b0>
<numpy.flatiter object at 0x7f3748dad360>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703383d90>
<numpy.flatiter object at 0x7f3749310910>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f617a680>
<numpy.flatiter object at 0x7f370312c4c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:40:24,481][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.6337
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:40:24,576][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:24,965][__main__][INFO] - Train Epoch: 9 [0/13 (0%)]	Loss: 0.686131
Epoch 9 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 9 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 9 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 9 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 9 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                Epoch 9 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 9 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 9 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:30,163][__main__][INFO] - Epoch 9: Val Loss: 1.2736, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18789808917197454, 'f1_weighted': 0.43904900044144546, 'precision_macro': 0.15051020408163265, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:30,521][__main__][INFO] - Train Epoch: 10 [0/13 (0%)]	Loss: 0.950284
Epoch 10 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 10 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 10 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 10 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 10 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 10 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:35,747][__main__][INFO] - Epoch 10: Val Loss: 1.0967, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.3021287416448707, 'f1_weighted': 0.5271075930609627, 'precision_macro': 0.5038304392236976, 'recall_macro': 0.3184899845916795}
Epoch 11 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:36,112][__main__][INFO] - Train Epoch: 11 [0/13 (0%)]	Loss: 0.903944
Epoch 11 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 11 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 11 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 11 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 11 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 11 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 11 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:41,319][__main__][INFO] - Epoch 11: Val Loss: 0.9573, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4575757575757575, 'f1_weighted': 0.611941194119412, 'precision_macro': 0.5025098358431692, 'recall_macro': 0.4486517719568567}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3810039630>
<numpy.flatiter object at 0x7f38101d6940>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37492c6150>
<numpy.flatiter object at 0x7f3811a12580>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381011d700>
<numpy.flatiter object at 0x7f3702ab8e00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748fc4940>
<numpy.flatiter object at 0x7f3702f11c80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38101da170>
<numpy.flatiter object at 0x7f3703381c80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:40:41,382][__main__][INFO] - Saved best model at epoch 11 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:40:41,482][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 12 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:41,872][__main__][INFO] - Train Epoch: 12 [0/13 (0%)]	Loss: 0.687170
Epoch 12 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 12 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 12 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 12 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 12 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 12 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 12 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:47,088][__main__][INFO] - Epoch 12: Val Loss: 1.0815, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.45769230769230773, 'f1_weighted': 0.6001523229246001, 'precision_macro': 0.5158268733850129, 'recall_macro': 0.4650808936825886}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38121f0140>
<numpy.flatiter object at 0x7f3748fe7e70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37487466c0>
<numpy.flatiter object at 0x7f3748fc4940>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37483f7900>
<numpy.flatiter object at 0x7f38117ae910>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748fe7e70>
<numpy.flatiter object at 0x7f3811a0e040>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f672c0>
<numpy.flatiter object at 0x7f36f63d4dc0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:40:47,148][__main__][INFO] - Saved best model at epoch 12 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:40:47,243][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 13 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:47,631][__main__][INFO] - Train Epoch: 13 [0/13 (0%)]	Loss: 0.533871
Epoch 13 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 13 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 13 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 13 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 13 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 13 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.94it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 13 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:52,855][__main__][INFO] - Epoch 13: Val Loss: 1.1834, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.4912630413242408, 'f1_weighted': 0.6609572515216201, 'precision_macro': 0.5771151586368978, 'recall_macro': 0.4864599383667181}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703380b90>
<numpy.flatiter object at 0x7f3703380b90>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63da2e0>
<numpy.flatiter object at 0x7f36f5f3ec90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63e0df0>
<numpy.flatiter object at 0x7f36f63de9b0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37487a0140>
<numpy.flatiter object at 0x7f36f46a0440>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3810180a30>
<numpy.flatiter object at 0x7f3749306fb0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:40:52,921][__main__][INFO] - Saved best model at epoch 13 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:40:53,023][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 14 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:53,421][__main__][INFO] - Train Epoch: 14 [0/13 (0%)]	Loss: 0.684919
Epoch 14 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 14 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 14 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 14 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 14 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 14 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 14 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:40:58,639][__main__][INFO] - Epoch 14: Val Loss: 1.0639, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.4704177862072598, 'f1_weighted': 0.6403401838524297, 'precision_macro': 0.4842298761609907, 'recall_macro': 0.47168721109399075}
Epoch 15 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:40:58,996][__main__][INFO] - Train Epoch: 15 [0/13 (0%)]	Loss: 0.622117
Epoch 15 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 15 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 15 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 15 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 15 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 15 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 15 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:41:04,205][__main__][INFO] - Epoch 15: Val Loss: 1.1694, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.35432131495228, 'f1_weighted': 0.5791869218735236, 'precision_macro': 0.5343580470162749, 'recall_macro': 0.37251540832049307}
Epoch 16 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:04,563][__main__][INFO] - Train Epoch: 16 [0/13 (0%)]	Loss: 0.656022
Epoch 16 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 16 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 16 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 16 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 16 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 16 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 16 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 16 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 16 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 16 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 16 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:41:09,784][__main__][INFO] - Epoch 16: Val Loss: 1.0021, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5353215199123128, 'f1_weighted': 0.6596530131639399, 'precision_macro': 0.8105485232067511, 'recall_macro': 0.4963790446841294}
Epoch 17 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:10,145][__main__][INFO] - Train Epoch: 17 [0/13 (0%)]	Loss: 0.430830
Epoch 17 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 17 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 17 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 17 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 17 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 17 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 17 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 17 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 17 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 17 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 17 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:41:15,373][__main__][INFO] - Epoch 17: Val Loss: 1.0663, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5390977443609022, 'f1_weighted': 0.6663961884910297, 'precision_macro': 0.5925925925925926, 'recall_macro': 0.5233436055469953}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748684570>
<numpy.flatiter object at 0x7f3748684570>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381225c4a0>
<numpy.flatiter object at 0x7f381225c4a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381225c4a0>
<numpy.flatiter object at 0x7f381225c4a0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f381225c4a0>
<numpy.flatiter object at 0x7f381225c4a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381225c4a0>
<numpy.flatiter object at 0x7f381225c4a0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:41:15,440][__main__][INFO] - Saved best model at epoch 17 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:41:15,541][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 18 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:15,932][__main__][INFO] - Train Epoch: 18 [0/13 (0%)]	Loss: 0.592944
Epoch 18 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 18 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 18 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 18 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 18 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 18 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 18 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 18 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 18 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 18 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 18 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:41:21,155][__main__][INFO] - Epoch 18: Val Loss: 0.9246, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5754985754985755, 'f1_weighted': 0.6874559250796874, 'precision_macro': 0.712171052631579, 'recall_macro': 0.5398690292758089}
Epoch 19 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:21,522][__main__][INFO] - Train Epoch: 19 [0/13 (0%)]	Loss: 0.515227
Epoch 19 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 19 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 19 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 19 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 19 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 19 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 19 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 19 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 19 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 19 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 19 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:41:26,746][__main__][INFO] - Epoch 19: Val Loss: 0.9794, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.589731052658444, 'f1_weighted': 0.6940409221630813, 'precision_macro': 0.7275641025641026, 'recall_macro': 0.5543335901386749}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63e9640>
<numpy.flatiter object at 0x7f3702f18840>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6188780>
<numpy.flatiter object at 0x7f37487c2e70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37033c0980>
<numpy.flatiter object at 0x7f374930ad00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38122415c0>
<numpy.flatiter object at 0x7f38122415c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38122415c0>
<numpy.flatiter object at 0x7f38122415c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:41:26,805][__main__][INFO] - Saved best model at epoch 19 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:41:26,900][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 20 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:27,287][__main__][INFO] - Train Epoch: 20 [0/13 (0%)]	Loss: 0.445520
Epoch 20 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 20 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 20 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 20 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 20 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 20 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 20 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 20 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 20 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 20 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 20 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:41:32,503][__main__][INFO] - Epoch 20: Val Loss: 0.8938, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6248330790315523, 'f1_weighted': 0.7290676913532329, 'precision_macro': 0.7174428104575163, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703607d30>
<numpy.flatiter object at 0x7f3703607d30>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f37190>
<numpy.flatiter object at 0x7f36f6188780>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f37190>
<numpy.flatiter object at 0x7f36f6188780>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6188780>
<numpy.flatiter object at 0x7f36f6188780>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6188780>
<numpy.flatiter object at 0x7f36f6188780>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:41:32,571][__main__][INFO] - Saved best model at epoch 20 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:41:32,670][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:41:32,713][__main__][INFO] - Saved model at epoch 20
Epoch 21 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:33,071][__main__][INFO] - Train Epoch: 21 [0/13 (0%)]	Loss: 0.385049
Epoch 21 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 21 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 21 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 21 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 21 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 21 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 21 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 21 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 21 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 21 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 21 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:41:38,294][__main__][INFO] - Epoch 21: Val Loss: 1.1117, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.45777777777777773, 'f1_weighted': 0.6154015401540154, 'precision_macro': 0.5411691542288557, 'recall_macro': 0.4610362095531587}
Epoch 22 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:38,660][__main__][INFO] - Train Epoch: 22 [0/13 (0%)]	Loss: 0.279865
Epoch 22 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 22 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 22 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 22 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 22 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 22 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 22 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 22 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 22 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 22 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 22 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:41:43,879][__main__][INFO] - Epoch 22: Val Loss: 0.9684, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6332070298661491, 'f1_weighted': 0.7254913856063763, 'precision_macro': 0.7402380952380953, 'recall_macro': 0.5895608628659477}
Epoch 23 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:44,238][__main__][INFO] - Train Epoch: 23 [0/13 (0%)]	Loss: 0.479817
Epoch 23 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 23 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 23 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 23 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 23 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 23 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 23 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 23 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 23 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 23 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s]Epoch 23 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:41:49,460][__main__][INFO] - Epoch 23: Val Loss: 1.0819, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.4277298311444653, 'f1_weighted': 0.5786487842029981, 'precision_macro': 0.5541666666666667, 'recall_macro': 0.5136171032357473}
Epoch 24 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:49,818][__main__][INFO] - Train Epoch: 24 [0/13 (0%)]	Loss: 1.097580
Epoch 24 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 24 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 24 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 24 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 24 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 24 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 24 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.80it/s]Epoch 24 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.80it/s]Epoch 24 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.80it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 24 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 24 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:41:55,059][__main__][INFO] - Epoch 24: Val Loss: 1.0227, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5700663349917081, 'f1_weighted': 0.7049734824228691, 'precision_macro': 0.6077192982456141, 'recall_macro': 0.5588790446841294}
Epoch 25 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:41:55,425][__main__][INFO] - Train Epoch: 25 [0/13 (0%)]	Loss: 0.499966
Epoch 25 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 25 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 25 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 25 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 25 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 25 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 25 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 25 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 25 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 25 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 25 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:42:00,637][__main__][INFO] - Epoch 25: Val Loss: 1.0744, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.593671679197995, 'f1_weighted': 0.7156381051638998, 'precision_macro': 0.5939117199391172, 'recall_macro': 0.6000963020030817}
Epoch 26 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:42:01,004][__main__][INFO] - Train Epoch: 26 [0/13 (0%)]	Loss: 0.684158
Epoch 26 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.75it/s]Epoch 26 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 26 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 26 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 26 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 26 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 26 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 26 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 26 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 26 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.94it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 26 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:42:06,230][__main__][INFO] - Epoch 26: Val Loss: 0.9861, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5939290794553952, 'f1_weighted': 0.709603618358178, 'precision_macro': 0.6122813990461049, 'recall_macro': 0.5875963020030817}
Epoch 27 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:42:06,598][__main__][INFO] - Train Epoch: 27 [0/13 (0%)]	Loss: 0.337446
Epoch 27 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 27 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:04,  2.74it/s]Epoch 27 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 27 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 27 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 27 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 27 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 27 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 27 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 27 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 27 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 27 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 27 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 27 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 27 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:42:11,826][__main__][INFO] - Epoch 27: Val Loss: 1.1148, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.524110671936759, 'f1_weighted': 0.6572378977028138, 'precision_macro': 0.5532835659417938, 'recall_macro': 0.5191063174114021}
Epoch 28 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:42:12,184][__main__][INFO] - Train Epoch: 28 [0/13 (0%)]	Loss: 0.525524
Epoch 28 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 28 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 28 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 28 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 28 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 28 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 28 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 28 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 28 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 28 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 28 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 28 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 28 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 28 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.94it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 28 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:42:17,406][__main__][INFO] - Epoch 28: Val Loss: 1.1662, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.606578947368421, 'f1_weighted': 0.7254299114121938, 'precision_macro': 0.6197447447447447, 'recall_macro': 0.6043335901386749}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703121b70>
<numpy.flatiter object at 0x7f3703121b70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702644710>
<numpy.flatiter object at 0x7f3702644710>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702644710>
<numpy.flatiter object at 0x7f3702644710>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702644d10>
<numpy.flatiter object at 0x7f3702644d10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702644d10>
<numpy.flatiter object at 0x7f3702644d10>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:42:17,473][__main__][INFO] - Saved best model at epoch 28 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:42:17,574][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 29 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:42:17,963][__main__][INFO] - Train Epoch: 29 [0/13 (0%)]	Loss: 0.747223
Epoch 29 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 29 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 29 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 29 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 29 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 29 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 29 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 29 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 29 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 29 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 29 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 29 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 29 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 29 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 29 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:42:23,188][__main__][INFO] - Epoch 29: Val Loss: 1.0046, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6043859649122807, 'f1_weighted': 0.7203057147820046, 'precision_macro': 0.6189117199391172, 'recall_macro': 0.6000963020030817}
Epoch 30 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:42:23,549][__main__][INFO] - Train Epoch: 30 [0/13 (0%)]	Loss: 0.654603
Epoch 30 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 30 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 30 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 30 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 30 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 30 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 30 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 30 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 30 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 30 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 30 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 30 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 30 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 30 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 30 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:42:28,770][__main__][INFO] - Epoch 30: Val Loss: 1.0002, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.6337728243978245, 'f1_weighted': 0.6821550424273196, 'precision_macro': 0.6682876510462716, 'recall_macro': 0.6398497688751926}
[2025-05-30 15:42:28,773][__main__][INFO] - Early stopping triggered after 30 epochs
[2025-05-30 15:42:28,774][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7723
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38101872e0>
<numpy.flatiter object at 0x7f38101872e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3810131240>
<numpy.flatiter object at 0x7f3810131240>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3810131240>
<numpy.flatiter object at 0x7f3810131240>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3810131840>
<numpy.flatiter object at 0x7f3810131840>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3810131840>
<numpy.flatiter object at 0x7f3810131840>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá
wandb:            Validation Loss ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     Validation f1_weighted ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb: Validation precision_macro ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.77228
wandb:                 Train Loss 0.6546
wandb:        Validation Accuracy 0.67327
wandb:            Validation Loss 1.00017
wandb:        Validation accuracy 0.67327
wandb:        Validation f1_macro 0.63377
wandb:     Validation f1_weighted 0.68216
wandb: Validation precision_macro 0.66829
wandb:    Validation recall_macro 0.63985
wandb: 
wandb: üöÄ View run unique-sweep-12 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/x236w1h7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 11 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_153928-x236w1h7/logs
wandb: Agent Starting Run: 02mjwd8x with config:
wandb: 	Fdropout_rate: 0.19800969731436124
wandb: 	Fnum_heads: 4
wandb: 	Fnum_layers: 8
wandb: 	Mdropout_rate: 0.10831573572924472
wandb: 	Mnum_layers: 2
wandb: 	batch_size: 256
wandb: 	learning_rate: 0.01841399084141004
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_154236-02mjwd8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/02mjwd8x
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:42:43,353][__main__][INFO] - Train Epoch: 0 [0/2 (0%)]	Loss: 1.477957
Epoch 0 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.03s/it]                                                              Epoch 0 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:42:45,925][__main__][INFO] - Epoch 0: Val Loss: 81.5808, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374873ce00>
<numpy.flatiter object at 0x7f374873ce00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370241c3f0>
<numpy.flatiter object at 0x7f370241c3f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370241c3f0>
<numpy.flatiter object at 0x7f370241c3f0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370241c9f0>
<numpy.flatiter object at 0x7f370241c9f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370241c9f0>
<numpy.flatiter object at 0x7f370241c9f0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:42:45,996][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.1980
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:42:46,107][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:42:46,142][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:42:48,834][__main__][INFO] - Train Epoch: 1 [0/2 (0%)]	Loss: 78.608337
Epoch 1 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.69s/it]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.02s/it]                                                              Epoch 1 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:42:51,408][__main__][INFO] - Epoch 1: Val Loss: 28.1292, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:42:54,121][__main__][INFO] - Train Epoch: 2 [0/2 (0%)]	Loss: 28.994570
Epoch 2 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.71s/it]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.03s/it]                                                              Epoch 2 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:42:56,706][__main__][INFO] - Epoch 2: Val Loss: 25.9597, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63a2e00>
<numpy.flatiter object at 0x7f36f63a2e00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703602660>
<numpy.flatiter object at 0x7f3703602660>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703602660>
<numpy.flatiter object at 0x7f3703602660>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703602c60>
<numpy.flatiter object at 0x7f3703602c60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703602c60>
<numpy.flatiter object at 0x7f3703602c60>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:42:56,766][__main__][INFO] - Saved best model at epoch 2 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:42:56,866][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 3 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:42:59,597][__main__][INFO] - Train Epoch: 3 [0/2 (0%)]	Loss: 26.658897
Epoch 3 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.70s/it]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.03s/it]                                                              Epoch 3 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:02,187][__main__][INFO] - Epoch 3: Val Loss: 18.6902, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:04,913][__main__][INFO] - Train Epoch: 4 [0/2 (0%)]	Loss: 19.302034
Epoch 4 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.72s/it]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]                                                              Epoch 4 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:07,505][__main__][INFO] - Epoch 4: Val Loss: 13.1544, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:10,212][__main__][INFO] - Train Epoch: 5 [0/2 (0%)]	Loss: 13.395975
Epoch 5 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.70s/it]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.03s/it]                                                              Epoch 5 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:12,805][__main__][INFO] - Epoch 5: Val Loss: 13.2539, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:15,517][__main__][INFO] - Train Epoch: 6 [0/2 (0%)]	Loss: 13.274196
Epoch 6 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.71s/it]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]                                                              Epoch 6 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:18,122][__main__][INFO] - Epoch 6: Val Loss: 12.1316, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:20,832][__main__][INFO] - Train Epoch: 7 [0/2 (0%)]	Loss: 11.533054
Epoch 7 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.71s/it]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.03s/it]                                                              Epoch 7 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:23,432][__main__][INFO] - Epoch 7: Val Loss: 23.1242, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:26,145][__main__][INFO] - Train Epoch: 8 [0/2 (0%)]	Loss: 23.079140
Epoch 8 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.71s/it]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]                                                              Epoch 8 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:28,759][__main__][INFO] - Epoch 8: Val Loss: 10.5764, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:31,493][__main__][INFO] - Train Epoch: 9 [0/2 (0%)]	Loss: 10.211884
Epoch 9 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]                                                              Epoch 9 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:34,095][__main__][INFO] - Epoch 9: Val Loss: 10.9876, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:36,817][__main__][INFO] - Train Epoch: 10 [0/2 (0%)]	Loss: 12.279206
Epoch 10 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.72s/it]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]                                                               Epoch 10 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:39,418][__main__][INFO] - Epoch 10: Val Loss: 9.0069, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2404658597853391, 'f1_weighted': 0.4819898751692936, 'precision_macro': 0.23822463768115942, 'recall_macro': 0.27902542372881356}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f63fc690>
<numpy.flatiter object at 0x7f36f63fc690>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811a0fa10>
<numpy.flatiter object at 0x7f3811a0fa10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811a0fa10>
<numpy.flatiter object at 0x7f3811a0fa10>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748617f40>
<numpy.flatiter object at 0x7f3748617f40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748617f40>
<numpy.flatiter object at 0x7f3748617f40>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:43:39,492][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:43:39,586][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:43:39,617][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:42,342][__main__][INFO] - Train Epoch: 11 [0/2 (0%)]	Loss: 8.011172
Epoch 11 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.72s/it]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 11 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:44,960][__main__][INFO] - Epoch 11: Val Loss: 9.7662, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:47,681][__main__][INFO] - Train Epoch: 12 [0/2 (0%)]	Loss: 11.026655
Epoch 12 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.72s/it]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 12 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:50,299][__main__][INFO] - Epoch 12: Val Loss: 11.9625, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 13 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:53,034][__main__][INFO] - Train Epoch: 13 [0/2 (0%)]	Loss: 11.497398
Epoch 13 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.04s/it]                                                               Epoch 13 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:43:55,645][__main__][INFO] - Epoch 13: Val Loss: 8.4397, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 14 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:43:58,388][__main__][INFO] - Train Epoch: 14 [0/2 (0%)]	Loss: 7.559550
Epoch 14 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 14 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:01,009][__main__][INFO] - Epoch 14: Val Loss: 8.2156, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 15 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:03,742][__main__][INFO] - Train Epoch: 15 [0/2 (0%)]	Loss: 8.075186
Epoch 15 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 15 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:06,359][__main__][INFO] - Epoch 15: Val Loss: 7.0400, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 16 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:09,084][__main__][INFO] - Train Epoch: 16 [0/2 (0%)]	Loss: 7.059826
Epoch 16 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.72s/it]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.07s/it]                                                               Epoch 16 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:11,739][__main__][INFO] - Epoch 16: Val Loss: 5.6013, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 17 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:14,501][__main__][INFO] - Train Epoch: 17 [0/2 (0%)]	Loss: 5.664168
Epoch 17 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.76s/it]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 17 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:17,121][__main__][INFO] - Epoch 17: Val Loss: 3.6580, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 18 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:19,853][__main__][INFO] - Train Epoch: 18 [0/2 (0%)]	Loss: 3.665963
Epoch 18 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 18 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:22,484][__main__][INFO] - Epoch 18: Val Loss: 4.6478, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 19 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:25,223][__main__][INFO] - Train Epoch: 19 [0/2 (0%)]	Loss: 4.674521
Epoch 19 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 19 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:27,840][__main__][INFO] - Epoch 19: Val Loss: 4.1681, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 20 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:30,593][__main__][INFO] - Train Epoch: 20 [0/2 (0%)]	Loss: 4.027254
Epoch 20 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 20 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:33,210][__main__][INFO] - Epoch 20: Val Loss: 3.1280, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
[2025-05-30 15:44:33,212][__main__][INFO] - Saved model at epoch 20
Epoch 21 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:35,963][__main__][INFO] - Train Epoch: 21 [0/2 (0%)]	Loss: 3.090495
Epoch 21 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 21 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:38,596][__main__][INFO] - Epoch 21: Val Loss: 2.8780, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 22 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:41,332][__main__][INFO] - Train Epoch: 22 [0/2 (0%)]	Loss: 2.972544
Epoch 22 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 22 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:43,963][__main__][INFO] - Epoch 22: Val Loss: 1.3443, Accuracy: 0.2079, Metrics: {'accuracy': 0.2079207920792079, 'f1_macro': 0.0966375068343357, 'f1_weighted': 0.1014567285049992, 'precision_macro': 0.2151360544217687, 'recall_macro': 0.24597457627118643}
Epoch 23 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:46,716][__main__][INFO] - Train Epoch: 23 [0/2 (0%)]	Loss: 1.371366
Epoch 23 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 23 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:49,348][__main__][INFO] - Epoch 23: Val Loss: 2.0243, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 24 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:52,084][__main__][INFO] - Train Epoch: 24 [0/2 (0%)]	Loss: 2.070513
Epoch 24 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 24 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:44:54,707][__main__][INFO] - Epoch 24: Val Loss: 1.6841, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 25 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:44:57,458][__main__][INFO] - Train Epoch: 25 [0/2 (0%)]	Loss: 1.717587
Epoch 25 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 25 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:00,092][__main__][INFO] - Epoch 25: Val Loss: 1.1340, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.20934411500449235, 'f1_weighted': 0.45238540026509383, 'precision_macro': 0.39749999999999996, 'recall_macro': 0.2625}
Epoch 26 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:02,827][__main__][INFO] - Train Epoch: 26 [0/2 (0%)]	Loss: 1.079750
Epoch 26 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 26 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:05,445][__main__][INFO] - Epoch 26: Val Loss: 1.2058, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.31926323160843284, 'f1_weighted': 0.5181328393785862, 'precision_macro': 0.3142626321974148, 'recall_macro': 0.39192989214175655}
Epoch 27 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:08,195][__main__][INFO] - Train Epoch: 27 [0/2 (0%)]	Loss: 1.117342
Epoch 27 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 27 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:10,828][__main__][INFO] - Epoch 27: Val Loss: 1.2312, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.3002565790584224, 'f1_weighted': 0.5288259519221786, 'precision_macro': 0.3806818181818182, 'recall_macro': 0.3184899845916795}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37492f5f80>
<numpy.flatiter object at 0x7f37492f5f80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811a28220>
<numpy.flatiter object at 0x7f3811a28220>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811a28220>
<numpy.flatiter object at 0x7f3811a28220>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f442f830>
<numpy.flatiter object at 0x7f36f442f830>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f442f830>
<numpy.flatiter object at 0x7f36f442f830>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:45:10,887][__main__][INFO] - Saved best model at epoch 27 with accuracy: 0.6238
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:45:10,995][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 28 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:13,774][__main__][INFO] - Train Epoch: 28 [0/2 (0%)]	Loss: 1.243591
Epoch 28 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 28 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:16,392][__main__][INFO] - Epoch 28: Val Loss: 1.1027, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2730364873222016, 'f1_weighted': 0.5209745464342352, 'precision_macro': 0.26092657342657344, 'recall_macro': 0.3082627118644068}
Epoch 29 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:19,141][__main__][INFO] - Train Epoch: 29 [0/2 (0%)]	Loss: 1.063239
Epoch 29 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 29 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:45:21,769][__main__][INFO] - Epoch 29: Val Loss: 1.1024, Accuracy: 0.4257, Metrics: {'accuracy': 0.42574257425742573, 'f1_macro': 0.30496318323421123, 'f1_weighted': 0.4259985811665279, 'precision_macro': 0.28670753588516745, 'recall_macro': 0.3671032357473035}
Epoch 30 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:24,524][__main__][INFO] - Train Epoch: 30 [0/2 (0%)]	Loss: 1.026737
Epoch 30 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 30 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:27,152][__main__][INFO] - Epoch 30: Val Loss: 1.0601, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2094361334867664, 'f1_weighted': 0.454272009479429, 'precision_macro': 0.273989898989899, 'recall_macro': 0.2625}
[2025-05-30 15:45:27,153][__main__][INFO] - Saved model at epoch 30
Epoch 31 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:29,899][__main__][INFO] - Train Epoch: 31 [0/2 (0%)]	Loss: 0.960853
Epoch 31 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 31 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:45:32,535][__main__][INFO] - Epoch 31: Val Loss: 0.9537, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.3182831661092531, 'f1_weighted': 0.524366148989481, 'precision_macro': 0.27721518987341776, 'recall_macro': 0.3736517719568567}
Epoch 32 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:35,288][__main__][INFO] - Train Epoch: 32 [0/2 (0%)]	Loss: 0.813557
Epoch 32 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 32 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:37,906][__main__][INFO] - Epoch 32: Val Loss: 0.9515, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2796515937731653, 'f1_weighted': 0.5315048183839881, 'precision_macro': 0.25502008032128515, 'recall_macro': 0.31652542372881354}
Epoch 33 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:40,658][__main__][INFO] - Train Epoch: 33 [0/2 (0%)]	Loss: 0.783136
Epoch 33 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 33 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:45:43,279][__main__][INFO] - Epoch 33: Val Loss: 0.9814, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.33151939655172413, 'f1_weighted': 0.5335332024581769, 'precision_macro': 0.3256038647342995, 'recall_macro': 0.36300077041602463}
Epoch 34 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:46,032][__main__][INFO] - Train Epoch: 34 [0/2 (0%)]	Loss: 0.840674
Epoch 34 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 34 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:48,650][__main__][INFO] - Epoch 34: Val Loss: 0.9952, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2796515937731653, 'f1_weighted': 0.5315048183839881, 'precision_macro': 0.25502008032128515, 'recall_macro': 0.31652542372881354}
Epoch 35 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:51,402][__main__][INFO] - Train Epoch: 35 [0/2 (0%)]	Loss: 0.809835
Epoch 35 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 35 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:54,032][__main__][INFO] - Epoch 35: Val Loss: 0.8999, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.33861283643892337, 'f1_weighted': 0.5459524834471025, 'precision_macro': 0.329000904159132, 'recall_macro': 0.375924499229584}
Epoch 36 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:45:56,786][__main__][INFO] - Train Epoch: 36 [0/2 (0%)]	Loss: 0.702435
Epoch 36 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 36 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:45:59,403][__main__][INFO] - Epoch 36: Val Loss: 0.9654, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.2989998245306194, 'f1_weighted': 0.5479648157832101, 'precision_macro': 0.2702380952380952, 'recall_macro': 0.33728813559322035}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f783ffb0>
<numpy.flatiter object at 0x7f36f783ffb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030edc00>
<numpy.flatiter object at 0x7f37030edc00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030edc00>
<numpy.flatiter object at 0x7f37030edc00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702abfe80>
<numpy.flatiter object at 0x7f3702abfe80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702abfe80>
<numpy.flatiter object at 0x7f3702abfe80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:45:59,461][__main__][INFO] - Saved best model at epoch 36 with accuracy: 0.6337
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:45:59,567][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 37 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:02,351][__main__][INFO] - Train Epoch: 37 [0/2 (0%)]	Loss: 0.665467
Epoch 37 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.75s/it]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 37 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:46:04,965][__main__][INFO] - Epoch 37: Val Loss: 0.9126, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.34338235294117647, 'f1_weighted': 0.5483983692486896, 'precision_macro': 0.33642344497607657, 'recall_macro': 0.40887904468412944}
Epoch 38 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:07,700][__main__][INFO] - Train Epoch: 38 [0/2 (0%)]	Loss: 0.708919
Epoch 38 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 38 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:10,325][__main__][INFO] - Epoch 38: Val Loss: 0.8855, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.35432131495228, 'f1_weighted': 0.5791869218735236, 'precision_macro': 0.5343580470162749, 'recall_macro': 0.37251540832049307}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703104c90>
<numpy.flatiter object at 0x7f3703104c90>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703104c90>
<numpy.flatiter object at 0x7f3703104c90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703104c90>
<numpy.flatiter object at 0x7f3703104c90>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703104c90>
<numpy.flatiter object at 0x7f3703104c90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703104c90>
<numpy.flatiter object at 0x7f3703104c90>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:46:10,386][__main__][INFO] - Saved best model at epoch 38 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:46:10,485][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 39 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:13,250][__main__][INFO] - Train Epoch: 39 [0/2 (0%)]	Loss: 0.615195
Epoch 39 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 39 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:15,867][__main__][INFO] - Epoch 39: Val Loss: 1.0658, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.2963306152705708, 'f1_weighted': 0.5501544965467636, 'precision_macro': 0.2719210174029451, 'recall_macro': 0.3332627118644068}
Epoch 40 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:18,600][__main__][INFO] - Train Epoch: 40 [0/2 (0%)]	Loss: 0.691667
Epoch 40 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 40 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:46:21,229][__main__][INFO] - Epoch 40: Val Loss: 0.9076, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.39692082111436955, 'f1_weighted': 0.569594378792718, 'precision_macro': 0.4102647352647353, 'recall_macro': 0.40225346687211094}
Epoch 41 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:23,968][__main__][INFO] - Train Epoch: 41 [0/2 (0%)]	Loss: 0.677413
Epoch 41 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 41 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:26,585][__main__][INFO] - Epoch 41: Val Loss: 0.9772, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.3854377104377104, 'f1_weighted': 0.6107977464413108, 'precision_macro': 0.5592105263157895, 'recall_macro': 0.41001540832049305}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f43e8b10>
<numpy.flatiter object at 0x7f36f43e8b10>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f442c900>
<numpy.flatiter object at 0x7f36f442c900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f442c900>
<numpy.flatiter object at 0x7f36f442c900>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811eb6340>
<numpy.flatiter object at 0x7f3811eb6340>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811eb6340>
<numpy.flatiter object at 0x7f3811eb6340>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:46:26,646][__main__][INFO] - Saved best model at epoch 41 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:46:26,739][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 42 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:29,498][__main__][INFO] - Train Epoch: 42 [0/2 (0%)]	Loss: 0.729822
Epoch 42 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 42 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:32,122][__main__][INFO] - Epoch 42: Val Loss: 1.5076, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.31004140786749484, 'f1_weighted': 0.5589652132915155, 'precision_macro': 0.279487917146145, 'recall_macro': 0.34978813559322036}
Epoch 43 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:34,869][__main__][INFO] - Train Epoch: 43 [0/2 (0%)]	Loss: 1.239814
Epoch 43 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 43 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 43 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:37,483][__main__][INFO] - Epoch 43: Val Loss: 1.4013, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3147920687839972, 'f1_weighted': 0.5660294753812984, 'precision_macro': 0.28526785714285713, 'recall_macro': 0.35402542372881357}
Epoch 44 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:40,230][__main__][INFO] - Train Epoch: 44 [0/2 (0%)]	Loss: 1.027433
Epoch 44 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 44 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 44 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 44 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:46:42,851][__main__][INFO] - Epoch 44: Val Loss: 1.1112, Accuracy: 0.4356, Metrics: {'accuracy': 0.43564356435643564, 'f1_macro': 0.36778182157521466, 'f1_weighted': 0.42778301346372044, 'precision_macro': 0.38861111111111113, 'recall_macro': 0.5090331278890601}
Epoch 45 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:45,597][__main__][INFO] - Train Epoch: 45 [0/2 (0%)]	Loss: 0.909168
Epoch 45 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 45 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 45 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 45 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:48,219][__main__][INFO] - Epoch 45: Val Loss: 1.1191, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3035714285714286, 'f1_weighted': 0.5548797736916549, 'precision_macro': 0.2759259259259259, 'recall_macro': 0.34152542372881356}
Epoch 46 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:50,951][__main__][INFO] - Train Epoch: 46 [0/2 (0%)]	Loss: 0.696218
Epoch 46 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.73s/it]Epoch 46 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 46 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 46 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             [2025-05-30 15:46:53,567][__main__][INFO] - Epoch 46: Val Loss: 1.0977, Accuracy: 0.4554, Metrics: {'accuracy': 0.45544554455445546, 'f1_macro': 0.4895833333333333, 'f1_weighted': 0.4933404054691183, 'precision_macro': 0.6110562865497076, 'recall_macro': 0.5261748844375963}
Epoch 47 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:46:56,315][__main__][INFO] - Train Epoch: 47 [0/2 (0%)]	Loss: 0.830439
Epoch 47 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.74s/it]Epoch 47 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.05s/it]                                                               Epoch 47 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 47 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:46:58,933][__main__][INFO] - Epoch 47: Val Loss: 1.0017, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.45034562211981566, 'f1_weighted': 0.6176712141260209, 'precision_macro': 0.4789562289562289, 'recall_macro': 0.4528890600924499}
Epoch 48 [Train]:   0%|          | 0/2 [00:00<?, ?it/s][2025-05-30 15:47:01,697][__main__][INFO] - Train Epoch: 48 [0/2 (0%)]	Loss: 0.634900
Epoch 48 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:02<00:02,  2.76s/it]Epoch 48 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.06s/it]                                                               Epoch 48 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 48 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:04,324][__main__][INFO] - Epoch 48: Val Loss: 0.8922, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3678411005053341, 'f1_weighted': 0.5624801952401867, 'precision_macro': 0.3657616892911011, 'recall_macro': 0.42137904468412946}
[2025-05-30 15:47:04,326][__main__][INFO] - Early stopping triggered after 48 epochs
[2025-05-30 15:47:04,326][__main__][INFO] - Saving best confusion matrix with accuracy: 0.6832
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37604102d0>
<numpy.flatiter object at 0x7f37604102d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37604102d0>
<numpy.flatiter object at 0x7f37604102d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37604102d0>
<numpy.flatiter object at 0x7f37604102d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37492be6d0>
<numpy.flatiter object at 0x7f37492be6d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492be6d0>
<numpy.flatiter object at 0x7f37492be6d0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÇ‚ñÅ‚ñá‚ñá‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÅ‚ñá‚ñá‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñà
wandb:            Validation Loss ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÇ‚ñÅ‚ñá‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÅ‚ñá‚ñÇ‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÇ‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñà
wandb:        Validation f1_macro ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ
wandb:     Validation f1_weighted ‚ñÇ‚ñÅ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÖ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÉ‚ñà‚ñÖ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.68317
wandb:                 Train Loss 0.6349
wandb:        Validation Accuracy 0.64356
wandb:            Validation Loss 0.89223
wandb:        Validation accuracy 0.64356
wandb:        Validation f1_macro 0.36784
wandb:     Validation f1_weighted 0.56248
wandb: Validation precision_macro 0.36576
wandb:    Validation recall_macro 0.42138
wandb: 
wandb: üöÄ View run graceful-sweep-13 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/02mjwd8x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 7 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_154236-02mjwd8x/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ouxoqgpq with config:
wandb: 	Fdropout_rate: 0.3947608681353531
wandb: 	Fnum_heads: 4
wandb: 	Fnum_layers: 5
wandb: 	Mdropout_rate: 0.1440601892110598
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 32
wandb: 	learning_rate: 0.020804742304433303
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_154718-ouxoqgpq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/ouxoqgpq
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:22,589][__main__][INFO] - Train Epoch: 0 [0/13 (0%)]	Loss: 1.848401
Epoch 0 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.75it/s]Epoch 0 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 0 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.87it/s]Epoch 0 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.87it/s]Epoch 0 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.87it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.88it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.88it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.25it/s]                                                                Epoch 0 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 0 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.03it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.03it/s]Epoch 0 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.03it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:27,698][__main__][INFO] - Epoch 0: Val Loss: 15.3727, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37031479e0>
<numpy.flatiter object at 0x7f37031479e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37031479e0>
<numpy.flatiter object at 0x7f37031479e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37031479e0>
<numpy.flatiter object at 0x7f37031479e0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37031479e0>
<numpy.flatiter object at 0x7f37031479e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37031479e0>
<numpy.flatiter object at 0x7f37031479e0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:47:28,022][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.1980
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:47:28,124][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:47:28,156][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:28,504][__main__][INFO] - Train Epoch: 1 [0/13 (0%)]	Loss: 14.129813
Epoch 1 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.88it/s]Epoch 1 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 1 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 1 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 1 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 1 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 1 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.01it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s]Epoch 1 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:33,642][__main__][INFO] - Epoch 1: Val Loss: 10.8244, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.18238993710691823, 'f1_weighted': 0.4261784669032941, 'precision_macro': 0.145, 'recall_macro': 0.2457627118644068}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f375b09e9c0>
<numpy.flatiter object at 0x7f375b09e9c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f6e2f0>
<numpy.flatiter object at 0x7f3811f6e2f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f6e2f0>
<numpy.flatiter object at 0x7f3811f6e2f0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f6e2f0>
<numpy.flatiter object at 0x7f3811f6e2f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f6e2f0>
<numpy.flatiter object at 0x7f3811f6e2f0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:47:33,707][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5743
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:47:33,803][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:34,188][__main__][INFO] - Train Epoch: 2 [0/13 (0%)]	Loss: 9.383139
Epoch 2 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 2 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 2 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.87it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.87it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.87it/s]Epoch 2 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.87it/s]Epoch 2 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                Epoch 2 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 2 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.00it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s]Epoch 2 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:39,316][__main__][INFO] - Epoch 2: Val Loss: 4.1126, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.3067908653846154, 'f1_weighted': 0.5386400418888043, 'precision_macro': 0.271286231884058, 'recall_macro': 0.3576271186440678}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f375b09e9c0>
<numpy.flatiter object at 0x7f375b09e9c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:47:39,384][__main__][INFO] - Saved best model at epoch 2 with accuracy: 0.6040
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:47:39,485][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 3 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:39,867][__main__][INFO] - Train Epoch: 3 [0/13 (0%)]	Loss: 4.422177
Epoch 3 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.87it/s]Epoch 3 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 3 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 3 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 3 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 3 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 3 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 3 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:45,021][__main__][INFO] - Epoch 3: Val Loss: 2.3358, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:45,382][__main__][INFO] - Train Epoch: 4 [0/13 (0%)]	Loss: 0.912376
Epoch 4 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 4 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 4 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.87it/s]Epoch 4 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.87it/s]Epoch 4 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 4 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 4 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 4 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:50,524][__main__][INFO] - Epoch 4: Val Loss: 1.6796, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2113289760348584, 'f1_weighted': 0.4651955391617593, 'precision_macro': 0.19262917933130697, 'recall_macro': 0.2625}
Epoch 5 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:50,881][__main__][INFO] - Train Epoch: 5 [0/13 (0%)]	Loss: 0.773933
Epoch 5 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 5 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 5 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 5 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 5 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 5 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 5 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:47:56,046][__main__][INFO] - Epoch 5: Val Loss: 2.7365, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:47:56,411][__main__][INFO] - Train Epoch: 6 [0/13 (0%)]	Loss: 1.256247
Epoch 6 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 6 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 6 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 6 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 6 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 6 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 6 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 6 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:01,598][__main__][INFO] - Epoch 6: Val Loss: 1.4563, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.3109112709832135, 'f1_weighted': 0.5314362371488948, 'precision_macro': 0.49375, 'recall_macro': 0.3265408320493066}
Epoch 7 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:01,962][__main__][INFO] - Train Epoch: 7 [0/13 (0%)]	Loss: 1.072140
Epoch 7 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 7 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 7 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 7 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 7 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 7 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 7 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 7 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:07,141][__main__][INFO] - Epoch 7: Val Loss: 2.2849, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18789808917197454, 'f1_weighted': 0.43904900044144546, 'precision_macro': 0.15051020408163265, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:07,496][__main__][INFO] - Train Epoch: 8 [0/13 (0%)]	Loss: 0.839497
Epoch 8 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 8 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 8 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 8 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 8 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                Epoch 8 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 8 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 8 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:12,699][__main__][INFO] - Epoch 8: Val Loss: 1.8046, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.35819131939821597, 'f1_weighted': 0.553393636527812, 'precision_macro': 0.499063670411985, 'recall_macro': 0.35568181818181815}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f375b09e9c0>
<numpy.flatiter object at 0x7f375b09e9c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:48:12,766][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.6436
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:48:12,868][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:13,255][__main__][INFO] - Train Epoch: 9 [0/13 (0%)]	Loss: 0.943218
Epoch 9 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 9 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 9 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 9 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 9 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                Epoch 9 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 9 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 9 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:18,451][__main__][INFO] - Epoch 9: Val Loss: 1.2444, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.3754559963520292, 'f1_weighted': 0.6005359085840184, 'precision_macro': 0.5513833992094862, 'recall_macro': 0.39751540832049304}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3810177eb0>
<numpy.flatiter object at 0x7f3748719340>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3810177eb0>
<numpy.flatiter object at 0x7f3748719340>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748719340>
<numpy.flatiter object at 0x7f3748719340>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748719340>
<numpy.flatiter object at 0x7f3748719340>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:48:18,515][__main__][INFO] - Saved best model at epoch 9 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:48:18,611][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 10 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:19,001][__main__][INFO] - Train Epoch: 10 [0/13 (0%)]	Loss: 0.496630
Epoch 10 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 10 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 10 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 10 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 10 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 10 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:24,202][__main__][INFO] - Epoch 10: Val Loss: 1.8545, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.420364238410596, 'f1_weighted': 0.5545144580683233, 'precision_macro': 0.41032608695652173, 'recall_macro': 0.4545454545454546}
Epoch 11 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:24,564][__main__][INFO] - Train Epoch: 11 [0/13 (0%)]	Loss: 0.598807
Epoch 11 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 11 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 11 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 11 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 11 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 11 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 11 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:29,776][__main__][INFO] - Epoch 11: Val Loss: 2.1369, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3680290297937357, 'f1_weighted': 0.524480179110348, 'precision_macro': 0.4052631578947369, 'recall_macro': 0.38636363636363635}
Epoch 12 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:30,145][__main__][INFO] - Train Epoch: 12 [0/13 (0%)]	Loss: 0.590486
Epoch 12 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 12 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 12 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 12 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 12 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 12 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 12 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.47it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.39it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:35,567][__main__][INFO] - Epoch 12: Val Loss: 1.6676, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.31041181041181043, 'f1_weighted': 0.5388500388500389, 'precision_macro': 0.49776785714285715, 'recall_macro': 0.3267526964560863}
Epoch 13 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:36,273][__main__][INFO] - Train Epoch: 13 [0/13 (0%)]	Loss: 0.447162
Epoch 13 [Train]:   8%|‚ñä         | 1/13 [00:00<00:08,  1.43it/s]Epoch 13 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:01<00:07,  1.43it/s]Epoch 13 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:02<00:06,  1.44it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:02<00:06,  1.44it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:03<00:05,  1.44it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:04<00:04,  1.44it/s]Epoch 13 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:04<00:04,  1.44it/s]Epoch 13 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:05<00:03,  1.44it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:06<00:02,  1.44it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:06<00:01,  1.67it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:06<00:01,  1.91it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:07<00:00,  2.12it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:07<00:00,  2.52it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 13 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 13 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:44,235][__main__][INFO] - Epoch 13: Val Loss: 1.6190, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4426850763807285, 'f1_weighted': 0.5730928086933252, 'precision_macro': 0.49625468164794007, 'recall_macro': 0.46280816640986133}
Epoch 14 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:44,594][__main__][INFO] - Train Epoch: 14 [0/13 (0%)]	Loss: 0.515442
Epoch 14 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 14 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 14 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 14 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 14 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.80it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.80it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.80it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 14 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 14 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:48:49,834][__main__][INFO] - Epoch 14: Val Loss: 1.3704, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.49220850941221667, 'f1_weighted': 0.6498504201169252, 'precision_macro': 0.5683760683760684, 'recall_macro': 0.475924499229584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381012fec0>
<numpy.flatiter object at 0x7f381012fec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37031479b0>
<numpy.flatiter object at 0x7f37031479b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37031479b0>
<numpy.flatiter object at 0x7f37031479b0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37485de3c0>
<numpy.flatiter object at 0x7f37485de3c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37485de3c0>
<numpy.flatiter object at 0x7f37485de3c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:48:49,896][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.7030
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:48:49,996][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:50,384][__main__][INFO] - Train Epoch: 15 [0/13 (0%)]	Loss: 0.841470
Epoch 15 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 15 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 15 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 15 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 15 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 15 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.93it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 15 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:48:55,612][__main__][INFO] - Epoch 15: Val Loss: 1.0306, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6054682159945318, 'f1_weighted': 0.7179334474800865, 'precision_macro': 0.6130835380835381, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3810189ef0>
<numpy.flatiter object at 0x7f37491ecec0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38119ee010>
<numpy.flatiter object at 0x7f38119ee010>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38119ee010>
<numpy.flatiter object at 0x7f38119ee010>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38119ee010>
<numpy.flatiter object at 0x7f38119ee010>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38119ee010>
<numpy.flatiter object at 0x7f38119ee010>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:48:55,675][__main__][INFO] - Saved best model at epoch 15 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:48:55,770][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 16 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:48:56,159][__main__][INFO] - Train Epoch: 16 [0/13 (0%)]	Loss: 0.400326
Epoch 16 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 16 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 16 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 16 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 16 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 16 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 16 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 16 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 16 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 16 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 16 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:49:01,380][__main__][INFO] - Epoch 16: Val Loss: 1.0547, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5939899516541852, 'f1_weighted': 0.7012968241558254, 'precision_macro': 0.6217948717948718, 'recall_macro': 0.5895608628659477}
Epoch 17 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:01,750][__main__][INFO] - Train Epoch: 17 [0/13 (0%)]	Loss: 0.326131
Epoch 17 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.73it/s]Epoch 17 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 17 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 17 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 17 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 17 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 17 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 17 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 17 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 17 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 17 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:49:06,972][__main__][INFO] - Epoch 17: Val Loss: 1.1055, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6359953703703703, 'f1_weighted': 0.7144297763109644, 'precision_macro': 0.743421052631579, 'recall_macro': 0.5955508474576271}
Epoch 18 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:07,339][__main__][INFO] - Train Epoch: 18 [0/13 (0%)]	Loss: 0.521252
Epoch 18 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 18 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:04,  2.74it/s]Epoch 18 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.74it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.77it/s]Epoch 18 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.78it/s]Epoch 18 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.79it/s]Epoch 18 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 18 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 18 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 18 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.80it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 18 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.93it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 18 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:49:12,591][__main__][INFO] - Epoch 18: Val Loss: 1.2509, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.6194700629483237, 'f1_weighted': 0.6701081702373135, 'precision_macro': 0.7073956294846706, 'recall_macro': 0.5967835130970724}
Epoch 19 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:12,957][__main__][INFO] - Train Epoch: 19 [0/13 (0%)]	Loss: 0.513356
Epoch 19 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 19 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 19 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 19 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 19 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 19 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 19 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 19 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.80it/s]Epoch 19 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.80it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 19 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 19 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:49:18,193][__main__][INFO] - Epoch 19: Val Loss: 1.0447, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.6104573026769823, 'f1_weighted': 0.6914610388793048, 'precision_macro': 0.6988014800514801, 'recall_macro': 0.5992681047765793}
Epoch 20 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:18,551][__main__][INFO] - Train Epoch: 20 [0/13 (0%)]	Loss: 0.526188
Epoch 20 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 20 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 20 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 20 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 20 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 20 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 20 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 20 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 20 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.80it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 20 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 20 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.94it/s]                                                             [2025-05-30 15:49:23,787][__main__][INFO] - Epoch 20: Val Loss: 1.1342, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5355392156862745, 'f1_weighted': 0.6672005435837701, 'precision_macro': 0.5848214285714286, 'recall_macro': 0.5171417565485362}
Epoch 21 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:24,154][__main__][INFO] - Train Epoch: 21 [0/13 (0%)]	Loss: 0.302647
Epoch 21 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 21 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:04,  2.75it/s]Epoch 21 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.77it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 21 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 21 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 21 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 21 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.80it/s]Epoch 21 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 21 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 21 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 21 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:49:29,393][__main__][INFO] - Epoch 21: Val Loss: 1.0788, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.574271499644634, 'f1_weighted': 0.6898111986038689, 'precision_macro': 0.6729166666666666, 'recall_macro': 0.5398690292758089}
Epoch 22 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:29,756][__main__][INFO] - Train Epoch: 22 [0/13 (0%)]	Loss: 0.411818
Epoch 22 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 22 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 22 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 22 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 22 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 22 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 22 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 22 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 22 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 22 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 22 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:49:34,992][__main__][INFO] - Epoch 22: Val Loss: 1.0149, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6196368446368447, 'f1_weighted': 0.7182256320870183, 'precision_macro': 0.7098515519568152, 'recall_macro': 0.5895608628659477}
Epoch 23 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:35,354][__main__][INFO] - Train Epoch: 23 [0/13 (0%)]	Loss: 0.360747
Epoch 23 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 23 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 23 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 23 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 23 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 23 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 23 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 23 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 23 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 23 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.94it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 23 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:49:40,579][__main__][INFO] - Epoch 23: Val Loss: 1.1393, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6057422969187676, 'f1_weighted': 0.7129267548603601, 'precision_macro': 0.6282467532467533, 'recall_macro': 0.6020608628659476}
Epoch 24 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:40,949][__main__][INFO] - Train Epoch: 24 [0/13 (0%)]	Loss: 0.424159
Epoch 24 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.72it/s]Epoch 24 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 24 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 24 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 24 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 24 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 24 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 24 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 24 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 24 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 24 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:49:46,169][__main__][INFO] - Epoch 24: Val Loss: 1.0974, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5830368906455863, 'f1_weighted': 0.7005974510494528, 'precision_macro': 0.6226874391431354, 'recall_macro': 0.5710708782742682}
Epoch 25 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:46,527][__main__][INFO] - Train Epoch: 25 [0/13 (0%)]	Loss: 0.538996
Epoch 25 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 25 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 25 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 25 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 25 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 25 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 25 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 25 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 25 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 25 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 25 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:49:51,748][__main__][INFO] - Epoch 25: Val Loss: 1.0557, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5706609712230216, 'f1_weighted': 0.6884998931547831, 'precision_macro': 0.615625, 'recall_macro': 0.5585708782742681}
Epoch 26 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:52,116][__main__][INFO] - Train Epoch: 26 [0/13 (0%)]	Loss: 0.341807
Epoch 26 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 26 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 26 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 26 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 26 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 26 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 26 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 26 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 26 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 26 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.85it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.91it/s]Epoch 26 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.93it/s]                                                             [2025-05-30 15:49:57,359][__main__][INFO] - Epoch 26: Val Loss: 1.0523, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5707115009746588, 'f1_weighted': 0.6973616659911606, 'precision_macro': 0.6060855263157895, 'recall_macro': 0.5566063174114022}
Epoch 27 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:49:57,725][__main__][INFO] - Train Epoch: 27 [0/13 (0%)]	Loss: 0.475194
Epoch 27 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 27 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 27 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 27 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 27 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 27 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 27 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 27 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 27 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.80it/s]Epoch 27 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 27 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 27 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 27 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 27 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.93it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s]Epoch 27 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:50:02,966][__main__][INFO] - Epoch 27: Val Loss: 1.0024, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5441783712754107, 'f1_weighted': 0.6539702098342666, 'precision_macro': 0.5910326086956521, 'recall_macro': 0.563828967642527}
Epoch 28 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:03,334][__main__][INFO] - Train Epoch: 28 [0/13 (0%)]	Loss: 0.398055
Epoch 28 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.74it/s]Epoch 28 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 28 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 28 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 28 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 28 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 28 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 28 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 28 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 28 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 28 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 28 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 28 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 28 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 28 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:50:08,560][__main__][INFO] - Epoch 28: Val Loss: 1.0205, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6280193236714976, 'f1_weighted': 0.7339886162529297, 'precision_macro': 0.6206478310502282, 'recall_macro': 0.6455508474576271}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748fba580>
<numpy.flatiter object at 0x7f36f63cd200>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811ee0bb0>
<numpy.flatiter object at 0x7f3811f84040>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3810074b20>
<numpy.flatiter object at 0x7f3702677b60>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811a06100>
<numpy.flatiter object at 0x7f37035fd540>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38101593f0>
<numpy.flatiter object at 0x7f3811a0e040>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:50:08,621][__main__][INFO] - Saved best model at epoch 28 with accuracy: 0.7822
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:50:08,725][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 29 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:09,114][__main__][INFO] - Train Epoch: 29 [0/13 (0%)]	Loss: 0.542756
Epoch 29 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 29 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 29 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 29 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 29 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 29 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 29 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 29 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 29 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 29 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 29 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 29 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 29 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 29 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 29 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:50:14,339][__main__][INFO] - Epoch 29: Val Loss: 1.0257, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.614279197080292, 'f1_weighted': 0.718761292187613, 'precision_macro': 0.641025641025641, 'recall_macro': 0.6165254237288136}
Epoch 30 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:14,698][__main__][INFO] - Train Epoch: 30 [0/13 (0%)]	Loss: 0.506178
Epoch 30 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 30 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 30 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 30 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 30 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 30 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 30 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 30 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 30 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 30 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 30 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 30 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 30 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 30 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 30 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:50:19,923][__main__][INFO] - Epoch 30: Val Loss: 1.0399, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6274859117490696, 'f1_weighted': 0.7004097041283076, 'precision_macro': 0.6756628787878788, 'recall_macro': 0.5951271186440679}
Epoch 31 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:20,289][__main__][INFO] - Train Epoch: 31 [0/13 (0%)]	Loss: 0.443138
Epoch 31 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 31 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 31 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 31 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 31 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 31 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 31 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 31 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 31 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 31 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 31 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 31 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 31 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 31 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 31 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:50:25,520][__main__][INFO] - Epoch 31: Val Loss: 1.1393, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5291525012141817, 'f1_weighted': 0.648931279723407, 'precision_macro': 0.5883534136546185, 'recall_macro': 0.5210708782742681}
Epoch 32 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:25,878][__main__][INFO] - Train Epoch: 32 [0/13 (0%)]	Loss: 0.566095
Epoch 32 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 32 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 32 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 32 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 32 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 32 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 32 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 32 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 32 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 32 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 32 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 32 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 32 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 32 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 32 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:50:31,112][__main__][INFO] - Epoch 32: Val Loss: 0.9462, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6092886167624945, 'f1_weighted': 0.6891367998476097, 'precision_macro': 0.6472308488612837, 'recall_macro': 0.586864406779661}
Epoch 33 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:31,479][__main__][INFO] - Train Epoch: 33 [0/13 (0%)]	Loss: 0.505905
Epoch 33 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.74it/s]Epoch 33 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 33 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 33 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 33 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 33 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 33 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 33 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 33 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 33 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 33 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 33 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 33 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 33 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 33 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:50:36,706][__main__][INFO] - Epoch 33: Val Loss: 0.9541, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6632497273718647, 'f1_weighted': 0.7418508481164365, 'precision_macro': 0.7208333333333333, 'recall_macro': 0.6515408320493066}
Epoch 34 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:37,070][__main__][INFO] - Train Epoch: 34 [0/13 (0%)]	Loss: 0.390676
Epoch 34 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 34 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 34 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 34 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 34 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.79it/s]Epoch 34 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 34 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 34 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 34 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 34 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 34 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 34 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 34 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 34 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 34 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:50:42,310][__main__][INFO] - Epoch 34: Val Loss: 1.1015, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.586231884057971, 'f1_weighted': 0.6886210360166451, 'precision_macro': 0.6272151898734177, 'recall_macro': 0.5872881355932204}
Epoch 35 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:42,676][__main__][INFO] - Train Epoch: 35 [0/13 (0%)]	Loss: 0.412690
Epoch 35 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 35 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 35 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 35 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 35 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 35 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 35 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 35 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 35 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 35 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 35 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 35 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 35 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 35 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.91it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s]Epoch 35 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:50:47,902][__main__][INFO] - Epoch 35: Val Loss: 1.0500, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5910364145658262, 'f1_weighted': 0.7012785312144659, 'precision_macro': 0.6103896103896104, 'recall_macro': 0.5895608628659477}
Epoch 36 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:48,268][__main__][INFO] - Train Epoch: 36 [0/13 (0%)]	Loss: 0.367671
Epoch 36 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 36 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 36 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.78it/s]Epoch 36 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 36 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 36 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 36 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 36 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 36 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 36 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 36 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 36 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 36 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 36 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 36 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:50:53,503][__main__][INFO] - Epoch 36: Val Loss: 1.0254, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.6590367965367965, 'f1_weighted': 0.6887510179589388, 'precision_macro': 0.6591320444261621, 'recall_macro': 0.6933551617873652}
Epoch 37 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:53,869][__main__][INFO] - Train Epoch: 37 [0/13 (0%)]	Loss: 0.460311
Epoch 37 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.75it/s]Epoch 37 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 37 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 37 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 37 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 37 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 37 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 37 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 37 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 37 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 37 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 37 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 37 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 37 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 37 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:50:59,096][__main__][INFO] - Epoch 37: Val Loss: 1.2528, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.4997252747252747, 'f1_weighted': 0.6389620280709389, 'precision_macro': 0.5628306878306879, 'recall_macro': 0.5312981510015409}
Epoch 38 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:50:59,464][__main__][INFO] - Train Epoch: 38 [0/13 (0%)]	Loss: 0.701550
Epoch 38 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 38 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 38 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 38 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 38 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 38 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 38 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 38 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 38 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 38 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 38 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 38 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 38 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 38 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s]Epoch 38 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:51:04,696][__main__][INFO] - Epoch 38: Val Loss: 1.1813, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5764383855732074, 'f1_weighted': 0.6920622032147397, 'precision_macro': 0.6080586080586081, 'recall_macro': 0.566833590138675}
Epoch 39 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:05,055][__main__][INFO] - Train Epoch: 39 [0/13 (0%)]	Loss: 0.400956
Epoch 39 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 39 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 39 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 39 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 39 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 39 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 39 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 39 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 39 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 39 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.80it/s]Epoch 39 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 39 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 39 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 39 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 39 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:51:10,281][__main__][INFO] - Epoch 39: Val Loss: 0.9582, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.6460788890185553, 'f1_weighted': 0.7133542622554938, 'precision_macro': 0.6578282828282829, 'recall_macro': 0.6386171032357474}
Epoch 40 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:10,642][__main__][INFO] - Train Epoch: 40 [0/13 (0%)]	Loss: 0.407487
Epoch 40 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 40 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 40 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 40 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 40 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 40 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 40 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 40 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 40 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 40 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 40 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 40 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 40 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 40 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 40 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:51:15,868][__main__][INFO] - Epoch 40: Val Loss: 0.9352, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.601059676217571, 'f1_weighted': 0.6722175950982621, 'precision_macro': 0.621045008912656, 'recall_macro': 0.5866525423728813}
[2025-05-30 15:51:15,869][__main__][INFO] - Saved model at epoch 40
Epoch 41 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:16,231][__main__][INFO] - Train Epoch: 41 [0/13 (0%)]	Loss: 0.363999
Epoch 41 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 41 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 41 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 41 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 41 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 41 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 41 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 41 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 41 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.80it/s]Epoch 41 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 41 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 41 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 41 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 41 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 41 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:51:21,461][__main__][INFO] - Epoch 41: Val Loss: 0.9513, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.6115546218487395, 'f1_weighted': 0.7026291704800733, 'precision_macro': 0.6580985915492957, 'recall_macro': 0.5851117103235748}
Epoch 42 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:21,820][__main__][INFO] - Train Epoch: 42 [0/13 (0%)]	Loss: 0.569792
Epoch 42 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 42 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 42 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 42 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 42 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.79it/s]Epoch 42 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 42 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 42 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 42 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 42 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.80it/s]Epoch 42 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 42 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 42 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 42 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 42 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 42 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:51:27,057][__main__][INFO] - Epoch 42: Val Loss: 1.1518, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5395198084411031, 'f1_weighted': 0.6609896846576355, 'precision_macro': 0.5777777777777778, 'recall_macro': 0.5520608628659476}
Epoch 43 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:27,418][__main__][INFO] - Train Epoch: 43 [0/13 (0%)]	Loss: 0.447156
Epoch 43 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 43 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 43 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 43 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 43 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.79it/s]Epoch 43 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.79it/s]Epoch 43 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 43 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 43 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 43 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 43 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 43 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 43 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 43 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 43 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 43 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:51:32,654][__main__][INFO] - Epoch 43: Val Loss: 1.2242, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.5961173860427592, 'f1_weighted': 0.7147168891959789, 'precision_macro': 0.6131372549019608, 'recall_macro': 0.5918335901386749}
Epoch 44 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:33,012][__main__][INFO] - Train Epoch: 44 [0/13 (0%)]	Loss: 0.234717
Epoch 44 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 44 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 44 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 44 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 44 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 44 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 44 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 44 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 44 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 44 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 44 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 44 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 44 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 44 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 44 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 44 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 44 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:51:38,238][__main__][INFO] - Epoch 44: Val Loss: 1.0373, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5628786681418261, 'f1_weighted': 0.6854368699079485, 'precision_macro': 0.5926857585139319, 'recall_macro': 0.552369029275809}
Epoch 45 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:38,607][__main__][INFO] - Train Epoch: 45 [0/13 (0%)]	Loss: 0.479914
Epoch 45 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.75it/s]Epoch 45 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:04,  2.75it/s]Epoch 45 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.76it/s]Epoch 45 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.78it/s]Epoch 45 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 45 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 45 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.80it/s]Epoch 45 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.80it/s]Epoch 45 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 45 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 45 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 45 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 45 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 45 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 45 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 45 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 45 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:51:43,844][__main__][INFO] - Epoch 45: Val Loss: 1.0666, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6143207282913166, 'f1_weighted': 0.7254000610145049, 'precision_macro': 0.6466033966033966, 'recall_macro': 0.6062981510015408}
Epoch 46 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:44,210][__main__][INFO] - Train Epoch: 46 [0/13 (0%)]	Loss: 0.321242
Epoch 46 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 46 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 46 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 46 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 46 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 46 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 46 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 46 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 46 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 46 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 46 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.82it/s]Epoch 46 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 46 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 46 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 46 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 46 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 46 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:51:49,432][__main__][INFO] - Epoch 46: Val Loss: 1.0359, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5877416223334595, 'f1_weighted': 0.6911246755749909, 'precision_macro': 0.6546546546546547, 'recall_macro': 0.5788135593220339}
Epoch 47 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:49,793][__main__][INFO] - Train Epoch: 47 [0/13 (0%)]	Loss: 0.400548
Epoch 47 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 47 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 47 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 47 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 47 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 47 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 47 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 47 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 47 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 47 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 47 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 47 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.80it/s]Epoch 47 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 47 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 47 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.94it/s]Epoch 47 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 47 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             [2025-05-30 15:51:55,031][__main__][INFO] - Epoch 47: Val Loss: 0.9969, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6307398432857992, 'f1_weighted': 0.7163910324856015, 'precision_macro': 0.6620553359683794, 'recall_macro': 0.6161016949152542}
Epoch 48 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:51:55,389][__main__][INFO] - Train Epoch: 48 [0/13 (0%)]	Loss: 0.341980
Epoch 48 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 48 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 48 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 48 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 48 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 48 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.81it/s]Epoch 48 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 48 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 48 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 48 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 48 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 48 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 48 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 48 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 48 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 48 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 48 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:00,622][__main__][INFO] - Epoch 48: Val Loss: 1.1495, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5880252100840336, 'f1_weighted': 0.7035610283717447, 'precision_macro': 0.6151515151515151, 'recall_macro': 0.5793335901386749}
Epoch 49 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:00,986][__main__][INFO] - Train Epoch: 49 [0/13 (0%)]	Loss: 0.521245
Epoch 49 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 49 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.77it/s]Epoch 49 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 49 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.79it/s]Epoch 49 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.80it/s]Epoch 49 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.80it/s]Epoch 49 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.81it/s]Epoch 49 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.81it/s]Epoch 49 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 49 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 49 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 49 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 49 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.17it/s]                                                                 Epoch 49 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 49 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.94it/s]Epoch 49 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.95it/s]Epoch 49 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.95it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:06,221][__main__][INFO] - Epoch 49: Val Loss: 1.1880, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5336645962732919, 'f1_weighted': 0.6632728614476355, 'precision_macro': 0.5643083182640144, 'recall_macro': 0.5665254237288135}
Epoch 50 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:06,586][__main__][INFO] - Train Epoch: 50 [0/13 (0%)]	Loss: 0.424312
Epoch 50 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 50 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 50 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 50 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 50 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 50 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 50 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 50 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 50 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.81it/s]Epoch 50 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.81it/s]Epoch 50 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.81it/s]Epoch 50 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.81it/s]Epoch 50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.18it/s]                                                                 Epoch 50 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 50 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 50 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 50 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:52:11,808][__main__][INFO] - Epoch 50: Val Loss: 0.9947, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6297472639596491, 'f1_weighted': 0.7215474446064707, 'precision_macro': 0.7622377622377623, 'recall_macro': 0.6040254237288135}
[2025-05-30 15:52:11,809][__main__][INFO] - Early stopping triggered after 50 epochs
[2025-05-30 15:52:11,810][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7822
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3748fc6ed0>
<numpy.flatiter object at 0x7f3748ff91b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811ee0bb0>
<numpy.flatiter object at 0x7f36f48d0ed0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374870ef80>
<numpy.flatiter object at 0x7f38117ae910>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702f11c80>
<numpy.flatiter object at 0x7f370269e6b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f8e490>
<numpy.flatiter object at 0x7f3811f30c20>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà
wandb:            Validation Loss ‚ñà‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:     Validation f1_weighted ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: Validation precision_macro ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.78218
wandb:                 Train Loss 0.42431
wandb:        Validation Accuracy 0.76238
wandb:            Validation Loss 0.99473
wandb:        Validation accuracy 0.76238
wandb:        Validation f1_macro 0.62975
wandb:     Validation f1_weighted 0.72155
wandb: Validation precision_macro 0.76224
wandb:    Validation recall_macro 0.60403
wandb: 
wandb: üöÄ View run driven-sweep-14 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/ouxoqgpq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_154718-ouxoqgpq/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8rj38qpp with config:
wandb: 	Fdropout_rate: 0.2698484402276188
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 3
wandb: 	Mdropout_rate: 0.1717213226300887
wandb: 	Mnum_layers: 4
wandb: 	batch_size: 32
wandb: 	learning_rate: 0.026278449649867645
wandb: 	pretrained_model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_155226-8rj38qpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/8rj38qpp
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:29,764][__main__][INFO] - Train Epoch: 0 [0/13 (0%)]	Loss: 1.493100
Epoch 0 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 0 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 0 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.89it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.90it/s]Epoch 0 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.90it/s]Epoch 0 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.90it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.90it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.90it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.90it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.90it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.28it/s]                                                                Epoch 0 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 0 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.04it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s]Epoch 0 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.04it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:34,835][__main__][INFO] - Epoch 0: Val Loss: 26.8265, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3760416a00>
<numpy.flatiter object at 0x7f3760416a00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37486e3c00>
<numpy.flatiter object at 0x7f37486e3c00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486e3c00>
<numpy.flatiter object at 0x7f37486e3c00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38117bc270>
<numpy.flatiter object at 0x7f38117bc270>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38117bc270>
<numpy.flatiter object at 0x7f38117bc270>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:52:34,896][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:52:35,014][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:52:35,045][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:35,389][__main__][INFO] - Train Epoch: 1 [0/13 (0%)]	Loss: 24.225735
Epoch 1 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.92it/s]Epoch 1 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 1 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.88it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.89it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.89it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.89it/s]Epoch 1 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.90it/s]Epoch 1 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.90it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.90it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.90it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.90it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.90it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.28it/s]                                                                Epoch 1 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 1 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.03it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s]Epoch 1 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.04it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:40,466][__main__][INFO] - Epoch 1: Val Loss: 7.9481, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:40,825][__main__][INFO] - Train Epoch: 2 [0/13 (0%)]	Loss: 6.516138
Epoch 2 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 2 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.86it/s]Epoch 2 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.87it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.88it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.88it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.89it/s]Epoch 2 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.89it/s]Epoch 2 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.89it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.89it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.89it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.89it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.89it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.26it/s]                                                                Epoch 2 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 2 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.02it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s]Epoch 2 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:45,913][__main__][INFO] - Epoch 2: Val Loss: 4.1874, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:46,269][__main__][INFO] - Train Epoch: 3 [0/13 (0%)]	Loss: 2.197510
Epoch 3 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 3 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 3 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.88it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.88it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.89it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.89it/s]Epoch 3 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.88it/s]Epoch 3 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.88it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.89it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.89it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.89it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.89it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.26it/s]                                                                Epoch 3 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 3 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.01it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.04it/s]Epoch 3 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.03it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:51,357][__main__][INFO] - Epoch 3: Val Loss: 2.1893, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.30230769230769233, 'f1_weighted': 0.5364813404417365, 'precision_macro': 0.2677230046948357, 'recall_macro': 0.349364406779661}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370313d460>
<numpy.flatiter object at 0x7f37030b1920>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370309ffd0>
<numpy.flatiter object at 0x7f3811ed1d10>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f48c6d10>
<numpy.flatiter object at 0x7f3748dc5a50>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3749306f90>
<numpy.flatiter object at 0x7f374871aa50>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702661350>
<numpy.flatiter object at 0x7f37487c7b50>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:52:51,415][__main__][INFO] - Saved best model at epoch 3 with accuracy: 0.6040
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:52:51,511][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 4 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:51,894][__main__][INFO] - Train Epoch: 4 [0/13 (0%)]	Loss: 1.106316
Epoch 4 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.87it/s]Epoch 4 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 4 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.87it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.88it/s]Epoch 4 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.88it/s]Epoch 4 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.88it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.88it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.88it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.88it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.88it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.26it/s]                                                                Epoch 4 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 4 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.02it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.02it/s]Epoch 4 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:52:57,001][__main__][INFO] - Epoch 4: Val Loss: 3.0366, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18789808917197454, 'f1_weighted': 0.43904900044144546, 'precision_macro': 0.15051020408163265, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:52:57,360][__main__][INFO] - Train Epoch: 5 [0/13 (0%)]	Loss: 1.542780
Epoch 5 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 5 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.85it/s]Epoch 5 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.86it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.87it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.88it/s]Epoch 5 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.88it/s]Epoch 5 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.88it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.88it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.87it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.88it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.87it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.25it/s]                                                                Epoch 5 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:00,  3.01it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.01it/s]Epoch 5 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:02,473][__main__][INFO] - Epoch 5: Val Loss: 2.2772, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.2748768472906404, 'f1_weighted': 0.5319611764132078, 'precision_macro': 0.2548449612403101, 'recall_macro': 0.3125}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37031260b0>
<numpy.flatiter object at 0x7f37031260b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702648910>
<numpy.flatiter object at 0x7f37030e6fd0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035fc330>
<numpy.flatiter object at 0x7f3749306f90>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37487c7b50>
<numpy.flatiter object at 0x7f3702648910>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030e6fd0>
<numpy.flatiter object at 0x7f37035fc330>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:53:02,613][__main__][INFO] - Saved best model at epoch 5 with accuracy: 0.6337
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:53:02,763][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 6 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:03,155][__main__][INFO] - Train Epoch: 6 [0/13 (0%)]	Loss: 1.485110
Epoch 6 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.88it/s]Epoch 6 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 6 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.87it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.87it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.87it/s]Epoch 6 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.87it/s]Epoch 6 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.87it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.87it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.25it/s]                                                                Epoch 6 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 6 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 6 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:08,280][__main__][INFO] - Epoch 6: Val Loss: 1.5739, Accuracy: 0.5644, Metrics: {'accuracy': 0.5643564356435643, 'f1_macro': 0.31114477040816324, 'f1_weighted': 0.5172920034350373, 'precision_macro': 0.33120939530234883, 'recall_macro': 0.3343798151001541}
Epoch 7 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:08,630][__main__][INFO] - Train Epoch: 7 [0/13 (0%)]	Loss: 0.508423
Epoch 7 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.87it/s]Epoch 7 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 7 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.87it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.87it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.87it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.87it/s]Epoch 7 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.87it/s]Epoch 7 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.87it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.87it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.87it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 7 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 7 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 7 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:13,759][__main__][INFO] - Epoch 7: Val Loss: 2.2018, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.30550712002324903, 'f1_weighted': 0.5350016257074706, 'precision_macro': 0.5066394279877426, 'recall_macro': 0.3227272727272727}
Epoch 8 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:14,120][__main__][INFO] - Train Epoch: 8 [0/13 (0%)]	Loss: 1.054821
Epoch 8 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 8 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 8 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 8 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 8 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 8 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 8 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 8 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:19,261][__main__][INFO] - Epoch 8: Val Loss: 0.9789, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.4975952746690074, 'f1_weighted': 0.6622600706416922, 'precision_macro': 0.5040356195528609, 'recall_macro': 0.5172380585516179}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486d8d30>
<numpy.flatiter object at 0x7f37486d8d30>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f75840>
<numpy.flatiter object at 0x7f36f61a8840>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f75840>
<numpy.flatiter object at 0x7f36f61a8840>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f61a8840>
<numpy.flatiter object at 0x7f36f61a8840>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f61a8840>
<numpy.flatiter object at 0x7f36f61a8840>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:53:19,328][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.7030
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:53:19,424][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:19,805][__main__][INFO] - Train Epoch: 9 [0/13 (0%)]	Loss: 0.706844
Epoch 9 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.87it/s]Epoch 9 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.87it/s]Epoch 9 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.86it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 9 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 9 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                Epoch 9 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 9 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 9 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:00<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:24,942][__main__][INFO] - Epoch 9: Val Loss: 2.2111, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.29280948851000743, 'f1_weighted': 0.5419269132250512, 'precision_macro': 0.26890896921017404, 'recall_macro': 0.32902542372881355}
Epoch 10 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:25,303][__main__][INFO] - Train Epoch: 10 [0/13 (0%)]	Loss: 0.933989
Epoch 10 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 10 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 10 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 10 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 10 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.87it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 10 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                             [2025-05-30 15:53:30,441][__main__][INFO] - Epoch 10: Val Loss: 1.0225, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5139287422285987, 'f1_weighted': 0.6764374428834563, 'precision_macro': 0.5514514024787998, 'recall_macro': 0.5091872110939908}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703173a00>
<numpy.flatiter object at 0x7f3703173a00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3753c54080>
<numpy.flatiter object at 0x7f3753c54080>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3753c54080>
<numpy.flatiter object at 0x7f3753c54080>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3812597ff0>
<numpy.flatiter object at 0x7f3812597ff0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812597ff0>
<numpy.flatiter object at 0x7f3812597ff0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:53:30,503][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:53:30,604][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 11 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:30,996][__main__][INFO] - Train Epoch: 11 [0/13 (0%)]	Loss: 0.536803
Epoch 11 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 11 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 11 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 11 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 11 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 11 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 11 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:36,135][__main__][INFO] - Epoch 11: Val Loss: 1.5232, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.46726087172112857, 'f1_weighted': 0.6546608099596095, 'precision_macro': 0.5779710144927537, 'recall_macro': 0.4679699537750385}
Epoch 12 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:36,487][__main__][INFO] - Train Epoch: 12 [0/13 (0%)]	Loss: 0.693974
Epoch 12 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 12 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 12 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 12 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 12 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 12 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 12 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:41,650][__main__][INFO] - Epoch 12: Val Loss: 1.2460, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.350259571706684, 'f1_weighted': 0.6001760461575034, 'precision_macro': 0.31166666666666665, 'recall_macro': 0.39978813559322035}
Epoch 13 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:42,010][__main__][INFO] - Train Epoch: 13 [0/13 (0%)]	Loss: 0.882911
Epoch 13 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 13 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 13 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 13 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 13 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 13 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 13 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:47,169][__main__][INFO] - Epoch 13: Val Loss: 1.7038, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.34074074074074073, 'f1_weighted': 0.5902456912357902, 'precision_macro': 0.3042105263157895, 'recall_macro': 0.38728813559322034}
Epoch 14 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:47,531][__main__][INFO] - Train Epoch: 14 [0/13 (0%)]	Loss: 0.759593
Epoch 14 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 14 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 14 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 14 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 14 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 14 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 14 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:52,706][__main__][INFO] - Epoch 14: Val Loss: 1.2856, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.42041847041847036, 'f1_weighted': 0.6234766333776235, 'precision_macro': 0.48159817351598166, 'recall_macro': 0.4367681047765794}
Epoch 15 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:53,063][__main__][INFO] - Train Epoch: 15 [0/13 (0%)]	Loss: 0.969116
Epoch 15 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 15 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 15 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 15 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 15 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 15 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.92it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 15 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:53:58,241][__main__][INFO] - Epoch 15: Val Loss: 1.6643, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.33, 'f1_weighted': 0.5702970297029704, 'precision_macro': 0.29143192488262915, 'recall_macro': 0.38283898305084746}
Epoch 16 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:53:58,603][__main__][INFO] - Train Epoch: 16 [0/13 (0%)]	Loss: 0.524262
Epoch 16 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 16 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 16 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 16 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 16 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 16 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 16 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 16 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 16 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 16 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 16 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:03,785][__main__][INFO] - Epoch 16: Val Loss: 1.3008, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.42542602325211026, 'f1_weighted': 0.6121694348125688, 'precision_macro': 0.5456362425049966, 'recall_macro': 0.41796995377503854}
Epoch 17 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:04,148][__main__][INFO] - Train Epoch: 17 [0/13 (0%)]	Loss: 0.789025
Epoch 17 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.77it/s]Epoch 17 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 17 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 17 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 17 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 17 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 17 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 17 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 17 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 17 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 17 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:09,314][__main__][INFO] - Epoch 17: Val Loss: 1.2348, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.4029466396487673, 'f1_weighted': 0.5876961556338005, 'precision_macro': 0.5301067073170732, 'recall_macro': 0.3929699537750385}
Epoch 18 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:09,674][__main__][INFO] - Train Epoch: 18 [0/13 (0%)]	Loss: 0.426497
Epoch 18 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 18 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 18 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 18 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 18 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 18 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 18 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 18 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 18 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 18 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 18 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:54:14,853][__main__][INFO] - Epoch 18: Val Loss: 0.9489, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.5971532091097308, 'f1_weighted': 0.7172888096263044, 'precision_macro': 0.5966894977168951, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374864a200>
<numpy.flatiter object at 0x7f374864a200>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f48e94b0>
<numpy.flatiter object at 0x7f36f48e94b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f48e94b0>
<numpy.flatiter object at 0x7f36f48e94b0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f48e9ab0>
<numpy.flatiter object at 0x7f36f48e9ab0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f48e9ab0>
<numpy.flatiter object at 0x7f36f48e9ab0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:54:14,916][__main__][INFO] - Saved best model at epoch 18 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:54:15,016][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 19 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:15,401][__main__][INFO] - Train Epoch: 19 [0/13 (0%)]	Loss: 0.383147
Epoch 19 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 19 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 19 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 19 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 19 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 19 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 19 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 19 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 19 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 19 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 19 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:54:20,574][__main__][INFO] - Epoch 19: Val Loss: 0.9356, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4703703703703703, 'f1_weighted': 0.6378494259682379, 'precision_macro': 0.625, 'recall_macro': 0.448959938366718}
Epoch 20 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:20,936][__main__][INFO] - Train Epoch: 20 [0/13 (0%)]	Loss: 0.465228
Epoch 20 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 20 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 20 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 20 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 20 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 20 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 20 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 20 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 20 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 20 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.90it/s]Epoch 20 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.93it/s]                                                             [2025-05-30 15:54:26,124][__main__][INFO] - Epoch 20: Val Loss: 1.1091, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5075825322304196, 'f1_weighted': 0.6356651090997765, 'precision_macro': 0.5752581755593804, 'recall_macro': 0.5085708782742682}
Epoch 21 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:26,486][__main__][INFO] - Train Epoch: 21 [0/13 (0%)]	Loss: 0.375393
Epoch 21 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 21 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 21 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 21 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 21 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 21 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 21 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 21 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 21 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 21 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 21 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:31,658][__main__][INFO] - Epoch 21: Val Loss: 1.0372, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5489754460342695, 'f1_weighted': 0.6835216113026247, 'precision_macro': 0.5935828877005348, 'recall_macro': 0.5338790446841294}
Epoch 22 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:32,023][__main__][INFO] - Train Epoch: 22 [0/13 (0%)]	Loss: 0.365402
Epoch 22 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 22 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 22 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 22 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 22 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 22 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 22 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 22 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 22 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 22 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 22 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:37,207][__main__][INFO] - Epoch 22: Val Loss: 1.0625, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6145952001215159, 'f1_weighted': 0.7251627418380936, 'precision_macro': 0.616208538083538, 'recall_macro': 0.6228235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38116b5e00>
<numpy.flatiter object at 0x7f38116b5e00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6193850>
<numpy.flatiter object at 0x7f36f6193850>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6193850>
<numpy.flatiter object at 0x7f36f6193850>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6193e50>
<numpy.flatiter object at 0x7f36f6193e50>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6193e50>
<numpy.flatiter object at 0x7f36f6193e50>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:54:37,272][__main__][INFO] - Saved best model at epoch 22 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:54:37,372][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 23 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:37,761][__main__][INFO] - Train Epoch: 23 [0/13 (0%)]	Loss: 0.303196
Epoch 23 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 23 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 23 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 23 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 23 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 23 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 23 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 23 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 23 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 23 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 23 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:42,934][__main__][INFO] - Epoch 23: Val Loss: 0.8875, Accuracy: 0.7822, Metrics: {'accuracy': 0.7821782178217822, 'f1_macro': 0.6303837953091684, 'f1_weighted': 0.7329477084168972, 'precision_macro': 0.6366666666666667, 'recall_macro': 0.6372881355932203}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811f69130>
<numpy.flatiter object at 0x7f3811f69130>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f370308a520>
<numpy.flatiter object at 0x7f370308a520>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370308a520>
<numpy.flatiter object at 0x7f370308a520>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370308ab20>
<numpy.flatiter object at 0x7f370308ab20>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370308ab20>
<numpy.flatiter object at 0x7f370308ab20>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:54:42,999][__main__][INFO] - Saved best model at epoch 23 with accuracy: 0.7822
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:54:43,094][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 24 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:43,480][__main__][INFO] - Train Epoch: 24 [0/13 (0%)]	Loss: 0.550666
Epoch 24 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 24 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 24 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 24 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 24 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 24 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 24 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 24 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 24 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 24 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 24 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:48,652][__main__][INFO] - Epoch 24: Val Loss: 0.9273, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6145952001215159, 'f1_weighted': 0.7251627418380936, 'precision_macro': 0.616208538083538, 'recall_macro': 0.6228235747303544}
Epoch 25 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:49,016][__main__][INFO] - Train Epoch: 25 [0/13 (0%)]	Loss: 0.338401
Epoch 25 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 25 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 25 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 25 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 25 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 25 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 25 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 25 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 25 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 25 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 25 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:54,211][__main__][INFO] - Epoch 25: Val Loss: 1.2827, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.448015873015873, 'f1_weighted': 0.6217664623605218, 'precision_macro': 0.5509259259259259, 'recall_macro': 0.4324345146379045}
Epoch 26 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:54:54,567][__main__][INFO] - Train Epoch: 26 [0/13 (0%)]	Loss: 0.354523
Epoch 26 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 26 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 26 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 26 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 26 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 26 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 26 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 26 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 26 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 26 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 26 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:54:59,762][__main__][INFO] - Epoch 26: Val Loss: 0.9510, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6145952001215159, 'f1_weighted': 0.7251627418380936, 'precision_macro': 0.616208538083538, 'recall_macro': 0.6228235747303544}
Epoch 27 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:00,116][__main__][INFO] - Train Epoch: 27 [0/13 (0%)]	Loss: 0.473247
Epoch 27 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 27 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 27 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 27 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 27 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 27 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 27 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 27 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 27 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 27 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 27 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 27 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 27 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 27 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 27 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:05,295][__main__][INFO] - Epoch 27: Val Loss: 1.0502, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.3950663349917081, 'f1_weighted': 0.6208150665812849, 'precision_macro': 0.5666666666666667, 'recall_macro': 0.42251540832049306}
Epoch 28 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:05,656][__main__][INFO] - Train Epoch: 28 [0/13 (0%)]	Loss: 0.690734
Epoch 28 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 28 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 28 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:04,  2.07it/s]Epoch 28 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:02<00:05,  1.78it/s]Epoch 28 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:02<00:04,  1.64it/s]Epoch 28 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:03<00:04,  1.56it/s]Epoch 28 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:03<00:03,  1.83it/s]Epoch 28 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:04<00:02,  2.06it/s]Epoch 28 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:04<00:01,  2.25it/s]Epoch 28 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:04<00:01,  2.41it/s]Epoch 28 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:05<00:00,  2.53it/s]Epoch 28 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:05<00:00,  2.62it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:05<00:00,  3.01it/s]                                                                 Epoch 28 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 28 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 28 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:55:12,139][__main__][INFO] - Epoch 28: Val Loss: 0.8809, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.7045940612117083, 'f1_weighted': 0.7449745485563773, 'precision_macro': 0.710436377348142, 'recall_macro': 0.7025616332819723}
Epoch 29 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:12,503][__main__][INFO] - Train Epoch: 29 [0/13 (0%)]	Loss: 0.595642
Epoch 29 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 29 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 29 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 29 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 29 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 29 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 29 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 29 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 29 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 29 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 29 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 29 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 29 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 29 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 29 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:17,677][__main__][INFO] - Epoch 29: Val Loss: 0.9079, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5861762615493958, 'f1_weighted': 0.7048984216118841, 'precision_macro': 0.5958333333333333, 'recall_macro': 0.5875963020030817}
Epoch 30 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:18,039][__main__][INFO] - Train Epoch: 30 [0/13 (0%)]	Loss: 0.534337
Epoch 30 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 30 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 30 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 30 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 30 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 30 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 30 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 30 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 30 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 30 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 30 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 30 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 30 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 30 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 30 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:23,226][__main__][INFO] - Epoch 30: Val Loss: 1.0695, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5880252100840336, 'f1_weighted': 0.7035610283717447, 'precision_macro': 0.6151515151515151, 'recall_macro': 0.5793335901386749}
Epoch 31 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:23,583][__main__][INFO] - Train Epoch: 31 [0/13 (0%)]	Loss: 0.531134
Epoch 31 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 31 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 31 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 31 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 31 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 31 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 31 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 31 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 31 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 31 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 31 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 31 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 31 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 31 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 31 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:28,767][__main__][INFO] - Epoch 31: Val Loss: 1.1528, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5379032258064517, 'f1_weighted': 0.654774832321942, 'precision_macro': 0.5819304152637486, 'recall_macro': 0.5293335901386749}
Epoch 32 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:29,129][__main__][INFO] - Train Epoch: 32 [0/13 (0%)]	Loss: 0.520472
Epoch 32 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 32 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 32 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 32 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 32 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 32 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 32 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 32 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 32 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 32 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 32 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 32 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 32 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 32 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 32 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:34,304][__main__][INFO] - Epoch 32: Val Loss: 0.9955, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6132045088566828, 'f1_weighted': 0.7208239664546164, 'precision_macro': 0.6249156545209177, 'recall_macro': 0.6247881355932203}
Epoch 33 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:34,659][__main__][INFO] - Train Epoch: 33 [0/13 (0%)]	Loss: 0.528792
Epoch 33 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 33 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 33 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 33 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 33 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 33 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 33 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 33 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 33 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 33 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 33 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 33 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 33 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 33 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 33 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:39,836][__main__][INFO] - Epoch 33: Val Loss: 0.9463, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.620912980687292, 'f1_weighted': 0.7249209362231153, 'precision_macro': 0.6078431372549019, 'recall_macro': 0.6413135593220339}
Epoch 34 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:40,198][__main__][INFO] - Train Epoch: 34 [0/13 (0%)]	Loss: 0.643188
Epoch 34 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 34 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 34 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 34 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 34 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 34 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 34 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 34 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 34 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 34 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 34 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 34 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 34 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 34 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 34 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:55:45,389][__main__][INFO] - Epoch 34: Val Loss: 0.9283, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.60237443517553, 'f1_weighted': 0.7135750592786078, 'precision_macro': 0.641025641025641, 'recall_macro': 0.5937981510015409}
Epoch 35 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:45,746][__main__][INFO] - Train Epoch: 35 [0/13 (0%)]	Loss: 0.481984
Epoch 35 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 35 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 35 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 35 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 35 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 35 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 35 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 35 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 35 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 35 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 35 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 35 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 35 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 35 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 35 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:55:50,921][__main__][INFO] - Epoch 35: Val Loss: 1.0752, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6016830294530154, 'f1_weighted': 0.7064557788177135, 'precision_macro': 0.6349252013808976, 'recall_macro': 0.6040254237288136}
Epoch 36 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:51,275][__main__][INFO] - Train Epoch: 36 [0/13 (0%)]	Loss: 0.237044
Epoch 36 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 36 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 36 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 36 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 36 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 36 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 36 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 36 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 36 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 36 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 36 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 36 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 36 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 36 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 36 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:55:56,452][__main__][INFO] - Epoch 36: Val Loss: 0.9162, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.6050637173642768, 'f1_weighted': 0.7032077689741623, 'precision_macro': 0.65, 'recall_macro': 0.5831471494607088}
Epoch 37 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:55:56,806][__main__][INFO] - Train Epoch: 37 [0/13 (0%)]	Loss: 0.492939
Epoch 37 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 37 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 37 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 37 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 37 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 37 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 37 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 37 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 37 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 37 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 37 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 37 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 37 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 37 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 37 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:01,984][__main__][INFO] - Epoch 37: Val Loss: 1.1136, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5856377877237852, 'f1_weighted': 0.6966334101440835, 'precision_macro': 0.5984848484848485, 'recall_macro': 0.5997881355932204}
Epoch 38 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:02,348][__main__][INFO] - Train Epoch: 38 [0/13 (0%)]	Loss: 0.167361
Epoch 38 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 38 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 38 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 38 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 38 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 38 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 38 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 38 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 38 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 38 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 38 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 38 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 38 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 38 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 38 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:56:07,525][__main__][INFO] - Epoch 38: Val Loss: 0.8849, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6473881155515642, 'f1_weighted': 0.7242406054705156, 'precision_macro': 0.6929563492063492, 'recall_macro': 0.6348035439137134}
[2025-05-30 15:56:07,528][__main__][INFO] - Early stopping triggered after 38 epochs
[2025-05-30 15:56:07,528][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7822
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381009a680>
<numpy.flatiter object at 0x7f381009a680>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030d4030>
<numpy.flatiter object at 0x7f37030d4030>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030d4030>
<numpy.flatiter object at 0x7f37030d4030>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37030d4630>
<numpy.flatiter object at 0x7f37030d4630>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030d4630>
<numpy.flatiter object at 0x7f37030d4630>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb:            Validation Loss ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá
wandb:        Validation f1_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá
wandb:     Validation f1_weighted ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.78218
wandb:                 Train Loss 0.16736
wandb:        Validation Accuracy 0.75248
wandb:            Validation Loss 0.88488
wandb:        Validation accuracy 0.75248
wandb:        Validation f1_macro 0.64739
wandb:     Validation f1_weighted 0.72424
wandb: Validation precision_macro 0.69296
wandb:    Validation recall_macro 0.6348
wandb: 
wandb: üöÄ View run visionary-sweep-15 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/8rj38qpp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_155226-8rj38qpp/logs
wandb: Agent Starting Run: kasz0v87 with config:
wandb: 	Fdropout_rate: 0.21299130295024035
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 4
wandb: 	Mdropout_rate: 0.13255832891928465
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 32
wandb: 	learning_rate: 0.020144804918776685
wandb: 	pretrained_model_name: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_155611-kasz0v87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/kasz0v87
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:15,255][__main__][INFO] - Train Epoch: 0 [0/13 (0%)]	Loss: 1.492602
Epoch 0 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 0 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 0 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.77it/s]Epoch 0 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 0 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 0 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 0 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 0 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 0 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 0 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 0 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 0 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.24it/s]                                                                Epoch 0 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 0 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  3.00it/s]Epoch 0 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:20,410][__main__][INFO] - Epoch 0: Val Loss: 27.3416, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3749300380>
<numpy.flatiter object at 0x7f3749300380>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f374869dc60>
<numpy.flatiter object at 0x7f374869dc60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374869dc60>
<numpy.flatiter object at 0x7f374869dc60>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3749245790>
<numpy.flatiter object at 0x7f3749245790>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3749245790>
<numpy.flatiter object at 0x7f3749245790>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:56:20,496][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:56:20,597][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:56:20,629][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:20,984][__main__][INFO] - Train Epoch: 1 [0/13 (0%)]	Loss: 22.782696
Epoch 1 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 1 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 1 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 1 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 1 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 1 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 1 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 1 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 1 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 1 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 1 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 1 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                Epoch 1 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 1 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 1 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:26,136][__main__][INFO] - Epoch 1: Val Loss: 10.2256, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:26,497][__main__][INFO] - Train Epoch: 2 [0/13 (0%)]	Loss: 8.959126
Epoch 2 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 2 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 2 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 2 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 2 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 2 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 2 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 2 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 2 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 2 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.86it/s]Epoch 2 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 2 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                Epoch 2 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 2 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 2 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:31,640][__main__][INFO] - Epoch 2: Val Loss: 3.5081, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:32,003][__main__][INFO] - Train Epoch: 3 [0/13 (0%)]	Loss: 3.175169
Epoch 3 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 3 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 3 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 3 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 3 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 3 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 3 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 3 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.86it/s]Epoch 3 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 3 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 3 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 3 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                Epoch 3 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 3 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.91it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.94it/s]Epoch 3 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:37,161][__main__][INFO] - Epoch 3: Val Loss: 1.2446, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.32310494605576573, 'f1_weighted': 0.539753092585425, 'precision_macro': 0.28900336417157274, 'recall_macro': 0.39470338983050846}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119fb900>
<numpy.flatiter object at 0x7f37491f2700>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703398230>
<numpy.flatiter object at 0x7f3703398230>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703398230>
<numpy.flatiter object at 0x7f3703398230>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703398830>
<numpy.flatiter object at 0x7f3703398830>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703398830>
<numpy.flatiter object at 0x7f3703398830>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:56:37,232][__main__][INFO] - Saved best model at epoch 3 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:56:37,348][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 4 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:37,738][__main__][INFO] - Train Epoch: 4 [0/13 (0%)]	Loss: 1.166071
Epoch 4 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 4 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 4 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 4 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.85it/s]Epoch 4 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 4 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 4 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 4 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 4 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 4 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 4 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.86it/s]Epoch 4 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.86it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.23it/s]                                                                Epoch 4 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 4 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 4 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:42,888][__main__][INFO] - Epoch 4: Val Loss: 1.2556, Accuracy: 0.5545, Metrics: {'accuracy': 0.5544554455445545, 'f1_macro': 0.33592307692307694, 'f1_weighted': 0.5228575780654989, 'precision_macro': 0.3159090909090909, 'recall_macro': 0.36082434514637907}
Epoch 5 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:43,248][__main__][INFO] - Train Epoch: 5 [0/13 (0%)]	Loss: 0.928325
Epoch 5 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 5 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 5 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 5 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 5 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 5 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 5 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 5 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 5 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 5 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 5 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 5 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 5 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 5 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  3.00it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 5 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:48,404][__main__][INFO] - Epoch 5: Val Loss: 1.4768, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.2295647558386412, 'f1_weighted': 0.4572008156229636, 'precision_macro': 0.4005102040816326, 'recall_macro': 0.2727272727272727}
Epoch 6 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:48,768][__main__][INFO] - Train Epoch: 6 [0/13 (0%)]	Loss: 0.765657
Epoch 6 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 6 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 6 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 6 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 6 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.85it/s]Epoch 6 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 6 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 6 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 6 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 6 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 6 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 6 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                Epoch 6 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 6 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 6 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            [2025-05-30 15:56:53,934][__main__][INFO] - Epoch 6: Val Loss: 1.0576, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.45455827851088115, 'f1_weighted': 0.6187624263907558, 'precision_macro': 0.517948717948718, 'recall_macro': 0.438424499229584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811cb0300>
<numpy.flatiter object at 0x7f3811cb0300>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37485f1430>
<numpy.flatiter object at 0x7f37485f1430>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37485f1430>
<numpy.flatiter object at 0x7f37485f1430>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37485f1430>
<numpy.flatiter object at 0x7f37485f1430>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37485f1430>
<numpy.flatiter object at 0x7f37485f1430>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:56:53,995][__main__][INFO] - Saved best model at epoch 6 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:56:54,090][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 7 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:56:54,474][__main__][INFO] - Train Epoch: 7 [0/13 (0%)]	Loss: 0.651582
Epoch 7 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 7 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.85it/s]Epoch 7 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 7 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.86it/s]Epoch 7 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.86it/s]Epoch 7 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.86it/s]Epoch 7 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.86it/s]Epoch 7 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 7 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.86it/s]Epoch 7 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 7 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 7 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 7 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 7 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 7 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:56:59,633][__main__][INFO] - Epoch 7: Val Loss: 1.4149, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.45122493441821176, 'f1_weighted': 0.6044670893659995, 'precision_macro': 0.5604707792207793, 'recall_macro': 0.43636363636363634}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702ccd080>
<numpy.flatiter object at 0x7f3702ccd080>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f5f79d90>
<numpy.flatiter object at 0x7f36f5f79d90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5f79d90>
<numpy.flatiter object at 0x7f36f5f79d90>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f5f79d90>
<numpy.flatiter object at 0x7f36f5f79d90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5f79d90>
<numpy.flatiter object at 0x7f36f5f79d90>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:56:59,698][__main__][INFO] - Saved best model at epoch 7 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:56:59,798][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 8 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:00,184][__main__][INFO] - Train Epoch: 8 [0/13 (0%)]	Loss: 0.791124
Epoch 8 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 8 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 8 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.85it/s]Epoch 8 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 8 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 8 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.85it/s]Epoch 8 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.85it/s]Epoch 8 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 8 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 8 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 8 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 8 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                Epoch 8 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 8 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 8 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:57:05,347][__main__][INFO] - Epoch 8: Val Loss: 1.7390, Accuracy: 0.2970, Metrics: {'accuracy': 0.297029702970297, 'f1_macro': 0.3430907172995781, 'f1_weighted': 0.19007185528679452, 'precision_macro': 0.37356848373797524, 'recall_macro': 0.49772727272727274}
Epoch 9 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:05,708][__main__][INFO] - Train Epoch: 9 [0/13 (0%)]	Loss: 1.350777
Epoch 9 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 9 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 9 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 9 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 9 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 9 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 9 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 9 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 9 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 9 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 9 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 9 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                Epoch 9 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 9 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 9 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                            [2025-05-30 15:57:10,876][__main__][INFO] - Epoch 9: Val Loss: 1.1674, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.4962023962344887, 'f1_weighted': 0.6161915292941361, 'precision_macro': 0.5055803571428572, 'recall_macro': 0.5040061633281973}
Epoch 10 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:11,241][__main__][INFO] - Train Epoch: 10 [0/13 (0%)]	Loss: 0.866721
Epoch 10 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 10 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 10 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 10 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 10 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 10 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 10 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 10 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 10 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 10 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 10 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 10 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 10 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 10 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 10 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  3.00it/s]                                                             [2025-05-30 15:57:16,405][__main__][INFO] - Epoch 10: Val Loss: 1.0028, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5293795620437955, 'f1_weighted': 0.6636987786369879, 'precision_macro': 0.5683760683760684, 'recall_macro': 0.5191063174114021}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f48a1ac0>
<numpy.flatiter object at 0x7f36f48a1ac0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748fc2eb0>
<numpy.flatiter object at 0x7f3748fc2eb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748fc2eb0>
<numpy.flatiter object at 0x7f3748fc2eb0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748fc34b0>
<numpy.flatiter object at 0x7f3748fc34b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748fc34b0>
<numpy.flatiter object at 0x7f3748fc34b0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:57:16,469][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:57:16,570][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:57:16,602][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:16,954][__main__][INFO] - Train Epoch: 11 [0/13 (0%)]	Loss: 0.532451
Epoch 11 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.85it/s]Epoch 11 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 11 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 11 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 11 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 11 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 11 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 11 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.85it/s]Epoch 11 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 11 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.85it/s]Epoch 11 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 11 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 11 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 11 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.99it/s]Epoch 11 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.99it/s]                                                             [2025-05-30 15:57:22,123][__main__][INFO] - Epoch 11: Val Loss: 0.9954, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5634674922600619, 'f1_weighted': 0.6892683076357171, 'precision_macro': 0.6103896103896104, 'recall_macro': 0.5441063174114023}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702ccd080>
<numpy.flatiter object at 0x7f3702ccd080>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3812297300>
<numpy.flatiter object at 0x7f3812297300>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812297300>
<numpy.flatiter object at 0x7f3812297300>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3812297900>
<numpy.flatiter object at 0x7f3812297900>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812297900>
<numpy.flatiter object at 0x7f3812297900>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:57:22,189][__main__][INFO] - Saved best model at epoch 11 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:57:22,283][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 12 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:22,670][__main__][INFO] - Train Epoch: 12 [0/13 (0%)]	Loss: 0.448688
Epoch 12 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 12 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.79it/s]Epoch 12 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 12 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 12 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 12 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 12 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 12 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 12 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 12 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 12 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 12 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 12 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 12 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.99it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 12 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:57:27,854][__main__][INFO] - Epoch 12: Val Loss: 0.9923, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5858835554209569, 'f1_weighted': 0.6917675156370876, 'precision_macro': 0.6176169590643275, 'recall_macro': 0.5706471494607088}
Epoch 13 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:28,216][__main__][INFO] - Train Epoch: 13 [0/13 (0%)]	Loss: 0.433832
Epoch 13 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 13 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 13 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 13 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 13 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 13 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 13 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 13 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 13 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 13 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 13 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.85it/s]Epoch 13 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.85it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.22it/s]                                                                 Epoch 13 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 13 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 13 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:57:33,381][__main__][INFO] - Epoch 13: Val Loss: 1.2391, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.43299319727891156, 'f1_weighted': 0.5636559574324779, 'precision_macro': 0.4703282828282828, 'recall_macro': 0.4503081664098613}
Epoch 14 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:33,742][__main__][INFO] - Train Epoch: 14 [0/13 (0%)]	Loss: 0.528619
Epoch 14 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 14 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 14 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 14 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 14 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 14 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 14 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 14 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 14 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 14 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 14 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 14 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 14 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 14 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 14 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:57:38,930][__main__][INFO] - Epoch 14: Val Loss: 0.9011, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6652603711427241, 'f1_weighted': 0.7474281836541592, 'precision_macro': 0.7037772368105994, 'recall_macro': 0.6473035439137135}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030337e0>
<numpy.flatiter object at 0x7f37030337e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703063880>
<numpy.flatiter object at 0x7f3703063880>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703063880>
<numpy.flatiter object at 0x7f3703063880>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703063e80>
<numpy.flatiter object at 0x7f3703063e80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703063e80>
<numpy.flatiter object at 0x7f3703063e80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:57:38,995][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:57:39,094][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:39,480][__main__][INFO] - Train Epoch: 15 [0/13 (0%)]	Loss: 0.444889
Epoch 15 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 15 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 15 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.84it/s]Epoch 15 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 15 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 15 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 15 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 15 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 15 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 15 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 15 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 15 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 15 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 15 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 15 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:57:44,653][__main__][INFO] - Epoch 15: Val Loss: 1.0449, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6316168327796234, 'f1_weighted': 0.7165926559433351, 'precision_macro': 0.6853174603174603, 'recall_macro': 0.5995762711864407}
Epoch 16 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:45,009][__main__][INFO] - Train Epoch: 16 [0/13 (0%)]	Loss: 0.326756
Epoch 16 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.83it/s]Epoch 16 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.83it/s]Epoch 16 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 16 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.84it/s]Epoch 16 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.84it/s]Epoch 16 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 16 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.84it/s]Epoch 16 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 16 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.85it/s]Epoch 16 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 16 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 16 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 16 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 16 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 16 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:57:50,183][__main__][INFO] - Epoch 16: Val Loss: 0.8900, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6595759552656104, 'f1_weighted': 0.7138669225729656, 'precision_macro': 0.6793945648434813, 'recall_macro': 0.6588597842835131}
Epoch 17 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:50,543][__main__][INFO] - Train Epoch: 17 [0/13 (0%)]	Loss: 0.523942
Epoch 17 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.80it/s]Epoch 17 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 17 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 17 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 17 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 17 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.84it/s]Epoch 17 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 17 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 17 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 17 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 17 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 17 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 17 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 17 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 17 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:57:55,727][__main__][INFO] - Epoch 17: Val Loss: 0.8824, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6908898305084745, 'f1_weighted': 0.7455445544554455, 'precision_macro': 0.7034966681153122, 'recall_macro': 0.6840716486902927}
Epoch 18 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:57:56,082][__main__][INFO] - Train Epoch: 18 [0/13 (0%)]	Loss: 0.359222
Epoch 18 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 18 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 18 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 18 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 18 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 18 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 18 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 18 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 18 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 18 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 18 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 18 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 18 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 18 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.98it/s]Epoch 18 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:58:01,273][__main__][INFO] - Epoch 18: Val Loss: 0.8970, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.7032849503437739, 'f1_weighted': 0.7512272235626923, 'precision_macro': 0.7087121212121212, 'recall_macro': 0.6985362095531588}
Epoch 19 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:01,637][__main__][INFO] - Train Epoch: 19 [0/13 (0%)]	Loss: 0.369947
Epoch 19 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 19 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 19 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 19 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 19 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 19 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 19 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 19 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.82it/s]Epoch 19 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.82it/s]Epoch 19 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 19 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 19 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 19 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 19 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 19 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:06,836][__main__][INFO] - Epoch 19: Val Loss: 0.9657, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6748819362455726, 'f1_weighted': 0.7298385682724116, 'precision_macro': 0.6841773817580269, 'recall_macro': 0.6735362095531587}
Epoch 20 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:07,192][__main__][INFO] - Train Epoch: 20 [0/13 (0%)]	Loss: 0.287261
Epoch 20 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.84it/s]Epoch 20 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.82it/s]Epoch 20 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 20 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 20 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 20 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 20 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 20 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 20 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 20 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 20 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 20 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 20 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 20 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 20 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.98it/s]                                                             [2025-05-30 15:58:12,374][__main__][INFO] - Epoch 20: Val Loss: 1.0058, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.6305852096273292, 'f1_weighted': 0.6950074180554702, 'precision_macro': 0.6722826086956522, 'recall_macro': 0.6217835130970725}
Epoch 21 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:12,731][__main__][INFO] - Train Epoch: 21 [0/13 (0%)]	Loss: 0.310402
Epoch 21 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.81it/s]Epoch 21 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.84it/s]Epoch 21 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.83it/s]Epoch 21 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 21 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 21 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 21 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 21 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 21 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 21 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 21 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 21 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 21 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 21 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 21 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.96it/s]                                                             [2025-05-30 15:58:17,923][__main__][INFO] - Epoch 21: Val Loss: 0.9129, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6804025974025973, 'f1_weighted': 0.7427383309759547, 'precision_macro': 0.7070707070707071, 'recall_macro': 0.6635208012326657}
Epoch 22 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:18,288][__main__][INFO] - Train Epoch: 22 [0/13 (0%)]	Loss: 0.352635
Epoch 22 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 22 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 22 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.81it/s]Epoch 22 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 22 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 22 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 22 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 22 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.84it/s]Epoch 22 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.84it/s]Epoch 22 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 22 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 22 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 22 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 22 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 22 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:23,477][__main__][INFO] - Epoch 22: Val Loss: 1.3978, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.563569748596727, 'f1_weighted': 0.6421742923363408, 'precision_macro': 0.671875, 'recall_macro': 0.5432781201848998}
Epoch 23 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:23,842][__main__][INFO] - Train Epoch: 23 [0/13 (0%)]	Loss: 0.502781
Epoch 23 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.78it/s]Epoch 23 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 23 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 23 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 23 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 23 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 23 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 23 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 23 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 23 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.82it/s]Epoch 23 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 23 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 23 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 23 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 23 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:29,033][__main__][INFO] - Epoch 23: Val Loss: 0.9079, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6993188405797102, 'f1_weighted': 0.7621190988664085, 'precision_macro': 0.7387040043290043, 'recall_macro': 0.6802580893682589}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702ee3640>
<numpy.flatiter object at 0x7f3702ee3640>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702698990>
<numpy.flatiter object at 0x7f3702698990>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702698990>
<numpy.flatiter object at 0x7f3702698990>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702698f90>
<numpy.flatiter object at 0x7f3702698f90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702698f90>
<numpy.flatiter object at 0x7f3702698f90>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:58:29,099][__main__][INFO] - Saved best model at epoch 23 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:58:29,198][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 24 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:29,595][__main__][INFO] - Train Epoch: 24 [0/13 (0%)]	Loss: 0.313153
Epoch 24 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.75it/s]Epoch 24 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.76it/s]Epoch 24 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.79it/s]Epoch 24 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.80it/s]Epoch 24 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.81it/s]Epoch 24 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 24 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 24 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 24 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 24 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 24 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.84it/s]Epoch 24 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 24 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 24 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.95it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.96it/s]Epoch 24 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:34,793][__main__][INFO] - Epoch 24: Val Loss: 0.9892, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6910833069369654, 'f1_weighted': 0.7460930762065754, 'precision_macro': 0.7067945075757576, 'recall_macro': 0.6820107858243452}
Epoch 25 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:35,156][__main__][INFO] - Train Epoch: 25 [0/13 (0%)]	Loss: 0.643492
Epoch 25 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.79it/s]Epoch 25 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.81it/s]Epoch 25 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 25 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.83it/s]Epoch 25 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 25 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 25 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 25 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 25 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 25 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 25 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 25 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.83it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.20it/s]                                                                 Epoch 25 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 25 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.98it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 25 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:40,346][__main__][INFO] - Epoch 25: Val Loss: 0.9468, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.7027032621294916, 'f1_weighted': 0.7579216938087252, 'precision_macro': 0.7151650432900434, 'recall_macro': 0.6945107858243451}
Epoch 26 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:40,702][__main__][INFO] - Train Epoch: 26 [0/13 (0%)]	Loss: 0.175719
Epoch 26 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.82it/s]Epoch 26 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.78it/s]Epoch 26 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.80it/s]Epoch 26 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.81it/s]Epoch 26 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.82it/s]Epoch 26 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.82it/s]Epoch 26 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.82it/s]Epoch 26 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 26 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 26 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.83it/s]Epoch 26 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 26 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.82it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.19it/s]                                                                 Epoch 26 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 26 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.97it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 26 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:45,904][__main__][INFO] - Epoch 26: Val Loss: 0.9400, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.6531288156288156, 'f1_weighted': 0.7116956201114616, 'precision_macro': 0.6463527851458886, 'recall_macro': 0.6630970724191063}
Epoch 27 [Train]:   0%|          | 0/13 [00:00<?, ?it/s][2025-05-30 15:58:46,268][__main__][INFO] - Train Epoch: 27 [0/13 (0%)]	Loss: 0.229355
Epoch 27 [Train]:   8%|‚ñä         | 1/13 [00:00<00:04,  2.76it/s]Epoch 27 [Train]:  15%|‚ñà‚ñå        | 2/13 [00:00<00:03,  2.80it/s]Epoch 27 [Train]:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:01<00:03,  2.82it/s]Epoch 27 [Train]:  31%|‚ñà‚ñà‚ñà       | 4/13 [00:01<00:03,  2.82it/s]Epoch 27 [Train]:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [00:01<00:02,  2.83it/s]Epoch 27 [Train]:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 6/13 [00:02<00:02,  2.83it/s]Epoch 27 [Train]:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 7/13 [00:02<00:02,  2.83it/s]Epoch 27 [Train]:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [00:02<00:01,  2.83it/s]Epoch 27 [Train]:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 9/13 [00:03<00:01,  2.83it/s]Epoch 27 [Train]:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [00:03<00:01,  2.84it/s]Epoch 27 [Train]:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [00:03<00:00,  2.83it/s]Epoch 27 [Train]:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 12/13 [00:04<00:00,  2.84it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:04<00:00,  3.21it/s]                                                                 Epoch 27 [Val]:   0%|          | 0/4 [00:00<?, ?it/s]Epoch 27 [Val]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:01,  2.96it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:00<00:00,  2.97it/s]Epoch 27 [Val]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  2.97it/s]                                                             [2025-05-30 15:58:51,452][__main__][INFO] - Epoch 27: Val Loss: 1.0446, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6976731601731602, 'f1_weighted': 0.7480669495520981, 'precision_macro': 0.6990880703995458, 'recall_macro': 0.7087634822804314}
[2025-05-30 15:58:51,454][__main__][INFO] - Early stopping triggered after 27 epochs
[2025-05-30 15:58:51,455][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7723
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f486e780>
<numpy.flatiter object at 0x7f36f486e780>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37035e18e0>
<numpy.flatiter object at 0x7f37035e18e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035e18e0>
<numpy.flatiter object at 0x7f37035e18e0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37035e1ee0>
<numpy.flatiter object at 0x7f37035e1ee0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035e1ee0>
<numpy.flatiter object at 0x7f37035e1ee0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:            Validation Loss ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:        Validation f1_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:     Validation f1_weighted ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñà‚ñà‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.77228
wandb:                 Train Loss 0.22936
wandb:        Validation Accuracy 0.75248
wandb:            Validation Loss 1.04459
wandb:        Validation accuracy 0.75248
wandb:        Validation f1_macro 0.69767
wandb:     Validation f1_weighted 0.74807
wandb: Validation precision_macro 0.69909
wandb:    Validation recall_macro 0.70876
wandb: 
wandb: üöÄ View run zesty-sweep-16 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/kasz0v87
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_155611-kasz0v87/logs
wandb: Agent Starting Run: clov3pao with config:
wandb: 	Fdropout_rate: 0.2633681427836705
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 5
wandb: 	Mdropout_rate: 0.1051850148358255
wandb: 	Mnum_layers: 4
wandb: 	batch_size: 8
wandb: 	learning_rate: 0.028847119540390525
wandb: 	pretrained_model_name: nvidia/biomegatron-345m-uncased
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_155859-clov3pao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/clov3pao
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.
wandb:                                                                                
wandb: üöÄ View run prime-sweep-17 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/clov3pao
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_155859-clov3pao/logs
wandb: ERROR Run clov3pao errored:
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 406, in hf_raise_for_status
wandb: ERROR     response.raise_for_status()
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
wandb: ERROR     raise HTTPError(http_error_msg, response=self)
wandb: ERROR requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 342, in cached_file
wandb: ERROR     resolved_file = hf_hub_download(
wandb: ERROR                     ^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 860, in hf_hub_download
wandb: ERROR     return _hf_hub_download_to_cache_dir(
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 967, in _hf_hub_download_to_cache_dir
wandb: ERROR     _raise_on_head_call_error(head_call_error, force_download, local_files_only)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1482, in _raise_on_head_call_error
wandb: ERROR     raise head_call_error
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1374, in _get_metadata_or_catch_error
wandb: ERROR     metadata = get_hf_file_metadata(
wandb: ERROR                ^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
wandb: ERROR     return fn(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1294, in get_hf_file_metadata
wandb: ERROR     r = _request_wrapper(
wandb: ERROR         ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 278, in _request_wrapper
wandb: ERROR     response = _request_wrapper(
wandb: ERROR                ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 302, in _request_wrapper
wandb: ERROR     hf_raise_for_status(response)
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 454, in hf_raise_for_status
wandb: ERROR     raise _format(RepositoryNotFoundError, message, response) from e
wandb: ERROR huggingface_hub.errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-68395734-290bcf531e9dce3216ee6c6f;32cecf0f-0cde-433f-a3f8-0615583833a8)
wandb: ERROR 
wandb: ERROR Repository Not Found for url: https://huggingface.co/nvidia/biomegatron-345m-uncased/resolve/main/tokenizer_config.json.
wandb: ERROR Please make sure you specified the correct `repo_id` and `repo_type`.
wandb: ERROR If you are trying to access a private or gated repo, make sure you are authenticated.
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 92, in _call_target
wandb: ERROR     return _target_(*args, **kwargs)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/src/data/dataset.py", line 155, in __init__
wandb: ERROR     self.tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer)
wandb: ERROR                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 881, in from_pretrained
wandb: ERROR     tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
wandb: ERROR                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py", line 713, in get_tokenizer_config
wandb: ERROR     resolved_config_file = cached_file(
wandb: ERROR                            ^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/transformers/utils/hub.py", line 365, in cached_file
wandb: ERROR     raise EnvironmentError(
wandb: ERROR OSError: nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
wandb: ERROR If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
wandb: ERROR 
wandb: ERROR The above exception was the direct cause of the following exception:
wandb: ERROR 
wandb: ERROR Traceback (most recent call last):
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
wandb: ERROR     self._function()
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 299, in sweep_train
wandb: ERROR   File "/home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/train.py", line 54, in train
wandb: ERROR     train_dataset = hydra.utils.instantiate(config.data.caller, data = train_data)
wandb: ERROR                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
wandb: ERROR     return instantiate_node(
wandb: ERROR            ^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 347, in instantiate_node
wandb: ERROR     return _call_target(_target_, partial, args, kwargs, full_key)
wandb: ERROR            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
wandb: ERROR   File "/home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 97, in _call_target
wandb: ERROR     raise InstantiationException(msg) from e
wandb: ERROR hydra.errors.InstantiationException: Error in call to target 'src.data.dataset.TBIDataset2stream':
wandb: ERROR OSError("nvidia/biomegatron-345m-uncased is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`")
wandb: ERROR full_key: default_sweep.data.caller
wandb: ERROR 
wandb: Agent Starting Run: h5rrh9bf with config:
wandb: 	Fdropout_rate: 0.2955043175583093
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 3
wandb: 	Mdropout_rate: 0.21595892893606392
wandb: 	Mnum_layers: 4
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.018880425215262005
wandb: 	pretrained_model_name: dmis-lab/biobert-base-cased-v1.1
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_155904-h5rrh9bf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/h5rrh9bf
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:09,254][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.567897
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.48it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.48it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.91it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.54it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.04it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:13,904][__main__][INFO] - Epoch 0: Val Loss: 33.7037, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811f38060>
<numpy.flatiter object at 0x7f3811f38060>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f4881ac0>
<numpy.flatiter object at 0x7f37035cdac0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4410800>
<numpy.flatiter object at 0x7f37035cc1c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37035cce40>
<numpy.flatiter object at 0x7f36f4881ac0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035cdac0>
<numpy.flatiter object at 0x7f36f4410800>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:59:14,273][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:59:14,375][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 15:59:14,408][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:15,084][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 26.181143
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.48it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.48it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.48it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.90it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.54it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.03it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:19,735][__main__][INFO] - Epoch 1: Val Loss: 32.5388, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:20,419][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 31.205660
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.47it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:25,091][__main__][INFO] - Epoch 2: Val Loss: 14.4085, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:25,774][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 10.217495
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.47it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.03it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:30,441][__main__][INFO] - Epoch 3: Val Loss: 12.5231, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:31,132][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 12.097945
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.47it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:35,792][__main__][INFO] - Epoch 4: Val Loss: 7.1875, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:36,485][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 6.009478
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:41,146][__main__][INFO] - Epoch 5: Val Loss: 2.6356, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.3128460686600222, 'f1_weighted': 0.5046983103625978, 'precision_macro': 0.25921658986175117, 'recall_macro': 0.4391371340523883}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:59:41,209][__main__][INFO] - Saved best model at epoch 5 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:59:41,313][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:42,030][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 2.430434
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:46,719][__main__][INFO] - Epoch 6: Val Loss: 1.9523, Accuracy: 0.5545, Metrics: {'accuracy': 0.5544554455445545, 'f1_macro': 0.33870967741935487, 'f1_weighted': 0.5039923347173426, 'precision_macro': 0.3085314685314685, 'recall_macro': 0.42022342064714946}
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:47,406][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 1.714133
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:52,106][__main__][INFO] - Epoch 7: Val Loss: 1.3335, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.2904701306185171, 'f1_weighted': 0.5177009201112198, 'precision_macro': 0.2893162393162393, 'recall_macro': 0.30980354391371345}
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:52,795][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 1.258004
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 15:59:57,485][__main__][INFO] - Epoch 8: Val Loss: 1.2241, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.3851547948653411, 'f1_weighted': 0.5539362977324666, 'precision_macro': 0.3782051282051282, 'recall_macro': 0.4211671802773498}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 15:59:57,549][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.6238
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 15:59:57,643][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 15:59:58,365][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 0.959961
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:03,067][__main__][INFO] - Epoch 9: Val Loss: 1.6847, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:03,754][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 0.794195
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:08,461][__main__][INFO] - Epoch 10: Val Loss: 1.0017, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.37056899934597776, 'f1_weighted': 0.5456319732692694, 'precision_macro': 0.4152960526315789, 'recall_macro': 0.4500963020030817}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:00:08,528][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.6436
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:00:08,626][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:00:08,659][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:09,351][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 0.861922
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:14,058][__main__][INFO] - Epoch 11: Val Loss: 1.2461, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.3700194821518351, 'f1_weighted': 0.5820857538242512, 'precision_macro': 0.530672268907563, 'recall_macro': 0.3704545454545455}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:00:14,124][__main__][INFO] - Saved best model at epoch 11 with accuracy: 0.6634
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:00:14,230][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:14,947][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 0.622662
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:19,652][__main__][INFO] - Epoch 12: Val Loss: 1.3940, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.33088235294117646, 'f1_weighted': 0.5800815375655213, 'precision_macro': 0.29640151515151514, 'recall_macro': 0.37478813559322033}
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:20,343][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 1.052172
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:25,058][__main__][INFO] - Epoch 13: Val Loss: 0.9614, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3795366455250176, 'f1_weighted': 0.5884268659424082, 'precision_macro': 0.3902025014889815, 'recall_macro': 0.39503081664098616}
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:25,749][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 0.951724
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:30,462][__main__][INFO] - Epoch 14: Val Loss: 1.3993, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.4022108843537415, 'f1_weighted': 0.5437798881929009, 'precision_macro': 0.3542395104895105, 'recall_macro': 0.4687981510015408}
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:31,166][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 1.095017
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:35,890][__main__][INFO] - Epoch 15: Val Loss: 1.3930, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3035714285714286, 'f1_weighted': 0.5548797736916549, 'precision_macro': 0.2759259259259259, 'recall_macro': 0.34152542372881356}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:36,590][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 0.683767
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:41,322][__main__][INFO] - Epoch 16: Val Loss: 1.3857, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3460616122486626, 'f1_weighted': 0.5770883673868217, 'precision_macro': 0.4083881578947368, 'recall_macro': 0.36425269645608627}
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:42,022][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.760400
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:00:46,756][__main__][INFO] - Epoch 17: Val Loss: 1.0020, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.43643733688711195, 'f1_weighted': 0.6019516094537989, 'precision_macro': 0.47953216374269003, 'recall_macro': 0.44214175654853616}
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:47,449][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.772435
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.21it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:05<00:01,  1.01s/it]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.22it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.42it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.93it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:53,485][__main__][INFO] - Epoch 18: Val Loss: 0.9486, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4204936854190585, 'f1_weighted': 0.6261040570187902, 'precision_macro': 0.42538847117794487, 'recall_macro': 0.43046995377503855}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6400310>
<numpy.flatiter object at 0x7f36f6400310>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:00:53,549][__main__][INFO] - Saved best model at epoch 18 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:00:53,645][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:54,371][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.592666
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:00:59,096][__main__][INFO] - Epoch 19: Val Loss: 1.2717, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.2918712493180578, 'f1_weighted': 0.5433823251392242, 'precision_macro': 0.2658857509627728, 'recall_macro': 0.32902542372881355}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:00:59,788][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.549282
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:04,527][__main__][INFO] - Epoch 20: Val Loss: 1.5120, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3206586318112375, 'f1_weighted': 0.5696623982547636, 'precision_macro': 0.28818283166109254, 'recall_macro': 0.3622881355932204}
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:05,219][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 0.865188
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:09,960][__main__][INFO] - Epoch 21: Val Loss: 1.0164, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4627100840336134, 'f1_weighted': 0.6279016557117897, 'precision_macro': 0.4714285714285714, 'recall_macro': 0.4694144838212635}
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:10,653][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 0.430679
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:15,385][__main__][INFO] - Epoch 22: Val Loss: 1.0685, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.46580706585722914, 'f1_weighted': 0.6247541882391268, 'precision_macro': 0.48120629370629375, 'recall_macro': 0.47964175654853614}
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:16,080][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.646705
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:20,810][__main__][INFO] - Epoch 23: Val Loss: 1.0561, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3206586318112375, 'f1_weighted': 0.5696623982547636, 'precision_macro': 0.28818283166109254, 'recall_macro': 0.3622881355932204}
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:21,510][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.634174
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:26,245][__main__][INFO] - Epoch 24: Val Loss: 0.9066, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5160836874795685, 'f1_weighted': 0.6739017151143032, 'precision_macro': 0.5149774774774775, 'recall_macro': 0.5296417565485362}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37492c07c0>
<numpy.flatiter object at 0x7f37492c07c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381255dd00>
<numpy.flatiter object at 0x7f38116bb890>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63c5a50>
<numpy.flatiter object at 0x7f3748dad360>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703382d80>
<numpy.flatiter object at 0x7f36f5f7b040>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486bf1d0>
<numpy.flatiter object at 0x7f36f7857280>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:01:26,357][__main__][INFO] - Saved best model at epoch 24 with accuracy: 0.7228
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:01:26,466][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:27,188][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.526420
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:31,928][__main__][INFO] - Epoch 25: Val Loss: 0.9366, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.44717155154744825, 'f1_weighted': 0.6340022606482825, 'precision_macro': 0.5627705627705628, 'recall_macro': 0.4429699537750385}
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:32,623][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.358361
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:37,364][__main__][INFO] - Epoch 26: Val Loss: 1.0550, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.3854377104377104, 'f1_weighted': 0.6107977464413108, 'precision_macro': 0.5592105263157895, 'recall_macro': 0.41001540832049305}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:38,059][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.515166
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:42,797][__main__][INFO] - Epoch 27: Val Loss: 0.8279, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6039251792983137, 'f1_weighted': 0.7143279359918935, 'precision_macro': 0.6106060606060606, 'recall_macro': 0.6103235747303544}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119f5c40>
<numpy.flatiter object at 0x7f38119f5c40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703382d80>
<numpy.flatiter object at 0x7f370263cf80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5f7b040>
<numpy.flatiter object at 0x7f3748779c70>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37035fb560>
<numpy.flatiter object at 0x7f37486a5040>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38122b6380>
<numpy.flatiter object at 0x7f3748747c10>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:01:42,861][__main__][INFO] - Saved best model at epoch 27 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:01:42,961][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:43,684][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.542689
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:01:48,419][__main__][INFO] - Epoch 28: Val Loss: 0.7874, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.7115819209039548, 'f1_weighted': 0.7416313059877417, 'precision_macro': 0.7331505483549352, 'recall_macro': 0.7085516178736518}
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:49,127][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.621597
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:53,868][__main__][INFO] - Epoch 29: Val Loss: 1.4929, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3147920687839972, 'f1_weighted': 0.5660294753812984, 'precision_macro': 0.28526785714285713, 'recall_macro': 0.35402542372881357}
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:01:54,574][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 0.730757
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:01:59,302][__main__][INFO] - Epoch 30: Val Loss: 1.5443, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.36509384775808135, 'f1_weighted': 0.5900071237572142, 'precision_macro': 0.543123543123543, 'recall_macro': 0.3850154083204931}
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:00,004][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.836646
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:04,738][__main__][INFO] - Epoch 31: Val Loss: 1.5349, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.30646005300383183, 'f1_weighted': 0.520030531437202, 'precision_macro': 0.4602272727272727, 'recall_macro': 0.3162172573189523}
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:05,438][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.943717
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:10,168][__main__][INFO] - Epoch 32: Val Loss: 1.0990, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.3950663349917081, 'f1_weighted': 0.6208150665812849, 'precision_macro': 0.5666666666666667, 'recall_macro': 0.42251540832049306}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:10,863][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.504110
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:02:15,585][__main__][INFO] - Epoch 33: Val Loss: 0.7707, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6333679833679834, 'f1_weighted': 0.7333607789053334, 'precision_macro': 0.6896506489919911, 'recall_macro': 0.6185862865947612}
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:16,285][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.551504
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:21,019][__main__][INFO] - Epoch 34: Val Loss: 0.8382, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.569186446508428, 'f1_weighted': 0.693798172386898, 'precision_macro': 0.6036931818181819, 'recall_macro': 0.5566063174114022}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:21,712][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.471955
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:26,448][__main__][INFO] - Epoch 35: Val Loss: 0.9527, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5479258121158912, 'f1_weighted': 0.6938429576056815, 'precision_macro': 0.5991666666666666, 'recall_macro': 0.5361517719568567}
Epoch 36 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:27,149][__main__][INFO] - Train Epoch: 36 [0/7 (0%)]	Loss: 0.430013
Epoch 36 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 36 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:31,884][__main__][INFO] - Epoch 36: Val Loss: 0.9501, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5489754460342695, 'f1_weighted': 0.6835216113026247, 'precision_macro': 0.5935828877005348, 'recall_macro': 0.5338790446841294}
Epoch 37 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:32,580][__main__][INFO] - Train Epoch: 37 [0/7 (0%)]	Loss: 0.356620
Epoch 37 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 37 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:37,300][__main__][INFO] - Epoch 37: Val Loss: 1.0616, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5255572011703933, 'f1_weighted': 0.6534410259289846, 'precision_macro': 0.5828713968957872, 'recall_macro': 0.5108436055469954}
Epoch 38 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:38,004][__main__][INFO] - Train Epoch: 38 [0/7 (0%)]	Loss: 0.350955
Epoch 38 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 38 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:02:42,723][__main__][INFO] - Epoch 38: Val Loss: 0.8516, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.48904157857646224, 'f1_weighted': 0.6557665068832464, 'precision_macro': 0.5762358546754021, 'recall_macro': 0.48222265023112487}
Epoch 39 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:43,415][__main__][INFO] - Train Epoch: 39 [0/7 (0%)]	Loss: 0.349166
Epoch 39 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 39 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:02:48,142][__main__][INFO] - Epoch 39: Val Loss: 0.9261, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5497885028777477, 'f1_weighted': 0.6738248195528936, 'precision_macro': 0.6002921129503408, 'recall_macro': 0.5316063174114022}
Epoch 40 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:48,839][__main__][INFO] - Train Epoch: 40 [0/7 (0%)]	Loss: 0.495543
Epoch 40 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 40 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:02:53,573][__main__][INFO] - Epoch 40: Val Loss: 1.2058, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.3950663349917081, 'f1_weighted': 0.6208150665812849, 'precision_macro': 0.5666666666666667, 'recall_macro': 0.42251540832049306}
Epoch 41 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:54,271][__main__][INFO] - Train Epoch: 41 [0/7 (0%)]	Loss: 0.464439
Epoch 41 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 41 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:02:59,001][__main__][INFO] - Epoch 41: Val Loss: 0.8669, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5406738238631404, 'f1_weighted': 0.6701657597024432, 'precision_macro': 0.5827777777777778, 'recall_macro': 0.525404468412943}
Epoch 42 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:02:59,702][__main__][INFO] - Train Epoch: 42 [0/7 (0%)]	Loss: 0.416796
Epoch 42 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 42 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 42 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 42 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 42 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 42 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 42 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 42 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:03:04,428][__main__][INFO] - Epoch 42: Val Loss: 0.7751, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5922179813401187, 'f1_weighted': 0.704258517454799, 'precision_macro': 0.6440972222222222, 'recall_macro': 0.5708590138674885}
Epoch 43 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:05,124][__main__][INFO] - Train Epoch: 43 [0/7 (0%)]	Loss: 0.260387
Epoch 43 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 43 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 43 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 43 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 43 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 43 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 43 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 43 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 43 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:03:09,856][__main__][INFO] - Epoch 43: Val Loss: 0.7732, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5866843796956942, 'f1_weighted': 0.7069536102489254, 'precision_macro': 0.6059523809523809, 'recall_macro': 0.5813944530046224}
[2025-05-30 16:03:09,858][__main__][INFO] - Early stopping triggered after 43 epochs
[2025-05-30 16:03:09,859][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7624
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38119f5c40>
<numpy.flatiter object at 0x7f38119f5c40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811803960>
<numpy.flatiter object at 0x7f3811f8e490>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702682720>
<numpy.flatiter object at 0x7f3702884f00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f5f7b040>
<numpy.flatiter object at 0x7f3703383d90>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6175480>
<numpy.flatiter object at 0x7f36f7857280>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb:                 Train Loss ‚ñÅ‚ñá‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà
wandb:            Validation Loss ‚ñà‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà
wandb:        Validation f1_macro ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá
wandb:     Validation f1_weighted ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: Validation precision_macro ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.76238
wandb:                 Train Loss 0.26039
wandb:        Validation Accuracy 0.74257
wandb:            Validation Loss 0.77324
wandb:        Validation accuracy 0.74257
wandb:        Validation f1_macro 0.58668
wandb:     Validation f1_weighted 0.70695
wandb: Validation precision_macro 0.60595
wandb:    Validation recall_macro 0.58139
wandb: 
wandb: üöÄ View run feasible-sweep-18 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/h5rrh9bf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_155904-h5rrh9bf/logs
wandb: Agent Starting Run: 2cq8qcop with config:
wandb: 	Fdropout_rate: 0.32540309134329726
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 4
wandb: 	Mdropout_rate: 0.13834795960477084
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.03057212790763271
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_160315-2cq8qcop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/2cq8qcop
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-8.8125, -7.0, 8.8125, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:20,210][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.522314
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:24,883][__main__][INFO] - Epoch 0: Val Loss: 31.6252, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37602d3e80>
<numpy.flatiter object at 0x7f37602d3e80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f6ef80>
<numpy.flatiter object at 0x7f3811f6ef80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f6ef80>
<numpy.flatiter object at 0x7f3811f6ef80>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703064960>
<numpy.flatiter object at 0x7f3703064960>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703064960>
<numpy.flatiter object at 0x7f3703064960>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:03:24,943][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:03:25,041][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:03:25,072][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:25,757][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 21.547935
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.47it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:30,429][__main__][INFO] - Epoch 1: Val Loss: 42.0812, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:31,127][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 37.094383
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:35,803][__main__][INFO] - Epoch 2: Val Loss: 7.8659, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:36,501][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 7.326982
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:41,192][__main__][INFO] - Epoch 3: Val Loss: 5.2634, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:41,888][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 4.633110
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:46,577][__main__][INFO] - Epoch 4: Val Loss: 2.3592, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:47,275][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 1.732722
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:51,978][__main__][INFO] - Epoch 5: Val Loss: 2.3743, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:52,673][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 1.309555
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:03:57,370][__main__][INFO] - Epoch 6: Val Loss: 1.2546, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.23933209647495363, 'f1_weighted': 0.4890244126453462, 'precision_macro': 0.2196241258741259, 'recall_macro': 0.27902542372881356}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38121fae10>
<numpy.flatiter object at 0x7f38121fae10>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811743e80>
<numpy.flatiter object at 0x7f3811743e80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811743e80>
<numpy.flatiter object at 0x7f3811743e80>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370310bc40>
<numpy.flatiter object at 0x7f381259d4c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63d4dc0>
<numpy.flatiter object at 0x7f37035c9c70>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:03:57,435][__main__][INFO] - Saved best model at epoch 6 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:03:57,534][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:03:58,257][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 0.989793
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:02,957][__main__][INFO] - Epoch 7: Val Loss: 1.0076, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.32138694638694637, 'f1_weighted': 0.5072468785340072, 'precision_macro': 0.2639432485322896, 'recall_macro': 0.4433744221879815}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374872b770>
<numpy.flatiter object at 0x7f374872b770>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381211d5d0>
<numpy.flatiter object at 0x7f381211d5d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381211d5d0>
<numpy.flatiter object at 0x7f381211d5d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f374867e240>
<numpy.flatiter object at 0x7f374867e240>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374867e240>
<numpy.flatiter object at 0x7f374867e240>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:04:03,016][__main__][INFO] - Saved best model at epoch 7 with accuracy: 0.6040
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:04:03,118][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:03,835][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 1.319685
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:08,536][__main__][INFO] - Epoch 8: Val Loss: 0.9372, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3821862348178138, 'f1_weighted': 0.5842145348138053, 'precision_macro': 0.5339506172839505, 'recall_macro': 0.3827426810477658}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811792760>
<numpy.flatiter object at 0x7f3811792760>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f4688660>
<numpy.flatiter object at 0x7f36f4688660>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4688660>
<numpy.flatiter object at 0x7f36f4688660>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f4688c60>
<numpy.flatiter object at 0x7f36f4688c60>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4688c60>
<numpy.flatiter object at 0x7f36f4688c60>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:04:08,595][__main__][INFO] - Saved best model at epoch 8 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:04:08,691][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:09,409][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 0.720887
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:14,126][__main__][INFO] - Epoch 9: Val Loss: 0.9147, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.41880764163372863, 'f1_weighted': 0.6005622301360571, 'precision_macro': 0.431488694146922, 'recall_macro': 0.425924499229584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3811800c50>
<numpy.flatiter object at 0x7f3811800c50>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f5d26b00>
<numpy.flatiter object at 0x7f36f5d26b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f5d26b00>
<numpy.flatiter object at 0x7f36f5d26b00>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f381016f530>
<numpy.flatiter object at 0x7f381016f530>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381016f530>
<numpy.flatiter object at 0x7f381016f530>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:04:14,191][__main__][INFO] - Saved best model at epoch 9 with accuracy: 0.6634
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:04:14,293][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:15,017][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 0.765154
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:19,717][__main__][INFO] - Epoch 10: Val Loss: 1.3003, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2896532438478747, 'f1_weighted': 0.5203778767138459, 'precision_macro': 0.4888888888888889, 'recall_macro': 0.3102272727272727}
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:20,417][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 0.797190
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:25,137][__main__][INFO] - Epoch 11: Val Loss: 2.6698, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:25,834][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 1.377364
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:30,549][__main__][INFO] - Epoch 12: Val Loss: 1.3877, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.3243006993006993, 'f1_weighted': 0.5498511389600498, 'precision_macro': 0.5133928571428572, 'recall_macro': 0.33925269645608624}
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:31,247][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 0.679182
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:35,963][__main__][INFO] - Epoch 13: Val Loss: 0.9485, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.40325385847906764, 'f1_weighted': 0.6076662335438294, 'precision_macro': 0.5485347985347986, 'recall_macro': 0.40774268104776584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f48d0ed0>
<numpy.flatiter object at 0x7f36f48d0ed0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63d2800>
<numpy.flatiter object at 0x7f36f63d2800>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63d2800>
<numpy.flatiter object at 0x7f36f63d2800>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63d2e00>
<numpy.flatiter object at 0x7f36f63d2e00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63d2e00>
<numpy.flatiter object at 0x7f36f63d2e00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:04:36,023][__main__][INFO] - Saved best model at epoch 13 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:04:36,117][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:36,840][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 0.776591
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:41,546][__main__][INFO] - Epoch 14: Val Loss: 0.8931, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5031579939668175, 'f1_weighted': 0.6608444215462269, 'precision_macro': 0.5765550239234449, 'recall_macro': 0.488424499229584}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370305d710>
<numpy.flatiter object at 0x7f370305d710>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811a2caa0>
<numpy.flatiter object at 0x7f37486843c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811a2caa0>
<numpy.flatiter object at 0x7f37486843c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811a2d0a0>
<numpy.flatiter object at 0x7f3811a2d0a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811a2d0a0>
<numpy.flatiter object at 0x7f3811a2d0a0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:04:41,608][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:04:41,707][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:42,424][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 0.794357
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:47,139][__main__][INFO] - Epoch 15: Val Loss: 0.9833, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4589591567852438, 'f1_weighted': 0.6234545193649801, 'precision_macro': 0.478497241155469, 'recall_macro': 0.4611517719568567}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:47,834][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 0.664842
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:52,537][__main__][INFO] - Epoch 16: Val Loss: 0.9251, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4137578108166344, 'f1_weighted': 0.6183073381675595, 'precision_macro': 0.5568181818181819, 'recall_macro': 0.4202426810477658}
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:53,235][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.592821
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:04:57,949][__main__][INFO] - Epoch 17: Val Loss: 1.0561, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.44306685440133503, 'f1_weighted': 0.6019710074887339, 'precision_macro': 0.5278745644599303, 'recall_macro': 0.425924499229584}
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:04:58,650][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.720210
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:05:03,362][__main__][INFO] - Epoch 18: Val Loss: 0.8422, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5115730223635722, 'f1_weighted': 0.6513366011748836, 'precision_macro': 0.583789704271632, 'recall_macro': 0.4923536209553159}
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:04,054][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.628754
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:05:08,763][__main__][INFO] - Epoch 19: Val Loss: 0.9718, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.49220850941221667, 'f1_weighted': 0.6498504201169252, 'precision_macro': 0.5683760683760684, 'recall_macro': 0.475924499229584}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:09,466][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.623988
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:05:14,192][__main__][INFO] - Epoch 20: Val Loss: 0.8530, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.6111150070126228, 'f1_weighted': 0.690980795134212, 'precision_macro': 0.6571379781420765, 'recall_macro': 0.6545261941448383}
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:14,894][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 0.819668
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:05:19,624][__main__][INFO] - Epoch 21: Val Loss: 0.9514, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.48708220415537484, 'f1_weighted': 0.6586349691879756, 'precision_macro': 0.5770676691729323, 'recall_macro': 0.4781972265023112}
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:20,329][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 0.617525
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:05:25,055][__main__][INFO] - Epoch 22: Val Loss: 0.8584, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.4142555361305361, 'f1_weighted': 0.5938297675921438, 'precision_macro': 0.5267857142857143, 'recall_macro': 0.39917180277349773}
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:25,755][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.692095
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:05:30,481][__main__][INFO] - Epoch 23: Val Loss: 0.8071, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5635504201680672, 'f1_weighted': 0.6823155004576088, 'precision_macro': 0.5821428571428572, 'recall_macro': 0.5625963020030816}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f43ee030>
<numpy.flatiter object at 0x7f36f43ee030>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63ec2d0>
<numpy.flatiter object at 0x7f36f63ec2d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63ec2d0>
<numpy.flatiter object at 0x7f36f63ec2d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63ec8d0>
<numpy.flatiter object at 0x7f36f63ec8d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63ec8d0>
<numpy.flatiter object at 0x7f36f63ec8d0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:05:30,605][__main__][INFO] - Saved best model at epoch 23 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:05:30,716][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:31,441][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.520801
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:05:36,162][__main__][INFO] - Epoch 24: Val Loss: 0.7862, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.610720855909387, 'f1_weighted': 0.7177338677731451, 'precision_macro': 0.7335416666666666, 'recall_macro': 0.5793335901386749}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f48dd7c0>
<numpy.flatiter object at 0x7f36f48dd7c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703063100>
<numpy.flatiter object at 0x7f3703063100>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703063100>
<numpy.flatiter object at 0x7f3703063100>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703063700>
<numpy.flatiter object at 0x7f3703063700>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703063700>
<numpy.flatiter object at 0x7f3703063700>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:05:36,227][__main__][INFO] - Saved best model at epoch 24 with accuracy: 0.7525
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:05:36,331][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:37,061][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.585580
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:05:41,779][__main__][INFO] - Epoch 25: Val Loss: 0.6762, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6608266326415972, 'f1_weighted': 0.742754775260857, 'precision_macro': 0.7049107142857143, 'recall_macro': 0.6598035439137134}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370308f810>
<numpy.flatiter object at 0x7f370308f810>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37035fa380>
<numpy.flatiter object at 0x7f37035fa380>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035fa380>
<numpy.flatiter object at 0x7f37035fa380>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37035fa380>
<numpy.flatiter object at 0x7f37035fa380>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035fa380>
<numpy.flatiter object at 0x7f37035fa380>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:05:41,848][__main__][INFO] - Saved best model at epoch 25 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:05:41,949][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:42,676][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.415890
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:05:47,391][__main__][INFO] - Epoch 26: Val Loss: 0.7425, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5737394957983193, 'f1_weighted': 0.6922456111157335, 'precision_macro': 0.5984848484848485, 'recall_macro': 0.566833590138675}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:48,096][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.364049
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:05:52,828][__main__][INFO] - Epoch 27: Val Loss: 0.7297, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6006218905472637, 'f1_weighted': 0.7182848135559824, 'precision_macro': 0.6241666666666666, 'recall_macro': 0.5918335901386749}
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:53,531][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.543395
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:05:58,267][__main__][INFO] - Epoch 28: Val Loss: 0.7337, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5984335839598998, 'f1_weighted': 0.7131715427181816, 'precision_macro': 0.6233108108108107, 'recall_macro': 0.5875963020030817}
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:05:58,961][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.459784
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:06:03,696][__main__][INFO] - Epoch 29: Val Loss: 0.7386, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6307669172932331, 'f1_weighted': 0.7235607831459836, 'precision_macro': 0.6534992784992785, 'recall_macro': 0.651328967642527}
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:06:04,390][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 0.509273
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:06:09,118][__main__][INFO] - Epoch 30: Val Loss: 0.7138, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6580418850155692, 'f1_weighted': 0.7178576880244415, 'precision_macro': 0.6841633180252583, 'recall_macro': 0.6550462249614792}
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:06:09,820][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.486005
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:06:14,547][__main__][INFO] - Epoch 31: Val Loss: 0.8078, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5548744019138756, 'f1_weighted': 0.6774657728930787, 'precision_macro': 0.673820395738204, 'recall_macro': 0.512904468412943}
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:06:15,251][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.542519
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:06:19,974][__main__][INFO] - Epoch 32: Val Loss: 0.7368, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.602159501807955, 'f1_weighted': 0.7151032861421941, 'precision_macro': 0.6180555555555556, 'recall_macro': 0.5958590138674885}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:06:20,677][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.469258
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:06:25,404][__main__][INFO] - Epoch 33: Val Loss: 0.7366, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5568846358320042, 'f1_weighted': 0.6877214037193193, 'precision_macro': 0.6015981735159817, 'recall_macro': 0.5379044684129429}
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:06:26,107][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.425232
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:06:30,839][__main__][INFO] - Epoch 34: Val Loss: 0.6969, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6528711484593838, 'f1_weighted': 0.7285492414787698, 'precision_macro': 0.6946844723749672, 'recall_macro': 0.6286016949152543}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:06:31,533][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.520777
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:06:36,271][__main__][INFO] - Epoch 35: Val Loss: 0.7299, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.6857422969187675, 'f1_weighted': 0.717576060127021, 'precision_macro': 0.6964285714285714, 'recall_macro': 0.6815870570107858}
[2025-05-30 16:06:36,273][__main__][INFO] - Early stopping triggered after 35 epochs
[2025-05-30 16:06:36,274][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7723
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381229eb30>
<numpy.flatiter object at 0x7f381229eb30>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702f01cc0>
<numpy.flatiter object at 0x7f3702f01cc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f01cc0>
<numpy.flatiter object at 0x7f3702f01cc0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702f022c0>
<numpy.flatiter object at 0x7f3702f022c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f022c0>
<numpy.flatiter object at 0x7f3702f022c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà
wandb:                 Train Loss ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ
wandb:            Validation Loss ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ
wandb:        Validation f1_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñà
wandb:     Validation f1_weighted ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá
wandb: Validation precision_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñÖ‚ñá‚ñÜ‚ñá‚ñà
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.77228
wandb:                 Train Loss 0.52078
wandb:        Validation Accuracy 0.71287
wandb:            Validation Loss 0.72991
wandb:        Validation accuracy 0.71287
wandb:        Validation f1_macro 0.68574
wandb:     Validation f1_weighted 0.71758
wandb: Validation precision_macro 0.69643
wandb:    Validation recall_macro 0.68159
wandb: 
wandb: üöÄ View run colorful-sweep-19 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/2cq8qcop
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_160315-2cq8qcop/logs
wandb: Agent Starting Run: u9ichn9o with config:
wandb: 	Fdropout_rate: 0.46905693499580303
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 7
wandb: 	Mdropout_rate: 0.13239546909893668
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 128
wandb: 	learning_rate: 0.02185924295572352
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_160645-u9ichn9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/u9ichn9o
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-8.875, -7.0, 8.875, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:06:50,574][__main__][INFO] - Train Epoch: 0 [0/4 (0%)]	Loss: 1.552568
Epoch 0 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 0 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.36s/it]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 0 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:06:54,516][__main__][INFO] - Epoch 0: Val Loss: 45.7889, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3702ee3980>
<numpy.flatiter object at 0x7f3702ee3980>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f4693840>
<numpy.flatiter object at 0x7f36f4693840>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4693840>
<numpy.flatiter object at 0x7f36f4693840>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f4693e40>
<numpy.flatiter object at 0x7f36f4693e40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f4693e40>
<numpy.flatiter object at 0x7f36f4693e40>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:06:54,574][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.1089
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:06:54,672][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:06:54,703][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:06:56,045][__main__][INFO] - Train Epoch: 1 [0/4 (0%)]	Loss: 42.645355
Epoch 1 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.34s/it]Epoch 1 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.11it/s]                                                              Epoch 1 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:06:59,990][__main__][INFO] - Epoch 1: Val Loss: 19.2201, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030541e0>
<numpy.flatiter object at 0x7f37030541e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f489c150>
<numpy.flatiter object at 0x7f36f489c150>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f489c150>
<numpy.flatiter object at 0x7f36f489c150>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f370312ae70>
<numpy.flatiter object at 0x7f370312ae70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f370312ae70>
<numpy.flatiter object at 0x7f370312ae70>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:07:00,058][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:07:00,157][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:01,541][__main__][INFO] - Train Epoch: 2 [0/4 (0%)]	Loss: 19.581831
Epoch 2 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.35s/it]Epoch 2 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 2 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:05,500][__main__][INFO] - Epoch 2: Val Loss: 14.0786, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:06,868][__main__][INFO] - Train Epoch: 3 [0/4 (0%)]	Loss: 15.590020
Epoch 3 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.36s/it]Epoch 3 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.74s/it]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.22s/it]                                                              Epoch 3 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.00s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:12,856][__main__][INFO] - Epoch 3: Val Loss: 24.0416, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:14,503][__main__][INFO] - Train Epoch: 4 [0/4 (0%)]	Loss: 22.921171
Epoch 4 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.64s/it]Epoch 4 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:03<00:02,  1.48s/it]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.42s/it]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.05it/s]                                                              Epoch 4 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:18,484][__main__][INFO] - Epoch 4: Val Loss: 14.9388, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:19,852][__main__][INFO] - Train Epoch: 5 [0/4 (0%)]	Loss: 16.527367
Epoch 5 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.36s/it]Epoch 5 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                              Epoch 5 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:23,844][__main__][INFO] - Epoch 5: Val Loss: 12.4390, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:25,205][__main__][INFO] - Train Epoch: 6 [0/4 (0%)]	Loss: 13.734101
Epoch 6 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.36s/it]Epoch 6 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 6 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:29,195][__main__][INFO] - Epoch 6: Val Loss: 11.8685, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:30,571][__main__][INFO] - Train Epoch: 7 [0/4 (0%)]	Loss: 9.822083
Epoch 7 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 7 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 7 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:34,551][__main__][INFO] - Epoch 7: Val Loss: 6.2710, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:35,927][__main__][INFO] - Train Epoch: 8 [0/4 (0%)]	Loss: 5.948881
Epoch 8 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 8 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                              Epoch 8 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:39,916][__main__][INFO] - Epoch 8: Val Loss: 4.7768, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:41,293][__main__][INFO] - Train Epoch: 9 [0/4 (0%)]	Loss: 2.665234
Epoch 9 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 9 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 9 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:45,281][__main__][INFO] - Epoch 9: Val Loss: 3.2252, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:46,652][__main__][INFO] - Train Epoch: 10 [0/4 (0%)]	Loss: 1.758294
Epoch 10 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 10 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 10 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:50,653][__main__][INFO] - Epoch 10: Val Loss: 2.7640, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
[2025-05-30 16:07:50,655][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:52,031][__main__][INFO] - Train Epoch: 11 [0/4 (0%)]	Loss: 2.054927
Epoch 11 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 11 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 11 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:07:56,030][__main__][INFO] - Epoch 11: Val Loss: 2.6525, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:07:57,399][__main__][INFO] - Train Epoch: 12 [0/4 (0%)]	Loss: 1.632961
Epoch 12 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 12 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 12 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:01,404][__main__][INFO] - Epoch 12: Val Loss: 3.4438, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 13 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:02,783][__main__][INFO] - Train Epoch: 13 [0/4 (0%)]	Loss: 1.747871
Epoch 13 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 13 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 13 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:06,794][__main__][INFO] - Epoch 13: Val Loss: 1.1731, Accuracy: 0.5347, Metrics: {'accuracy': 0.5346534653465347, 'f1_macro': 0.3391743522178305, 'f1_weighted': 0.49489644616635575, 'precision_macro': 0.30648395721925137, 'recall_macro': 0.45069337442218793}
Epoch 14 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:08,165][__main__][INFO] - Train Epoch: 14 [0/4 (0%)]	Loss: 2.250989
Epoch 14 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 14 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 14 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:12,166][__main__][INFO] - Epoch 14: Val Loss: 1.5650, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.3161538461538461, 'f1_weighted': 0.5533891850723535, 'precision_macro': 0.2795774647887324, 'recall_macro': 0.36610169491525424}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3810152650>
<numpy.flatiter object at 0x7f3810152650>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703156570>
<numpy.flatiter object at 0x7f3703156570>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703156570>
<numpy.flatiter object at 0x7f3703156570>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703389a30>
<numpy.flatiter object at 0x7f3703389a30>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703389a30>
<numpy.flatiter object at 0x7f3703389a30>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:08:12,236][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.6238
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:08:12,336][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:13,743][__main__][INFO] - Train Epoch: 15 [0/4 (0%)]	Loss: 1.291417
Epoch 15 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 15 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 15 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 15 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:17,754][__main__][INFO] - Epoch 15: Val Loss: 2.6874, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 16 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:19,123][__main__][INFO] - Train Epoch: 16 [0/4 (0%)]	Loss: 1.363461
Epoch 16 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 16 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 16 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 16 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:23,128][__main__][INFO] - Epoch 16: Val Loss: 1.8745, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 17 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:24,501][__main__][INFO] - Train Epoch: 17 [0/4 (0%)]	Loss: 0.896031
Epoch 17 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 17 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 17 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 17 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:28,511][__main__][INFO] - Epoch 17: Val Loss: 1.7515, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 18 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:29,883][__main__][INFO] - Train Epoch: 18 [0/4 (0%)]	Loss: 0.771342
Epoch 18 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 18 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 18 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 18 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:33,905][__main__][INFO] - Epoch 18: Val Loss: 1.4100, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2796515937731653, 'f1_weighted': 0.5315048183839881, 'precision_macro': 0.25502008032128515, 'recall_macro': 0.31652542372881354}
Epoch 19 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:35,285][__main__][INFO] - Train Epoch: 19 [0/4 (0%)]	Loss: 0.856491
Epoch 19 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 19 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 19 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 19 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:39,307][__main__][INFO] - Epoch 19: Val Loss: 1.1219, Accuracy: 0.3960, Metrics: {'accuracy': 0.39603960396039606, 'f1_macro': 0.3076711855549109, 'f1_weighted': 0.4104348094524324, 'precision_macro': 0.333695652173913, 'recall_macro': 0.4000385208012327}
Epoch 20 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:40,692][__main__][INFO] - Train Epoch: 20 [0/4 (0%)]	Loss: 1.678672
Epoch 20 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 20 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 20 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 20 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:44,702][__main__][INFO] - Epoch 20: Val Loss: 1.5517, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.3139661756683033, 'f1_weighted': 0.5142789238007272, 'precision_macro': 0.2707317073170732, 'recall_macro': 0.3736517719568567}
Epoch 21 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:46,087][__main__][INFO] - Train Epoch: 21 [0/4 (0%)]	Loss: 0.770034
Epoch 21 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 21 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 21 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 21 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:50,107][__main__][INFO] - Epoch 21: Val Loss: 1.1152, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.2963306152705708, 'f1_weighted': 0.5501544965467636, 'precision_macro': 0.2719210174029451, 'recall_macro': 0.3332627118644068}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381229b0f0>
<numpy.flatiter object at 0x7f381229b0f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37035b3120>
<numpy.flatiter object at 0x7f37035b3120>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035b3120>
<numpy.flatiter object at 0x7f37035b3120>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37035b3720>
<numpy.flatiter object at 0x7f37035b3720>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37035b3720>
<numpy.flatiter object at 0x7f37035b3720>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:08:50,175][__main__][INFO] - Saved best model at epoch 21 with accuracy: 0.6436
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:08:50,283][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 22 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:51,693][__main__][INFO] - Train Epoch: 22 [0/4 (0%)]	Loss: 0.696465
Epoch 22 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 22 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 22 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 22 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:08:55,720][__main__][INFO] - Epoch 22: Val Loss: 1.5347, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.28916256157635467, 'f1_weighted': 0.5432765936692191, 'precision_macro': 0.27151162790697675, 'recall_macro': 0.325}
Epoch 23 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:08:57,106][__main__][INFO] - Train Epoch: 23 [0/4 (0%)]	Loss: 0.783255
Epoch 23 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 23 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 23 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 23 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:01,116][__main__][INFO] - Epoch 23: Val Loss: 1.2920, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3194790369447904, 'f1_weighted': 0.5502858505028586, 'precision_macro': 0.5156940760389036, 'recall_macro': 0.3352272727272727}
Epoch 24 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:02,502][__main__][INFO] - Train Epoch: 24 [0/4 (0%)]	Loss: 0.523449
Epoch 24 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 24 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 24 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 24 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:06,512][__main__][INFO] - Epoch 24: Val Loss: 1.4393, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.23024464169733708, 'f1_weighted': 0.4881730433272814, 'precision_macro': 0.20934343434343433, 'recall_macro': 0.275}
Epoch 25 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:07,903][__main__][INFO] - Train Epoch: 25 [0/4 (0%)]	Loss: 0.740348
Epoch 25 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 25 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 25 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.08it/s]                                                               Epoch 25 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:11,930][__main__][INFO] - Epoch 25: Val Loss: 1.2997, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3035714285714286, 'f1_weighted': 0.5548797736916549, 'precision_macro': 0.2759259259259259, 'recall_macro': 0.34152542372881356}
Epoch 26 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:13,316][__main__][INFO] - Train Epoch: 26 [0/4 (0%)]	Loss: 0.622934
Epoch 26 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 26 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 26 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.08it/s]                                                               Epoch 26 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:17,343][__main__][INFO] - Epoch 26: Val Loss: 0.8723, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.41468253968253965, 'f1_weighted': 0.6072450102153072, 'precision_macro': 0.48842592592592593, 'recall_macro': 0.40970724191063174}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37485f27e0>
<numpy.flatiter object at 0x7f37485f27e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38120fc190>
<numpy.flatiter object at 0x7f38120fc190>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38120fc190>
<numpy.flatiter object at 0x7f38120fc190>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38120fc790>
<numpy.flatiter object at 0x7f38120fc790>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38120fc790>
<numpy.flatiter object at 0x7f38120fc790>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:09:17,401][__main__][INFO] - Saved best model at epoch 26 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:09:17,496][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 27 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:18,901][__main__][INFO] - Train Epoch: 27 [0/4 (0%)]	Loss: 0.695706
Epoch 27 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 27 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 27 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 27 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:22,918][__main__][INFO] - Epoch 27: Val Loss: 1.1051, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4404906731549067, 'f1_weighted': 0.624974906249749, 'precision_macro': 0.46296932234432236, 'recall_macro': 0.44069722650231125}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3703046ef0>
<numpy.flatiter object at 0x7f3703046ef0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f38122984a0>
<numpy.flatiter object at 0x7f38122984a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38122984a0>
<numpy.flatiter object at 0x7f38122984a0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748fd1210>
<numpy.flatiter object at 0x7f3748fd1210>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748fd1210>
<numpy.flatiter object at 0x7f3748fd1210>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:09:22,985][__main__][INFO] - Saved best model at epoch 27 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:09:23,084][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 28 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:24,496][__main__][INFO] - Train Epoch: 28 [0/4 (0%)]	Loss: 0.713311
Epoch 28 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 28 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 28 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 28 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:28,508][__main__][INFO] - Epoch 28: Val Loss: 1.5234, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.26686826686826687, 'f1_weighted': 0.5192115885185192, 'precision_macro': 0.24317226890756305, 'recall_macro': 0.3040254237288136}
Epoch 29 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:29,880][__main__][INFO] - Train Epoch: 29 [0/4 (0%)]	Loss: 0.674373
Epoch 29 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 29 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 29 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 29 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:33,894][__main__][INFO] - Epoch 29: Val Loss: 1.3991, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.32345197309986046, 'f1_weighted': 0.5513467029991922, 'precision_macro': 0.5099220411055989, 'recall_macro': 0.33925269645608624}
Epoch 30 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:35,265][__main__][INFO] - Train Epoch: 30 [0/4 (0%)]	Loss: 0.816009
Epoch 30 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 30 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 30 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 30 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:39,279][__main__][INFO] - Epoch 30: Val Loss: 2.8905, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 31 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:40,665][__main__][INFO] - Train Epoch: 31 [0/4 (0%)]	Loss: 1.492485
Epoch 31 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 31 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 31 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.08it/s]                                                               Epoch 31 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:44,691][__main__][INFO] - Epoch 31: Val Loss: 1.1602, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.3701396253092966, 'f1_weighted': 0.5973124884068471, 'precision_macro': 0.5494273658830621, 'recall_macro': 0.3892526964560863}
Epoch 32 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:46,077][__main__][INFO] - Train Epoch: 32 [0/4 (0%)]	Loss: 0.557886
Epoch 32 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 32 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 32 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 32 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:50,090][__main__][INFO] - Epoch 32: Val Loss: 1.1254, Accuracy: 0.6436, Metrics: {'accuracy': 0.6435643564356436, 'f1_macro': 0.3035714285714286, 'f1_weighted': 0.5548797736916549, 'precision_macro': 0.2759259259259259, 'recall_macro': 0.34152542372881356}
Epoch 33 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:51,471][__main__][INFO] - Train Epoch: 33 [0/4 (0%)]	Loss: 0.620802
Epoch 33 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 33 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 33 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 33 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:09:55,491][__main__][INFO] - Epoch 33: Val Loss: 1.0871, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.33088235294117646, 'f1_weighted': 0.5800815375655213, 'precision_macro': 0.29640151515151514, 'recall_macro': 0.37478813559322033}
Epoch 34 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:09:56,872][__main__][INFO] - Train Epoch: 34 [0/4 (0%)]	Loss: 0.546764
Epoch 34 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 34 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 34 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 34 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:00,888][__main__][INFO] - Epoch 34: Val Loss: 1.3337, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.448015873015873, 'f1_weighted': 0.6217664623605218, 'precision_macro': 0.5509259259259259, 'recall_macro': 0.4324345146379045}
Epoch 35 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:10:02,272][__main__][INFO] - Train Epoch: 35 [0/4 (0%)]	Loss: 0.609151
Epoch 35 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 35 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.38s/it]Epoch 35 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.38s/it]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 35 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:06,300][__main__][INFO] - Epoch 35: Val Loss: 0.9374, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.48094970722707947, 'f1_weighted': 0.6292977817874833, 'precision_macro': 0.5137820512820513, 'recall_macro': 0.5125963020030817}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f5d1d3c0>
<numpy.flatiter object at 0x7f36f5d1d3c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702cbf570>
<numpy.flatiter object at 0x7f3702cbf570>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702cbf570>
<numpy.flatiter object at 0x7f3702cbf570>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702cbfb70>
<numpy.flatiter object at 0x7f3702cbfb70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702cbfb70>
<numpy.flatiter object at 0x7f3702cbfb70>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:10:06,364][__main__][INFO] - Saved best model at epoch 35 with accuracy: 0.6931
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:10:06,465][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 36 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:10:07,872][__main__][INFO] - Train Epoch: 36 [0/4 (0%)]	Loss: 0.640691
Epoch 36 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 36 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 36 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 36 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:11,888][__main__][INFO] - Epoch 36: Val Loss: 1.1143, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.35920263788968826, 'f1_weighted': 0.586354678633331, 'precision_macro': 0.540625, 'recall_macro': 0.3767526964560863}
[2025-05-30 16:10:11,889][__main__][INFO] - Early stopping triggered after 36 epochs
[2025-05-30 16:10:11,890][__main__][INFO] - Saving best confusion matrix with accuracy: 0.6931
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f4692c40>
<numpy.flatiter object at 0x7f36f4692c40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811cb5b40>
<numpy.flatiter object at 0x7f3811cb5b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811cb5b40>
<numpy.flatiter object at 0x7f3811cb5b40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811cb5b40>
<numpy.flatiter object at 0x7f3811cb5b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811cb5b40>
<numpy.flatiter object at 0x7f3811cb5b40>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)wandb: uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:            Validation Loss ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÇ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:        Validation f1_macro ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ
wandb:     Validation f1_weighted ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: Validation precision_macro ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñá‚ñá‚ñÑ‚ñá‚ñÉ‚ñà‚ñÑ‚ñÖ‚ñà‚ñà‚ñà
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñÑ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.69307
wandb:                 Train Loss 0.64069
wandb:        Validation Accuracy 0.66337
wandb:            Validation Loss 1.11428
wandb:        Validation accuracy 0.66337
wandb:        Validation f1_macro 0.3592
wandb:     Validation f1_weighted 0.58635
wandb: Validation precision_macro 0.54063
wandb:    Validation recall_macro 0.37675
wandb: 
wandb: üöÄ View run decent-sweep-20 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/u9ichn9o
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 7 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_160645-u9ichn9o/logs
wandb: Agent Starting Run: jus8vbva with config:
wandb: 	Fdropout_rate: 0.20607557102573684
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 4
wandb: 	Mdropout_rate: 0.20019852766236412
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.01844305690346792
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_161019-jus8vbva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/jus8vbva
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:24,333][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.517558
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.47it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.54it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.03it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:28,997][__main__][INFO] - Epoch 0: Val Loss: 44.0486, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37035daf00>
<numpy.flatiter object at 0x7f37035daf00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3748ffb0b0>
<numpy.flatiter object at 0x7f3748ffb0b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748ffb0b0>
<numpy.flatiter object at 0x7f3748ffb0b0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748719020>
<numpy.flatiter object at 0x7f3748719020>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748719020>
<numpy.flatiter object at 0x7f3748719020>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:10:29,061][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:10:29,161][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:10:29,192][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:29,871][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 33.004505
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.47it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.47it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.90it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:34,530][__main__][INFO] - Epoch 1: Val Loss: 27.4497, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:35,224][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 24.207287
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:39,893][__main__][INFO] - Epoch 2: Val Loss: 13.9486, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:40,580][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 12.783040
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.47it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.47it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.47it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:45,244][__main__][INFO] - Epoch 3: Val Loss: 11.1577, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:45,929][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 10.940306
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.47it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.47it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.89it/s]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:50,606][__main__][INFO] - Epoch 4: Val Loss: 6.5102, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:51,302][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 6.326329
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.47it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.53it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:10:55,976][__main__][INFO] - Epoch 5: Val Loss: 3.3856, Accuracy: 0.1386, Metrics: {'accuracy': 0.13861386138613863, 'f1_macro': 0.07521139296840232, 'f1_weighted': 0.0780270283370126, 'precision_macro': 0.21614583333333334, 'recall_macro': 0.2627118644067797}
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:10:56,663][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 2.929013
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:01,350][__main__][INFO] - Epoch 6: Val Loss: 1.8834, Accuracy: 0.4950, Metrics: {'accuracy': 0.49504950495049505, 'f1_macro': 0.26618426153249775, 'f1_weighted': 0.45881794536864207, 'precision_macro': 0.2485294117647059, 'recall_macro': 0.3358050847457627}
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:02,038][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 1.908010
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.02it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:06,723][__main__][INFO] - Epoch 7: Val Loss: 1.4131, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.20864661654135339, 'f1_weighted': 0.4599493783964863, 'precision_macro': 0.18716397849462366, 'recall_macro': 0.2582627118644068}
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:07,417][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 1.301642
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            [2025-05-30 16:11:12,117][__main__][INFO] - Epoch 8: Val Loss: 1.4395, Accuracy: 0.2277, Metrics: {'accuracy': 0.22772277227722773, 'f1_macro': 0.22490153656743622, 'f1_weighted': 0.21617409259169293, 'precision_macro': 0.37749615975422424, 'recall_macro': 0.3523882896764253}
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:12,804][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 1.280815
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.88it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            [2025-05-30 16:11:17,502][__main__][INFO] - Epoch 9: Val Loss: 1.2420, Accuracy: 0.4158, Metrics: {'accuracy': 0.4158415841584158, 'f1_macro': 0.3210743022378677, 'f1_weighted': 0.4614621947485168, 'precision_macro': 0.3449730094466936, 'recall_macro': 0.3404468412942989}
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:18,202][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 1.162764
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:22,909][__main__][INFO] - Epoch 10: Val Loss: 1.1730, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.2989251297257227, 'f1_weighted': 0.5358938414226893, 'precision_macro': 0.27677376171352075, 'recall_macro': 0.33305084745762714}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3810140dc0>
<numpy.flatiter object at 0x7f3810140dc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f63ef5c0>
<numpy.flatiter object at 0x7f36f63ef5c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63ef5c0>
<numpy.flatiter object at 0x7f36f63ef5c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f63efbc0>
<numpy.flatiter object at 0x7f36f63efbc0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f63efbc0>
<numpy.flatiter object at 0x7f36f63efbc0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:11:22,976][__main__][INFO] - Saved best model at epoch 10 with accuracy: 0.6238
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:11:23,077][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:11:23,115][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:23,802][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 0.979341
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.46it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.46it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:28,510][__main__][INFO] - Epoch 11: Val Loss: 1.4457, Accuracy: 0.5545, Metrics: {'accuracy': 0.5544554455445545, 'f1_macro': 0.20069279064732626, 'f1_weighted': 0.4440333619852568, 'precision_macro': 0.17550505050505052, 'recall_macro': 0.24555084745762712}
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:29,200][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 1.194409
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:33,920][__main__][INFO] - Epoch 12: Val Loss: 1.3084, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.22281105990783412, 'f1_weighted': 0.4527353196149108, 'precision_macro': 0.234375, 'recall_macro': 0.2684899845916795}
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:34,620][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 0.867680
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:11:39,336][__main__][INFO] - Epoch 13: Val Loss: 1.3657, Accuracy: 0.3564, Metrics: {'accuracy': 0.3564356435643564, 'f1_macro': 0.3120985603543743, 'f1_weighted': 0.39292896067015337, 'precision_macro': 0.34789712986643934, 'recall_macro': 0.36852850539291215}
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:40,025][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 1.355856
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.46it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.46it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.46it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:44,743][__main__][INFO] - Epoch 14: Val Loss: 1.4507, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.2636319376825706, 'f1_weighted': 0.4697812527114445, 'precision_macro': 0.398989898989899, 'recall_macro': 0.29545454545454547}
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:45,433][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 1.223782
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:50,147][__main__][INFO] - Epoch 15: Val Loss: 1.9425, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.2636319376825706, 'f1_weighted': 0.4697812527114445, 'precision_macro': 0.398989898989899, 'recall_macro': 0.29545454545454547}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:50,850][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 1.590452
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:11:55,569][__main__][INFO] - Epoch 16: Val Loss: 1.2255, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.1895424836601307, 'f1_weighted': 0.44289134795832524, 'precision_macro': 0.15425531914893617, 'recall_macro': 0.2457627118644068}
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:11:56,268][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.885733
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:12:00,991][__main__][INFO] - Epoch 17: Val Loss: 1.1761, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.35916214554593207, 'f1_weighted': 0.538014631120226, 'precision_macro': 0.34930555555555554, 'recall_macro': 0.3901771956856703}
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:01,684][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.972537
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:12:06,414][__main__][INFO] - Epoch 18: Val Loss: 0.9635, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.42415966386554627, 'f1_weighted': 0.6084616024627674, 'precision_macro': 0.46759259259259256, 'recall_macro': 0.41993451463790443}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370313c740>
<numpy.flatiter object at 0x7f370313c740>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f374873a370>
<numpy.flatiter object at 0x7f374873a370>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f374873a370>
<numpy.flatiter object at 0x7f374873a370>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3702689f70>
<numpy.flatiter object at 0x7f3702689f70>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702689f70>
<numpy.flatiter object at 0x7f3702689f70>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:12:06,481][__main__][INFO] - Saved best model at epoch 18 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:12:06,582][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:07,307][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.749454
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:12:12,040][__main__][INFO] - Epoch 19: Val Loss: 1.3346, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.325990445806114, 'f1_weighted': 0.5407537360815639, 'precision_macro': 0.48579545454545453, 'recall_macro': 0.33295454545454545}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:12,733][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.885478
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:12:17,456][__main__][INFO] - Epoch 20: Val Loss: 0.9033, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.437037037037037, 'f1_weighted': 0.6183665985646184, 'precision_macro': 0.4392543859649123, 'recall_macro': 0.4466872110939908}
[2025-05-30 16:12:17,458][__main__][INFO] - Saved model at epoch 20
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:18,160][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 0.507691
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:12:22,890][__main__][INFO] - Epoch 21: Val Loss: 0.9522, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.3644179894179894, 'f1_weighted': 0.5884278904080884, 'precision_macro': 0.5445574162679425, 'recall_macro': 0.3807781201848998}
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:23,596][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 0.619344
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:12:28,321][__main__][INFO] - Epoch 22: Val Loss: 1.0434, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.4613188360450563, 'f1_weighted': 0.6219051661111041, 'precision_macro': 0.5487804878048781, 'recall_macro': 0.4426617873651772}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486ac1e0>
<numpy.flatiter object at 0x7f37486ac1e0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f6402290>
<numpy.flatiter object at 0x7f36f6402290>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6402290>
<numpy.flatiter object at 0x7f36f6402290>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f36f6402290>
<numpy.flatiter object at 0x7f36f6402290>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f6402290>
<numpy.flatiter object at 0x7f36f6402290>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:12:28,382][__main__][INFO] - Saved best model at epoch 22 with accuracy: 0.6832
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:12:28,475][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:29,197][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.663074
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:12:33,934][__main__][INFO] - Epoch 23: Val Loss: 0.8681, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.5665238905513506, 'f1_weighted': 0.6584938233305815, 'precision_macro': 0.5777427792513999, 'recall_macro': 0.5659861325115563}
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:34,637][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.753897
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:12:39,372][__main__][INFO] - Epoch 24: Val Loss: 1.1046, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.43367569930069927, 'f1_weighted': 0.5956432181679706, 'precision_macro': 0.5238095238095238, 'recall_macro': 0.41766178736517723}
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:40,065][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.675109
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:12:44,788][__main__][INFO] - Epoch 25: Val Loss: 0.8966, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5802804161013116, 'f1_weighted': 0.6898361477938839, 'precision_macro': 0.5995804195804196, 'recall_macro': 0.5810862865947611}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370268bf40>
<numpy.flatiter object at 0x7f370268bf40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f36f46a9180>
<numpy.flatiter object at 0x7f36f46a9180>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f36f46a9180>
<numpy.flatiter object at 0x7f36f46a9180>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3748794560>
<numpy.flatiter object at 0x7f3748794560>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3748794560>
<numpy.flatiter object at 0x7f3748794560>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:12:44,855][__main__][INFO] - Saved best model at epoch 25 with accuracy: 0.7327
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:12:44,954][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:45,678][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.391602
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:12:50,404][__main__][INFO] - Epoch 26: Val Loss: 0.8913, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5170954145774289, 'f1_weighted': 0.6514068673054355, 'precision_macro': 0.5788461538461538, 'recall_macro': 0.4963790446841294}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:51,108][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.359067
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:12:55,830][__main__][INFO] - Epoch 27: Val Loss: 0.9344, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.5384090336269907, 'f1_weighted': 0.5959218879914333, 'precision_macro': 0.5731360247317694, 'recall_macro': 0.5892141756548537}
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:12:56,523][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.924272
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:01,249][__main__][INFO] - Epoch 28: Val Loss: 1.1180, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.471053276178812, 'f1_weighted': 0.594746957855614, 'precision_macro': 0.523995983935743, 'recall_macro': 0.4978235747303543}
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:01,944][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.646312
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:06,673][__main__][INFO] - Epoch 29: Val Loss: 1.2531, Accuracy: 0.4851, Metrics: {'accuracy': 0.48514851485148514, 'f1_macro': 0.31160287081339716, 'f1_weighted': 0.4659860722914397, 'precision_macro': 0.5178571428571428, 'recall_macro': 0.3748459167950693}
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:07,376][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 1.032036
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:12,100][__main__][INFO] - Epoch 30: Val Loss: 0.8630, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6858549783549783, 'f1_weighted': 0.7429184347006129, 'precision_macro': 0.6958413171527926, 'recall_macro': 0.6860362095531587}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381211bb00>
<numpy.flatiter object at 0x7f381211bb00>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f1c9b0>
<numpy.flatiter object at 0x7f3811f1c9b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f1c9b0>
<numpy.flatiter object at 0x7f3811f1c9b0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f1cfb0>
<numpy.flatiter object at 0x7f3811f1cfb0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f1cfb0>
<numpy.flatiter object at 0x7f3811f1cfb0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:13:12,163][__main__][INFO] - Saved best model at epoch 30 with accuracy: 0.7426
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:13:12,257][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:13:12,289][__main__][INFO] - Saved model at epoch 30
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:12,983][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.674625
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:17,711][__main__][INFO] - Epoch 31: Val Loss: 0.8207, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5473763368983957, 'f1_weighted': 0.6729761211415259, 'precision_macro': 0.5706168831168832, 'recall_macro': 0.5500963020030817}
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:18,404][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.567336
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:13:23,142][__main__][INFO] - Epoch 32: Val Loss: 0.9163, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.537712895377129, 'f1_weighted': 0.6722796367227963, 'precision_macro': 0.5857371794871795, 'recall_macro': 0.5213790446841294}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:23,844][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.545515
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:28,572][__main__][INFO] - Epoch 33: Val Loss: 0.8132, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6106442577030813, 'f1_weighted': 0.716809496075658, 'precision_macro': 0.6433566433566433, 'recall_macro': 0.6020608628659476}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37486b0d70>
<numpy.flatiter object at 0x7f37486b0d70>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f33440>
<numpy.flatiter object at 0x7f3811f33440>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f33440>
<numpy.flatiter object at 0x7f3811f33440>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38122eca80>
<numpy.flatiter object at 0x7f38122eca80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38122eca80>
<numpy.flatiter object at 0x7f38122eca80>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:13:28,637][__main__][INFO] - Saved best model at epoch 33 with accuracy: 0.7624
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:13:28,736][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:29,461][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.406116
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:34,183][__main__][INFO] - Epoch 34: Val Loss: 0.7831, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5633861940298507, 'f1_weighted': 0.6715014038717304, 'precision_macro': 0.6141666666666666, 'recall_macro': 0.5416217257318953}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:34,886][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.472366
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:39,610][__main__][INFO] - Epoch 35: Val Loss: 0.7785, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5545314174071974, 'f1_weighted': 0.6812314243335849, 'precision_macro': 0.5904761904761905, 'recall_macro': 0.5419298921417566}
Epoch 36 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:40,305][__main__][INFO] - Train Epoch: 36 [0/7 (0%)]	Loss: 0.414820
Epoch 36 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 36 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:45,047][__main__][INFO] - Epoch 36: Val Loss: 0.7573, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.6085635058721183, 'f1_weighted': 0.6843827923462202, 'precision_macro': 0.6434384164222874, 'recall_macro': 0.5846879815100154}
Epoch 37 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:45,739][__main__][INFO] - Train Epoch: 37 [0/7 (0%)]	Loss: 0.420252
Epoch 37 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 37 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:50,465][__main__][INFO] - Epoch 37: Val Loss: 0.7410, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.7042112394808159, 'f1_weighted': 0.7428353746799584, 'precision_macro': 0.7149621212121212, 'recall_macro': 0.7065870570107858}
Epoch 38 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:51,167][__main__][INFO] - Train Epoch: 38 [0/7 (0%)]	Loss: 0.532639
Epoch 38 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 38 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:13:55,900][__main__][INFO] - Epoch 38: Val Loss: 0.7157, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6436011904761905, 'f1_weighted': 0.7259252710985384, 'precision_macro': 0.6927917620137299, 'recall_macro': 0.6328389830508475}
Epoch 39 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:13:56,595][__main__][INFO] - Train Epoch: 39 [0/7 (0%)]	Loss: 0.352011
Epoch 39 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 39 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:14:01,323][__main__][INFO] - Epoch 39: Val Loss: 0.9084, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.5808947135589472, 'f1_weighted': 0.6955919679559197, 'precision_macro': 0.6217948717948718, 'recall_macro': 0.566833590138675}
Epoch 40 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:02,021][__main__][INFO] - Train Epoch: 40 [0/7 (0%)]	Loss: 0.469257
Epoch 40 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 40 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:14:06,751][__main__][INFO] - Epoch 40: Val Loss: 0.7547, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6160953725892959, 'f1_weighted': 0.7094987870919922, 'precision_macro': 0.6333333333333333, 'recall_macro': 0.6161016949152542}
Epoch 41 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:07,458][__main__][INFO] - Train Epoch: 41 [0/7 (0%)]	Loss: 0.427959
Epoch 41 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 41 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:14:12,177][__main__][INFO] - Epoch 41: Val Loss: 0.8149, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.6328073089700996, 'f1_weighted': 0.7255978421762442, 'precision_macro': 0.693671679197995, 'recall_macro': 0.614348998459168}
Epoch 42 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:12,880][__main__][INFO] - Train Epoch: 42 [0/7 (0%)]	Loss: 0.430017
Epoch 42 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 42 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 42 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 42 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 42 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 42 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 42 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 42 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:14:17,610][__main__][INFO] - Epoch 42: Val Loss: 0.9126, Accuracy: 0.7525, Metrics: {'accuracy': 0.7524752475247525, 'f1_macro': 0.5851851851851851, 'f1_weighted': 0.7036670333700037, 'precision_macro': 0.6060855263157895, 'recall_macro': 0.5793335901386749}
Epoch 43 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:18,301][__main__][INFO] - Train Epoch: 43 [0/7 (0%)]	Loss: 0.466846
Epoch 43 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 43 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 43 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 43 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 43 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 43 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 43 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 43 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 43 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:14:23,037][__main__][INFO] - Epoch 43: Val Loss: 0.8735, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.592824074074074, 'f1_weighted': 0.7082324899156582, 'precision_macro': 0.6040823211875843, 'recall_macro': 0.6122881355932204}
Epoch 44 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:23,740][__main__][INFO] - Train Epoch: 44 [0/7 (0%)]	Loss: 0.441859
Epoch 44 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 44 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 44 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 44 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 44 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 44 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 44 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 44 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 44 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 44 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:14:28,462][__main__][INFO] - Epoch 44: Val Loss: 0.8040, Accuracy: 0.7624, Metrics: {'accuracy': 0.7623762376237624, 'f1_macro': 0.6070243175506334, 'f1_weighted': 0.7153084745580838, 'precision_macro': 0.6122813990461049, 'recall_macro': 0.6103235747303544}
Epoch 45 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:29,166][__main__][INFO] - Train Epoch: 45 [0/7 (0%)]	Loss: 0.435834
Epoch 45 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 45 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 45 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 45 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 45 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 45 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 45 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 45 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 45 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 45 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:14:33,889][__main__][INFO] - Epoch 45: Val Loss: 0.8181, Accuracy: 0.7723, Metrics: {'accuracy': 0.7722772277227723, 'f1_macro': 0.6502574002574002, 'f1_weighted': 0.7371204301897373, 'precision_macro': 0.8648267526188558, 'recall_macro': 0.6330508474576271}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3812258d80>
<numpy.flatiter object at 0x7f3812258d80>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3812276240>
<numpy.flatiter object at 0x7f3812276240>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812276240>
<numpy.flatiter object at 0x7f3812276240>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3812276240>
<numpy.flatiter object at 0x7f3812276240>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812276240>
<numpy.flatiter object at 0x7f3812276240>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:14:33,954][__main__][INFO] - Saved best model at epoch 45 with accuracy: 0.7723
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.5625, -4.0, 117.5625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.5625, -4.0, 117.5625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.5625, -4.0, 117.5625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-117.5625, -4.0, 117.5625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:14:34,053][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 46 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:34,779][__main__][INFO] - Train Epoch: 46 [0/7 (0%)]	Loss: 0.446631
Epoch 46 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 46 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 46 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 46 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 46 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 46 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 46 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 46 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 46 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 46 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:14:39,509][__main__][INFO] - Epoch 46: Val Loss: 0.7769, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6506393712276065, 'f1_weighted': 0.7259714161286671, 'precision_macro': 0.6773751563040413, 'recall_macro': 0.638828967642527}
Epoch 47 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:40,212][__main__][INFO] - Train Epoch: 47 [0/7 (0%)]	Loss: 0.286360
Epoch 47 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 47 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 47 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 47 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 47 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 47 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 47 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 47 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 47 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 47 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:14:44,940][__main__][INFO] - Epoch 47: Val Loss: 0.7946, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6488678804855275, 'f1_weighted': 0.7250580100026808, 'precision_macro': 0.669694111858291, 'recall_macro': 0.6490562403697997}
Epoch 48 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:14:45,646][__main__][INFO] - Train Epoch: 48 [0/7 (0%)]	Loss: 0.365977
Epoch 48 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 48 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 48 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 48 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 48 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 48 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 48 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                               Epoch 48 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 48 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 48 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:14:50,366][__main__][INFO] - Epoch 48: Val Loss: 0.8549, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.5691343743975323, 'f1_weighted': 0.6906119067661538, 'precision_macro': 0.584346991037132, 'recall_macro': 0.5688944530046225}
[2025-05-30 16:14:50,367][__main__][INFO] - Early stopping triggered after 48 epochs
[2025-05-30 16:14:50,368][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7723
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f381253a3d0>
<numpy.flatiter object at 0x7f381253a3d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030d4a80>
<numpy.flatiter object at 0x7f37030d4a80>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030d4a80>
<numpy.flatiter object at 0x7f37030d4a80>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37030d5080>
<numpy.flatiter object at 0x7f37030d5080>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030d5080>
<numpy.flatiter object at 0x7f37030d5080>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-172.0, -4.0, 172.0, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)wandb: uploading output.log; uploading history steps 339-358, summary, console lines 2110-2691; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            Validation Loss ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:        Validation f1_macro ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:     Validation f1_weighted ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb: Validation precision_macro ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.77228
wandb:                 Train Loss 0.36598
wandb:        Validation Accuracy 0.73267
wandb:            Validation Loss 0.85488
wandb:        Validation accuracy 0.73267
wandb:        Validation f1_macro 0.56913
wandb:     Validation f1_weighted 0.69061
wandb: Validation precision_macro 0.58435
wandb:    Validation recall_macro 0.56889
wandb: 
wandb: üöÄ View run confused-sweep-21 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/jus8vbva
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_161019-jus8vbva/logs
wandb: Agent Starting Run: 98qiujxv with config:
wandb: 	Fdropout_rate: 0.37563930238118226
wandb: 	Fnum_heads: 2
wandb: 	Fnum_layers: 7
wandb: 	Mdropout_rate: 0.17070355541755494
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 64
wandb: 	learning_rate: 0.03353937142755636
wandb: 	pretrained_model_name: dmis-lab/biobert-base-cased-v1.1
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_161456-98qiujxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/98qiujxv
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-8.8125, -7.0, 8.8125, 7.0)
(-172.0, -4.0, 172.0, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:01,200][__main__][INFO] - Train Epoch: 0 [0/7 (0%)]	Loss: 1.575011
Epoch 0 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.46it/s]Epoch 0 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 0 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 0 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 0 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 0 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.87it/s]                                                              Epoch 0 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 0 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.01it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:05,915][__main__][INFO] - Epoch 0: Val Loss: 44.1885, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37492931c0>
<numpy.flatiter object at 0x7f37492931c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37492931c0>
<numpy.flatiter object at 0x7f37492931c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492931c0>
<numpy.flatiter object at 0x7f37492931c0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37492931c0>
<numpy.flatiter object at 0x7f37492931c0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492931c0>
<numpy.flatiter object at 0x7f37492931c0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:15:05,982][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:15:06,076][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:15:06,108][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:06,798][__main__][INFO] - Train Epoch: 1 [0/7 (0%)]	Loss: 42.040508
Epoch 1 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 1 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 1 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 1 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 1 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 1 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 1 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 1 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:11,529][__main__][INFO] - Epoch 1: Val Loss: 28.5861, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 2 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:12,222][__main__][INFO] - Train Epoch: 2 [0/7 (0%)]	Loss: 23.357777
Epoch 2 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 2 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.45it/s]Epoch 2 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 2 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 2 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 2 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 2 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.52it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:16,948][__main__][INFO] - Epoch 2: Val Loss: 21.2991, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:17,652][__main__][INFO] - Train Epoch: 3 [0/7 (0%)]	Loss: 19.813406
Epoch 3 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 3 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 3 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.45it/s]Epoch 3 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 3 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 3 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 3 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 3 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:22,382][__main__][INFO] - Epoch 3: Val Loss: 5.5738, Accuracy: 0.1980, Metrics: {'accuracy': 0.19801980198019803, 'f1_macro': 0.08264462809917356, 'f1_weighted': 0.06546109156370182, 'precision_macro': 0.04950495049504951, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:23,085][__main__][INFO] - Train Epoch: 4 [0/7 (0%)]	Loss: 3.765913
Epoch 4 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 4 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 4 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 4 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 4 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 4 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 4 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 4 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:27,825][__main__][INFO] - Epoch 4: Val Loss: 1.9184, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.216025641025641, 'f1_weighted': 0.4414064483371414, 'precision_macro': 0.20940721649484537, 'recall_macro': 0.2642526964560863}
Epoch 5 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:28,519][__main__][INFO] - Train Epoch: 5 [0/7 (0%)]	Loss: 1.746768
Epoch 5 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 5 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 5 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 5 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.45it/s]Epoch 5 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.45it/s]Epoch 5 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 5 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 5 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:33,263][__main__][INFO] - Epoch 5: Val Loss: 1.4487, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:33,968][__main__][INFO] - Train Epoch: 6 [0/7 (0%)]	Loss: 1.476930
Epoch 6 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 6 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 6 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 6 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 6 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 6 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                              Epoch 6 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 6 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.48it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.97it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:38,748][__main__][INFO] - Epoch 6: Val Loss: 1.7498, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 7 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:39,446][__main__][INFO] - Train Epoch: 7 [0/7 (0%)]	Loss: 1.692096
Epoch 7 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 7 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 7 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 7 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 7 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 7 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.45it/s]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 7 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 7 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:44,188][__main__][INFO] - Epoch 7: Val Loss: 1.4915, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:44,887][__main__][INFO] - Train Epoch: 8 [0/7 (0%)]	Loss: 1.505925
Epoch 8 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 8 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 8 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 8 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 8 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 8 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                              Epoch 8 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 8 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:49,629][__main__][INFO] - Epoch 8: Val Loss: 1.1997, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:50,335][__main__][INFO] - Train Epoch: 9 [0/7 (0%)]	Loss: 1.211334
Epoch 9 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 9 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 9 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 9 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 9 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                              Epoch 9 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 9 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:15:55,081][__main__][INFO] - Epoch 9: Val Loss: 1.1322, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 10 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:15:55,788][__main__][INFO] - Train Epoch: 10 [0/7 (0%)]	Loss: 1.025322
Epoch 10 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 10 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 10 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 10 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 10 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 10 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 10 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:00,533][__main__][INFO] - Epoch 10: Val Loss: 1.1141, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
[2025-05-30 16:16:00,534][__main__][INFO] - Saved model at epoch 10
Epoch 11 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:01,238][__main__][INFO] - Train Epoch: 11 [0/7 (0%)]	Loss: 1.123727
Epoch 11 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 11 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 11 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 11 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 11 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 11 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.86it/s]                                                               Epoch 11 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 11 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:05,989][__main__][INFO] - Epoch 11: Val Loss: 1.2142, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18670886075949367, 'f1_weighted': 0.43627020929941096, 'precision_macro': 0.14898989898989898, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:06,693][__main__][INFO] - Train Epoch: 12 [0/7 (0%)]	Loss: 1.122193
Epoch 12 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 12 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 12 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 12 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 12 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 12 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 12 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:11,441][__main__][INFO] - Epoch 12: Val Loss: 1.2550, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 13 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:12,143][__main__][INFO] - Train Epoch: 13 [0/7 (0%)]	Loss: 1.145208
Epoch 13 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 13 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 13 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 13 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 13 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 13 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 13 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 13 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:16,905][__main__][INFO] - Epoch 13: Val Loss: 0.9646, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.4079328756674294, 'f1_weighted': 0.5777858335032588, 'precision_macro': 0.5042194092827004, 'recall_macro': 0.39472265023112485}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370243ac40>
<numpy.flatiter object at 0x7f370243ac40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f16190>
<numpy.flatiter object at 0x7f3811f16190>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f16190>
<numpy.flatiter object at 0x7f3811f16190>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f16790>
<numpy.flatiter object at 0x7f3811f16790>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f16790>
<numpy.flatiter object at 0x7f3811f16790>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:16:16,987][__main__][INFO] - Saved best model at epoch 13 with accuracy: 0.6337
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:16:17,089][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 14 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:17,823][__main__][INFO] - Train Epoch: 14 [0/7 (0%)]	Loss: 0.939409
Epoch 14 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 14 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 14 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 14 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 14 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 14 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 14 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 14 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:22,575][__main__][INFO] - Epoch 14: Val Loss: 0.9818, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.36538631346578365, 'f1_weighted': 0.5385264354249996, 'precision_macro': 0.5076086956521739, 'recall_macro': 0.36167180277349775}
Epoch 15 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:23,282][__main__][INFO] - Train Epoch: 15 [0/7 (0%)]	Loss: 0.788614
Epoch 15 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 15 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 15 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 15 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 15 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 15 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 15 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 15 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 15 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:28,032][__main__][INFO] - Epoch 15: Val Loss: 1.2511, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.18553459119496854, 'f1_weighted': 0.43352637150507495, 'precision_macro': 0.1475, 'recall_macro': 0.25}
Epoch 16 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:28,729][__main__][INFO] - Train Epoch: 16 [0/7 (0%)]	Loss: 0.827708
Epoch 16 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 16 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 16 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 16 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 16 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 16 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 16 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 16 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 16 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:33,477][__main__][INFO] - Epoch 16: Val Loss: 1.0657, Accuracy: 0.6040, Metrics: {'accuracy': 0.6039603960396039, 'f1_macro': 0.3259009009009009, 'f1_weighted': 0.5080456694318081, 'precision_macro': 0.4101123595505618, 'recall_macro': 0.33243451463790447}
Epoch 17 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:34,187][__main__][INFO] - Train Epoch: 17 [0/7 (0%)]	Loss: 0.636887
Epoch 17 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 17 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 17 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 17 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 17 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 17 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 17 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 17 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 17 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 17 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:38,933][__main__][INFO] - Epoch 17: Val Loss: 1.1744, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.32538631346578367, 'f1_weighted': 0.5068432671081678, 'precision_macro': 0.40760869565217395, 'recall_macro': 0.33667180277349773}
Epoch 18 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:39,634][__main__][INFO] - Train Epoch: 18 [0/7 (0%)]	Loss: 0.653773
Epoch 18 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 18 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 18 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 18 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 18 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 18 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 18 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 18 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 18 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:16:44,384][__main__][INFO] - Epoch 18: Val Loss: 1.3624, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.2950409463148317, 'f1_weighted': 0.48572509662249214, 'precision_macro': 0.4005102040816326, 'recall_macro': 0.3181818181818182}
Epoch 19 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:45,091][__main__][INFO] - Train Epoch: 19 [0/7 (0%)]	Loss: 0.831422
Epoch 19 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 19 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 19 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 19 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 19 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 19 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 19 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 19 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 19 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:16:49,854][__main__][INFO] - Epoch 19: Val Loss: 1.1109, Accuracy: 0.4158, Metrics: {'accuracy': 0.4158415841584158, 'f1_macro': 0.4502195513105023, 'f1_weighted': 0.4269748998085847, 'precision_macro': 0.6115196078431373, 'recall_macro': 0.5442411402157165}
Epoch 20 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:50,557][__main__][INFO] - Train Epoch: 20 [0/7 (0%)]	Loss: 0.873433
Epoch 20 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 20 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 20 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 20 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 20 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 20 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 20 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 20 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 20 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 20 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:16:55,322][__main__][INFO] - Epoch 20: Val Loss: 1.1492, Accuracy: 0.4059, Metrics: {'accuracy': 0.40594059405940597, 'f1_macro': 0.42128812199036914, 'f1_weighted': 0.43107210400012713, 'precision_macro': 0.5575757575757576, 'recall_macro': 0.4802003081664099}
Epoch 21 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:16:56,023][__main__][INFO] - Train Epoch: 21 [0/7 (0%)]	Loss: 1.074176
Epoch 21 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 21 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 21 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 21 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 21 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 21 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 21 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 21 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 21 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:17:00,780][__main__][INFO] - Epoch 21: Val Loss: 0.9109, Accuracy: 0.6238, Metrics: {'accuracy': 0.6237623762376238, 'f1_macro': 0.5053151054202368, 'f1_weighted': 0.6078381373518116, 'precision_macro': 0.6418350168350169, 'recall_macro': 0.47900616332819723}
Epoch 22 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:01,479][__main__][INFO] - Train Epoch: 22 [0/7 (0%)]	Loss: 0.657531
Epoch 22 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 22 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 22 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 22 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 22 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 22 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 22 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 22 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 22 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 22 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:17:06,244][__main__][INFO] - Epoch 22: Val Loss: 1.0123, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.392063492063492, 'f1_weighted': 0.5553826811252554, 'precision_macro': 0.49170524691358025, 'recall_macro': 0.3779853620955316}
Epoch 23 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:06,942][__main__][INFO] - Train Epoch: 23 [0/7 (0%)]	Loss: 0.681724
Epoch 23 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 23 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 23 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 23 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 23 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 23 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 23 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 23 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 23 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:17:11,696][__main__][INFO] - Epoch 23: Val Loss: 1.1121, Accuracy: 0.6535, Metrics: {'accuracy': 0.6534653465346535, 'f1_macro': 0.42659374094465374, 'f1_weighted': 0.5785804659863263, 'precision_macro': 0.5094476744186046, 'recall_macro': 0.4153890600924499}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f61941f0>
<numpy.flatiter object at 0x7f36f61941f0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3703379ea0>
<numpy.flatiter object at 0x7f3703379ea0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703379ea0>
<numpy.flatiter object at 0x7f3703379ea0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703379ea0>
<numpy.flatiter object at 0x7f3703379ea0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703379ea0>
<numpy.flatiter object at 0x7f3703379ea0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:17:11,762][__main__][INFO] - Saved best model at epoch 23 with accuracy: 0.6535
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.6875, -4.0, 117.6875, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.6875, -4.0, 117.6875, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:17:11,884][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 24 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:12,630][__main__][INFO] - Train Epoch: 24 [0/7 (0%)]	Loss: 0.599287
Epoch 24 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 24 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 24 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 24 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 24 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 24 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 24 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 24 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 24 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 24 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:17:17,383][__main__][INFO] - Epoch 24: Val Loss: 1.0292, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.47085495428712626, 'f1_weighted': 0.5970367978235925, 'precision_macro': 0.5156626506024097, 'recall_macro': 0.4648690292758089}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f3812594150>
<numpy.flatiter object at 0x7f3812594150>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3812239500>
<numpy.flatiter object at 0x7f3812239500>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812239500>
<numpy.flatiter object at 0x7f3812239500>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3812239b00>
<numpy.flatiter object at 0x7f3812239b00>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3812239b00>
<numpy.flatiter object at 0x7f3812239b00>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:17:17,449][__main__][INFO] - Saved best model at epoch 24 with accuracy: 0.6634
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:17:17,551][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 25 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:18,283][__main__][INFO] - Train Epoch: 25 [0/7 (0%)]	Loss: 0.434208
Epoch 25 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 25 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 25 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 25 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 25 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 25 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 25 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 25 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 25 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 25 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:17:23,046][__main__][INFO] - Epoch 25: Val Loss: 0.9838, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4876274890723652, 'f1_weighted': 0.6051630369447824, 'precision_macro': 0.5267737617135207, 'recall_macro': 0.4875963020030817}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f7847900>
<numpy.flatiter object at 0x7f36f7847900>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3811f1fe40>
<numpy.flatiter object at 0x7f3811f1fe40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f1fe40>
<numpy.flatiter object at 0x7f3811f1fe40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811f20440>
<numpy.flatiter object at 0x7f3811f20440>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811f20440>
<numpy.flatiter object at 0x7f3811f20440>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:17:23,111][__main__][INFO] - Saved best model at epoch 25 with accuracy: 0.6733
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:17:23,206][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 26 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:23,937][__main__][INFO] - Train Epoch: 26 [0/7 (0%)]	Loss: 0.483230
Epoch 26 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 26 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 26 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 26 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 26 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 26 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 26 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 26 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 26 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 26 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:17:28,698][__main__][INFO] - Epoch 26: Val Loss: 1.0370, Accuracy: 0.5347, Metrics: {'accuracy': 0.5346534653465347, 'f1_macro': 0.5404249644381223, 'f1_weighted': 0.5514281086714646, 'precision_macro': 0.5939986737400531, 'recall_macro': 0.5557395993836671}
Epoch 27 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:29,409][__main__][INFO] - Train Epoch: 27 [0/7 (0%)]	Loss: 0.577374
Epoch 27 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 27 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 27 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 27 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.43it/s]Epoch 27 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 27 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 27 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 27 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 27 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 27 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:17:34,177][__main__][INFO] - Epoch 27: Val Loss: 0.8668, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5304621848739496, 'f1_weighted': 0.650428488226974, 'precision_macro': 0.5431818181818182, 'recall_macro': 0.5333590138674885}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f370308f740>
<numpy.flatiter object at 0x7f370308f740>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f3702f00b40>
<numpy.flatiter object at 0x7f3702f00b40>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3702f00b40>
<numpy.flatiter object at 0x7f3702f00b40>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3811ed85d0>
<numpy.flatiter object at 0x7f3811ed85d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3811ed85d0>
<numpy.flatiter object at 0x7f3811ed85d0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:17:34,238][__main__][INFO] - Saved best model at epoch 27 with accuracy: 0.7030
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:17:34,336][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 28 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:35,064][__main__][INFO] - Train Epoch: 28 [0/7 (0%)]	Loss: 0.552408
Epoch 28 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 28 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 28 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 28 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 28 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 28 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 28 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 28 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 28 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 28 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:17:39,815][__main__][INFO] - Epoch 28: Val Loss: 0.8597, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5573912298732443, 'f1_weighted': 0.6614007238339455, 'precision_macro': 0.7999999999999999, 'recall_macro': 0.5395608628659476}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38121fe490>
<numpy.flatiter object at 0x7f38121fe490>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f381257ffa0>
<numpy.flatiter object at 0x7f381257ffa0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f381257ffa0>
<numpy.flatiter object at 0x7f381257ffa0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f38125805a0>
<numpy.flatiter object at 0x7f38125805a0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f38125805a0>
<numpy.flatiter object at 0x7f38125805a0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:17:39,874][__main__][INFO] - Saved best model at epoch 28 with accuracy: 0.7129
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:17:39,972][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 29 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:40,694][__main__][INFO] - Train Epoch: 29 [0/7 (0%)]	Loss: 0.469715
Epoch 29 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.45it/s]Epoch 29 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 29 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 29 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 29 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 29 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 29 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 29 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 29 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:17:45,452][__main__][INFO] - Epoch 29: Val Loss: 0.8687, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5887796414112204, 'f1_weighted': 0.6595926220730807, 'precision_macro': 0.7621674491392801, 'recall_macro': 0.5618644067796611}
Epoch 30 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:46,159][__main__][INFO] - Train Epoch: 30 [0/7 (0%)]	Loss: 0.516271
Epoch 30 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 30 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 30 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 30 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 30 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 30 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 30 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 30 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 30 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 30 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:17:50,913][__main__][INFO] - Epoch 30: Val Loss: 1.1700, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5036878881987578, 'f1_weighted': 0.62477707398069, 'precision_macro': 0.5208860759493671, 'recall_macro': 0.5083590138674885}
Epoch 31 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:51,614][__main__][INFO] - Train Epoch: 31 [0/7 (0%)]	Loss: 0.485723
Epoch 31 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 31 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 31 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 31 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 31 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 31 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 31 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 31 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 31 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 31 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:17:56,374][__main__][INFO] - Epoch 31: Val Loss: 1.1752, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.5306676449009537, 'f1_weighted': 0.626524193138316, 'precision_macro': 0.7787940379403795, 'recall_macro': 0.5103235747303544}
Epoch 32 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:17:57,083][__main__][INFO] - Train Epoch: 32 [0/7 (0%)]	Loss: 0.528861
Epoch 32 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 32 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 32 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 32 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 32 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 32 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 32 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 32 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 32 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:18:01,845][__main__][INFO] - Epoch 32: Val Loss: 0.8514, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.6567006269592477, 'f1_weighted': 0.6956299078183681, 'precision_macro': 0.6504125260704208, 'recall_macro': 0.6648497688751926}
Epoch 33 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:02,541][__main__][INFO] - Train Epoch: 33 [0/7 (0%)]	Loss: 0.583179
Epoch 33 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 33 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 33 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 33 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 33 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 33 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 33 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 33 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 33 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:18:07,297][__main__][INFO] - Epoch 33: Val Loss: 0.9634, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.5371473310404608, 'f1_weighted': 0.6497417126999169, 'precision_macro': 0.5336622807017544, 'recall_macro': 0.5456471494607088}
Epoch 34 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:07,994][__main__][INFO] - Train Epoch: 34 [0/7 (0%)]	Loss: 0.382395
Epoch 34 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 34 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 34 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 34 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 34 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 34 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 34 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 34 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 34 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:18:12,751][__main__][INFO] - Epoch 34: Val Loss: 0.9634, Accuracy: 0.7030, Metrics: {'accuracy': 0.7029702970297029, 'f1_macro': 0.5421592775041051, 'f1_weighted': 0.6471134305548782, 'precision_macro': 0.7867283950617284, 'recall_macro': 0.5270608628659477}
Epoch 35 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:13,455][__main__][INFO] - Train Epoch: 35 [0/7 (0%)]	Loss: 0.402443
Epoch 35 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 35 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.42it/s]Epoch 35 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 35 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 35 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 35 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 35 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 35 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 35 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 35 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:18:18,214][__main__][INFO] - Epoch 35: Val Loss: 0.8404, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.6111395994208494, 'f1_weighted': 0.69311888355824, 'precision_macro': 0.656841432225064, 'recall_macro': 0.5911016949152542}
Epoch 36 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:18,911][__main__][INFO] - Train Epoch: 36 [0/7 (0%)]	Loss: 0.511137
Epoch 36 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 36 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 36 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 36 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 36 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 36 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 36 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 36 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 36 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:18:23,667][__main__][INFO] - Epoch 36: Val Loss: 0.8353, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6376607888235795, 'f1_weighted': 0.7185728539631373, 'precision_macro': 0.8090225563909774, 'recall_macro': 0.6120762711864407}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f374924ad40>
<numpy.flatiter object at 0x7f374924ad40>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37492438d0>
<numpy.flatiter object at 0x7f37492438d0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37492438d0>
<numpy.flatiter object at 0x7f37492438d0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3749243ed0>
<numpy.flatiter object at 0x7f3749243ed0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3749243ed0>
<numpy.flatiter object at 0x7f3749243ed0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:18:23,733][__main__][INFO] - Saved best model at epoch 36 with accuracy: 0.7426
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:18:23,847][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 37 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:24,576][__main__][INFO] - Train Epoch: 37 [0/7 (0%)]	Loss: 0.523373
Epoch 37 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 37 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 37 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 37 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 37 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 37 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 37 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 37 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 37 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 37 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:18:29,321][__main__][INFO] - Epoch 37: Val Loss: 0.8623, Accuracy: 0.7426, Metrics: {'accuracy': 0.7425742574257426, 'f1_macro': 0.6574465586093493, 'f1_weighted': 0.7255306926041442, 'precision_macro': 0.7097652347652348, 'recall_macro': 0.6325308166409861}
Epoch 38 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:30,027][__main__][INFO] - Train Epoch: 38 [0/7 (0%)]	Loss: 0.365230
Epoch 38 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 38 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 38 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 38 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 38 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 38 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 38 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 38 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 38 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 38 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:18:34,779][__main__][INFO] - Epoch 38: Val Loss: 1.1430, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.4990741711211264, 'f1_weighted': 0.6256472413827695, 'precision_macro': 0.534620596205962, 'recall_macro': 0.504333590138675}
Epoch 39 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:35,485][__main__][INFO] - Train Epoch: 39 [0/7 (0%)]	Loss: 0.378060
Epoch 39 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 39 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 39 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 39 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 39 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 39 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 39 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 39 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 39 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 39 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:18:40,235][__main__][INFO] - Epoch 39: Val Loss: 1.2387, Accuracy: 0.6733, Metrics: {'accuracy': 0.6732673267326733, 'f1_macro': 0.4508374384236453, 'f1_weighted': 0.5843047358923085, 'precision_macro': 0.4906976744186047, 'recall_macro': 0.4710708782742681}
Epoch 40 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:40,932][__main__][INFO] - Train Epoch: 40 [0/7 (0%)]	Loss: 0.505573
Epoch 40 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 40 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 40 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 40 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 40 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 40 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 40 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:18:45,689][__main__][INFO] - Epoch 40: Val Loss: 0.8344, Accuracy: 0.7327, Metrics: {'accuracy': 0.7326732673267327, 'f1_macro': 0.6541339116291678, 'f1_weighted': 0.7216987082281011, 'precision_macro': 0.6923076923076923, 'recall_macro': 0.6345916795069337}
[2025-05-30 16:18:45,691][__main__][INFO] - Saved model at epoch 40
Epoch 41 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:46,401][__main__][INFO] - Train Epoch: 41 [0/7 (0%)]	Loss: 0.426454
Epoch 41 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s]Epoch 41 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 41 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 41 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 41 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 41 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 41 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 41 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 41 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 41 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:18:51,152][__main__][INFO] - Epoch 41: Val Loss: 1.1414, Accuracy: 0.6832, Metrics: {'accuracy': 0.6831683168316832, 'f1_macro': 0.48289738430583495, 'f1_weighted': 0.6106739446580474, 'precision_macro': 0.5186746987951807, 'recall_macro': 0.4918335901386749}
Epoch 42 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:51,850][__main__][INFO] - Train Epoch: 42 [0/7 (0%)]	Loss: 0.343280
Epoch 42 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 42 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 42 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 42 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 42 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 42 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 42 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 42 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 42 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 42 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:18:56,606][__main__][INFO] - Epoch 42: Val Loss: 1.2168, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.4046052631578947, 'f1_weighted': 0.545205836373111, 'precision_macro': 0.4086021505376344, 'recall_macro': 0.4318181818181818}
Epoch 43 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:18:57,317][__main__][INFO] - Train Epoch: 43 [0/7 (0%)]	Loss: 0.776749
Epoch 43 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.41it/s]Epoch 43 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 43 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.43it/s]Epoch 43 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 43 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 43 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 43 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 43 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 43 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 43 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             [2025-05-30 16:19:02,074][__main__][INFO] - Epoch 43: Val Loss: 1.0109, Accuracy: 0.6139, Metrics: {'accuracy': 0.6138613861386139, 'f1_macro': 0.5025737602008788, 'f1_weighted': 0.6082141547488081, 'precision_macro': 0.6527916251246261, 'recall_macro': 0.4810670261941449}
Epoch 44 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:02,783][__main__][INFO] - Train Epoch: 44 [0/7 (0%)]	Loss: 0.676502
Epoch 44 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 44 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 44 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 44 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 44 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 44 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 44 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 44 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 44 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 44 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:19:07,543][__main__][INFO] - Epoch 44: Val Loss: 0.8542, Accuracy: 0.6337, Metrics: {'accuracy': 0.6336633663366337, 'f1_macro': 0.49363675582398625, 'f1_weighted': 0.610196567542863, 'precision_macro': 0.5044642857142857, 'recall_macro': 0.49976887519260393}
Epoch 45 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:08,247][__main__][INFO] - Train Epoch: 45 [0/7 (0%)]	Loss: 0.579987
Epoch 45 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 45 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 45 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 45 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 45 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 45 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 45 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 45 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 45 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 45 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:19:13,003][__main__][INFO] - Epoch 45: Val Loss: 0.8636, Accuracy: 0.6931, Metrics: {'accuracy': 0.693069306930693, 'f1_macro': 0.4963643321852277, 'f1_weighted': 0.644970122729839, 'precision_macro': 0.5258646616541354, 'recall_macro': 0.49017719568567025}
Epoch 46 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:13,707][__main__][INFO] - Train Epoch: 46 [0/7 (0%)]	Loss: 0.495489
Epoch 46 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 46 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 46 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 46 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 46 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 46 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 46 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 46 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 46 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 46 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:19:18,465][__main__][INFO] - Epoch 46: Val Loss: 0.8635, Accuracy: 0.7129, Metrics: {'accuracy': 0.7128712871287128, 'f1_macro': 0.5345588235294119, 'f1_weighted': 0.6644437973209085, 'precision_macro': 0.5615079365079365, 'recall_macro': 0.5273690292758089}
Epoch 47 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:19,172][__main__][INFO] - Train Epoch: 47 [0/7 (0%)]	Loss: 0.533179
Epoch 47 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 47 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.43it/s]Epoch 47 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 47 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 47 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 47 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 47 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 47 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 47 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 47 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:19:23,926][__main__][INFO] - Epoch 47: Val Loss: 0.9868, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.45560811737282325, 'f1_weighted': 0.6004075520674239, 'precision_macro': 0.5416666666666666, 'recall_macro': 0.4361517719568567}
Epoch 48 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:24,629][__main__][INFO] - Train Epoch: 48 [0/7 (0%)]	Loss: 0.493379
Epoch 48 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.43it/s]Epoch 48 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 48 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 48 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 48 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 48 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 48 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 48 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 48 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 48 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.99it/s]                                                             [2025-05-30 16:19:29,381][__main__][INFO] - Epoch 48: Val Loss: 0.9048, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.564141414141414, 'f1_weighted': 0.6518205666720518, 'precision_macro': 0.5896551724137931, 'recall_macro': 0.5864406779661018}
Epoch 49 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:30,076][__main__][INFO] - Train Epoch: 49 [0/7 (0%)]	Loss: 0.489358
Epoch 49 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.44it/s]Epoch 49 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 49 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 49 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 49 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 49 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 49 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 49 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 49 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.50it/s]Epoch 49 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.98it/s]                                                             [2025-05-30 16:19:34,836][__main__][INFO] - Epoch 49: Val Loss: 0.8476, Accuracy: 0.6634, Metrics: {'accuracy': 0.6633663366336634, 'f1_macro': 0.6144156142404672, 'f1_weighted': 0.6664499766003482, 'precision_macro': 0.6180555555555556, 'recall_macro': 0.6234206471494608}
Epoch 50 [Train]:   0%|          | 0/7 [00:00<?, ?it/s][2025-05-30 16:19:35,544][__main__][INFO] - Train Epoch: 50 [0/7 (0%)]	Loss: 0.516311
Epoch 50 [Train]:  14%|‚ñà‚ñç        | 1/7 [00:00<00:04,  1.42it/s]Epoch 50 [Train]:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:01<00:03,  1.44it/s]Epoch 50 [Train]:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:02<00:02,  1.44it/s]Epoch 50 [Train]:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:02<00:02,  1.44it/s]Epoch 50 [Train]:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:03<00:01,  1.44it/s]Epoch 50 [Train]:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:04<00:00,  1.44it/s]Epoch 50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:04<00:00,  1.85it/s]                                                               Epoch 50 [Val]:   0%|          | 0/2 [00:00<?, ?it/s]Epoch 50 [Val]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:00<00:00,  1.51it/s]Epoch 50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  2.00it/s]                                                             [2025-05-30 16:19:40,294][__main__][INFO] - Epoch 50: Val Loss: 0.9233, Accuracy: 0.7228, Metrics: {'accuracy': 0.7227722772277227, 'f1_macro': 0.5920611123009923, 'f1_weighted': 0.6805084020931543, 'precision_macro': 0.735548523206751, 'recall_macro': 0.5622881355932203}
[2025-05-30 16:19:40,295][__main__][INFO] - Early stopping triggered after 50 epochs
[2025-05-30 16:19:40,295][__main__][INFO] - Saving best confusion matrix with accuracy: 0.7426
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f38120f6c50>
<numpy.flatiter object at 0x7f38120f6c50>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37036084b0>
<numpy.flatiter object at 0x7f37036084b0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37036084b0>
<numpy.flatiter object at 0x7f37036084b0>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f3703608ab0>
<numpy.flatiter object at 0x7f3703608ab0>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f3703608ab0>
<numpy.flatiter object at 0x7f3703608ab0>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-171.9375, -4.0, 171.9375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:              Best Accuracy ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:                 Train Loss ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation Accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà
wandb:            Validation Loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Validation accuracy ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà
wandb:        Validation f1_macro ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá
wandb:     Validation f1_weighted ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: Validation precision_macro ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá
wandb:    Validation recall_macro ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:              Best Accuracy 0.74257
wandb:                 Train Loss 0.51631
wandb:        Validation Accuracy 0.72277
wandb:            Validation Loss 0.92327
wandb:        Validation accuracy 0.72277
wandb:        Validation f1_macro 0.59206
wandb:     Validation f1_weighted 0.68051
wandb: Validation precision_macro 0.73555
wandb:    Validation recall_macro 0.56229
wandb: 
wandb: üöÄ View run silver-sweep-22 at: https://wandb.ai/vinakhiem120/naim_tbi/runs/98qiujxv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vinakhiem120/naim_tbi
wandb: Synced 5 W&B file(s), 8 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250530_161456-98qiujxv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: y9iadisf with config:
wandb: 	Fdropout_rate: 0.33191282803561506
wandb: 	Fnum_heads: 8
wandb: 	Fnum_layers: 3
wandb: 	Mdropout_rate: 0.1833630984861181
wandb: 	Mnum_layers: 3
wandb: 	batch_size: 128
wandb: 	learning_rate: 0.024909084200189707
wandb: 	pretrained_model_name: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /home/khanhhiep/Code/Khanh/Khiem/MyBachelorThesis/outputs/2025-05-30/15-05-43/wandb/run-20250530_161953-y9iadisf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vinakhiem120/naim_tbi
wandb: üßπ View sweep at https://wandb.ai/vinakhiem120/naim_tbi/sweeps/dpgwzdsz
wandb: üöÄ View run at https://wandb.ai/vinakhiem120/naim_tbi/runs/y9iadisf
wandb: WARNING Ignoring project 'naim_tbi' when running a sweep.

(-4.4375, -7.0, 4.4375, 7.0)
(-171.9375, -4.0, 171.9375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
Training started...
Epoch 0 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:19:58,991][__main__][INFO] - Train Epoch: 0 [0/4 (0%)]	Loss: 1.525814
Epoch 0 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.36s/it]Epoch 0 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 0 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.34s/it]Epoch 0 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.12it/s]                                                              Epoch 0 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 0 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.01s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:02,895][__main__][INFO] - Epoch 0: Val Loss: 127.9162, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f36f616fbd0>
<numpy.flatiter object at 0x7f36f616fbd0>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37486ec330>
<numpy.flatiter object at 0x7f37486ec330>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486ec330>
<numpy.flatiter object at 0x7f37486ec330>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37486ec330>
<numpy.flatiter object at 0x7f37486ec330>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37486ec330>
<numpy.flatiter object at 0x7f37486ec330>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:20:03,229][__main__][INFO] - Saved best model at epoch 0 with accuracy: 0.1089
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.3125, -4.0, 112.3125, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-112.3125, -4.0, 112.3125, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:20:03,328][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
[2025-05-30 16:20:03,360][__main__][INFO] - Saved model at epoch 0
Epoch 1 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:04,700][__main__][INFO] - Train Epoch: 1 [0/4 (0%)]	Loss: 115.876228
Epoch 1 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.34s/it]Epoch 1 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.34s/it]Epoch 1 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.34s/it]Epoch 1 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.12it/s]                                                              Epoch 1 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 1 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:08,621][__main__][INFO] - Epoch 1: Val Loss: 27.8160, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:20:08,685][__main__][INFO] - Saved best model at epoch 1 with accuracy: 0.5842
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-112.375, -4.0, 112.375, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.75, -7.0, 8.75, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-112.375, -4.0, 112.375, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:20:08,785][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 2 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:10,158][__main__][INFO] - Train Epoch: 2 [0/4 (0%)]	Loss: 21.684458
Epoch 2 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.34s/it]Epoch 2 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.34s/it]Epoch 2 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.34s/it]Epoch 2 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.12it/s]                                                              Epoch 2 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 2 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:14,081][__main__][INFO] - Epoch 2: Val Loss: 31.6702, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 3 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:15,437][__main__][INFO] - Train Epoch: 3 [0/4 (0%)]	Loss: 28.629045
Epoch 3 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.35s/it]Epoch 3 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 3 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.34s/it]Epoch 3 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.11it/s]                                                              Epoch 3 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 3 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:19,362][__main__][INFO] - Epoch 3: Val Loss: 17.4538, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 4 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:20,710][__main__][INFO] - Train Epoch: 4 [0/4 (0%)]	Loss: 12.211627
Epoch 4 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.35s/it]Epoch 4 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 4 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 4 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.11it/s]                                                              Epoch 4 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 4 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:24,653][__main__][INFO] - Epoch 4: Val Loss: 10.3410, Accuracy: 0.1089, Metrics: {'accuracy': 0.10891089108910891, 'f1_macro': 0.049107142857142856, 'f1_weighted': 0.021393210749646393, 'precision_macro': 0.027227722772277228, 'recall_macro': 0.25}
Epoch 5 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:26,012][__main__][INFO] - Train Epoch: 5 [0/4 (0%)]	Loss: 8.144334
Epoch 5 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.35s/it]Epoch 5 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 5 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.11it/s]                                                              Epoch 5 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 5 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:29,962][__main__][INFO] - Epoch 5: Val Loss: 17.1555, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 6 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:31,312][__main__][INFO] - Train Epoch: 6 [0/4 (0%)]	Loss: 13.416619
Epoch 6 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.35s/it]Epoch 6 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 6 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 6 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.11it/s]                                                              Epoch 6 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 6 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:35,271][__main__][INFO] - Epoch 6: Val Loss: 8.2312, Accuracy: 0.4752, Metrics: {'accuracy': 0.4752475247524752, 'f1_macro': 0.21479558728098636, 'f1_weighted': 0.41795542305690664, 'precision_macro': 0.1914102564102564, 'recall_macro': 0.24470338983050846}
Epoch 7 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:36,621][__main__][INFO] - Train Epoch: 7 [0/4 (0%)]	Loss: 5.860145
Epoch 7 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.35s/it]Epoch 7 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.35s/it]Epoch 7 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.35s/it]Epoch 7 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.11it/s]                                                              Epoch 7 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 7 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.02s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:40,568][__main__][INFO] - Epoch 7: Val Loss: 10.2243, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 8 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:41,936][__main__][INFO] - Train Epoch: 8 [0/4 (0%)]	Loss: 7.438075
Epoch 8 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.36s/it]Epoch 8 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.36s/it]Epoch 8 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 8 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 8 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 8 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:45,900][__main__][INFO] - Epoch 8: Val Loss: 6.5827, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 9 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:47,272][__main__][INFO] - Train Epoch: 9 [0/4 (0%)]	Loss: 3.948952
Epoch 9 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 9 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 9 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 9 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                              Epoch 9 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 9 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                            /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:51,252][__main__][INFO] - Epoch 9: Val Loss: 2.2923, Accuracy: 0.1881, Metrics: {'accuracy': 0.18811881188118812, 'f1_macro': 0.07916666666666666, 'f1_weighted': 0.0627062706270627, 'precision_macro': 0.0475, 'recall_macro': 0.2375}
Epoch 10 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:52,610][__main__][INFO] - Train Epoch: 10 [0/4 (0%)]	Loss: 2.454672
Epoch 10 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.36s/it]Epoch 10 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.36s/it]Epoch 10 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                               Epoch 10 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:20:56,583][__main__][INFO] - Epoch 10: Val Loss: 3.2349, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 11 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:20:57,953][__main__][INFO] - Train Epoch: 11 [0/4 (0%)]	Loss: 1.654369
Epoch 11 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 11 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.36s/it]Epoch 11 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 11 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                               Epoch 11 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 11 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:21:01,926][__main__][INFO] - Epoch 11: Val Loss: 2.2548, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 12 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:21:03,302][__main__][INFO] - Train Epoch: 12 [0/4 (0%)]	Loss: 1.068365
Epoch 12 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 12 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 12 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 12 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                               Epoch 12 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 12 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:21:07,289][__main__][INFO] - Epoch 12: Val Loss: 1.3564, Accuracy: 0.5743, Metrics: {'accuracy': 0.5742574257425742, 'f1_macro': 0.23333333333333334, 'f1_weighted': 0.467986798679868, 'precision_macro': 0.22609890109890107, 'recall_macro': 0.2705508474576271}
Epoch 13 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:21:08,661][__main__][INFO] - Train Epoch: 13 [0/4 (0%)]	Loss: 1.083933
Epoch 13 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.37s/it]Epoch 13 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.36s/it]Epoch 13 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.36s/it]Epoch 13 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.10it/s]                                                               Epoch 13 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 13 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.04s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:21:12,644][__main__][INFO] - Epoch 13: Val Loss: 1.9949, Accuracy: 0.5842, Metrics: {'accuracy': 0.5841584158415841, 'f1_macro': 0.184375, 'f1_weighted': 0.43081683168316837, 'precision_macro': 0.14603960396039603, 'recall_macro': 0.25}
Epoch 14 [Train]:   0%|          | 0/4 [00:00<?, ?it/s][2025-05-30 16:21:14,022][__main__][INFO] - Train Epoch: 14 [0/4 (0%)]	Loss: 1.312296
Epoch 14 [Train]:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:01<00:04,  1.38s/it]Epoch 14 [Train]:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:02<00:02,  1.37s/it]Epoch 14 [Train]:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:04<00:01,  1.37s/it]Epoch 14 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.09it/s]                                                               Epoch 14 [Val]:   0%|          | 0/1 [00:00<?, ?it/s]Epoch 14 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]                                                             /home/khanhhiep/anaconda3/envs/khiem/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
[2025-05-30 16:21:18,013][__main__][INFO] - Epoch 14: Val Loss: 1.4946, Accuracy: 0.5941, Metrics: {'accuracy': 0.594059405940594, 'f1_macro': 0.20993589743589744, 'f1_weighted': 0.4583650672759583, 'precision_macro': 0.21456185567010308, 'recall_macro': 0.2625}
(0, 0, 8, 6)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.9, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.7450000000000001, 0.88)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.125, 0.10999999999999999, 0.9, 0.88)
<numpy.flatiter object at 0x7f37030b5970>
<numpy.flatiter object at 0x7f37030b5970>
(0.7837500000000002, 0.10999999999999999, 0.9000000000000001, 0.88)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0, 0, 800.0, 600.0)
(0, 0, 1, 1)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
(0.0, 0.0, 1.0, 1.0)
[2025-05-30 16:21:18,077][__main__][INFO] - Saved best model at epoch 14 with accuracy: 0.5941
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0, 0, 1, 1)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(100.0, 532.1666666666666, 100.0, 532.1666666666666)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-117.625, -4.0, 117.625, 14.0)
(100.0, 536.3333333333333, 100.0, 536.3333333333333)
(596.0000000000001, 536.3333333333333, 596.0000000000001, 536.3333333333333)
(0.0, 0.0, 1.0, 1.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.4375, -14.0, 4.4375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-4.375, -14.0, 4.375, 0.0)
(-53.6875, -14.0, 53.6875, 0.0)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.437500000000001, 0.0, 4.437499999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.0, -4.375000000000001, 0.0, 4.374999999999999)
(-14.000000000000002, -35.75, 1.7763568394002505e-15, 35.75)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.8125, -7.0, 8.8125, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-8.875, -7.0, 8.875, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.4375, -7.0, 4.4375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-4.375, -7.0, 4.375, 7.0)
(-117.625, -4.0, 117.625, 14.0)
(0.0, 0.0, 1.0, 1.0)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
(0.0, -8.5, 8.75, 5.5)
(0.0, -8.5, 17.625, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
(0.0, -8.5, 17.5, 5.5)
16
16
[2025-05-30 16:21:18,177][tensorboardX.summary][INFO] - Summary name Validation/Confusion Matrix is illegal; using Validation/Confusion_Matrix instead.
Epoch 15 [Train]:   0%|          | 0/4 [00:00<?, ?it/s]