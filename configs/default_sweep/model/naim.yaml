name: naim
model:
  _target_: src.models.naim.NAIMclassifier
  params:
    input_size: ${default_sweep.data.caller.num_features}
    output_size: ${default_sweep.data.caller.num_classes}
    cat_idxs: null
    cat_dims: null
    d_token: 64
    embedder_initialization: normal
    bias: false
    mask_type: 2
    missing_value: ~inf
    num_heads: 4
    feedforward_dim: 1000
    dropout_rate: 0.0.13494352349372787
    activation: relu
    num_layers: 1
    extractor: false
# back bone embedding (quan trong nhat)
# xem thử cái L ảnh hưởng thế nào
# xem feature importance của cái này.
# feature engineering thông thường 
# xem thử 1 subset nhỏ hơn với dataset missing value ít hơn 1 threshold (cáo màu để so sánh với)
# hiểu về trường dữ liệu
# raise ra được problem của dữ liệu 
# xem cái mạng có thể học được như nào
# chạy thử trên TBI 102
# fuse của text và tabnet = MMiunet chủ yếu là cross
# trước hết là cái này, còn text thì làm thêm
# phân tích Mij 
optimizer:
  lr: ${default_sweep.training.learning_rate}
  betas: [ 0.9, 0.999 ]
  eps: 1e-8   
  weight_decay: 0.01
  amsgrad: False
  foreach: null
  maximize: False
  capturable: False
scheduler:
  T_max: ${default_sweep.training.num_epochs}
  eta_min: 1e-6 
  mode: min
  factor: 0.1
  patience: 10
  verbose: False
